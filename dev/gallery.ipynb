{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "\n",
    "from invert.forward import get_info, create_forward_model\n",
    "from invert.util import pos_from_forward\n",
    "pp = dict(surface='inflated', hemi='both', clim=dict(kind=\"percent\", pos_lims=(0, 99, 100)), colorbar=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    4.2s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi64')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "pos = pos_from_forward(fwd)\n",
    "leadfield = fwd[\"sol\"][\"data\"]\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "source_model = fwd['src']\n",
    "vertices = [source_model[0]['vertno'], source_model[1]['vertno']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invert.solvers.esinet import generator\n",
    "\n",
    "sim_params = dict(\n",
    "    use_cov=False, \n",
    "    return_mask=False, \n",
    "    batch_repetitions=1,\n",
    "    batch_size=1,\n",
    "    n_sources=1, \n",
    "    n_orders=(2, 3), \n",
    "    snr_range=(100, 101), \n",
    "    n_timecourses=1,\n",
    "    scale_data=False)\n",
    "    \n",
    "\n",
    "gen = generator(fwd, **sim_params)\n",
    "x, y = gen.__next__()\n",
    "\n",
    "tmin = 0\n",
    "tstep = 1/info[\"sfreq\"]\n",
    "subject = \"fsaverage\"\n",
    "evoked = mne.EvokedArray(x[0].T, info, tmin=tmin)\n",
    "stc = mne.SourceEstimate(y[0].T, vertices, tmin=tmin, tstep=tstep, \n",
    "                        subject=subject, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Neither input subject subject nor class subject attribute was a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m brain \u001b[39m=\u001b[39m stc\u001b[39m.\u001b[39;49mplot(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpp, brain_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(title\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGround Truth\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m      2\u001b[0m brain\u001b[39m.\u001b[39madd_text(\u001b[39m0.1\u001b[39m, \u001b[39m0.9\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mGround Truth\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m, font_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\mne\\source_estimate.py:650\u001b[0m, in \u001b[0;36m_BaseSourceEstimate.plot\u001b[1;34m(self, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39m@copy_function_doc_to_method_doc\u001b[39m(plot_source_estimates)\n\u001b[0;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39mself\u001b[39m, subject\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, surface\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minflated\u001b[39m\u001b[39m'\u001b[39m, hemi\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlh\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    641\u001b[0m          colormap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, time_label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, smoothing_steps\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    648\u001b[0m          src\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, volume_options\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, view_layout\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    649\u001b[0m          add_data_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, brain_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 650\u001b[0m     brain \u001b[39m=\u001b[39m plot_source_estimates(\n\u001b[0;32m    651\u001b[0m         \u001b[39mself\u001b[39;49m, subject, surface\u001b[39m=\u001b[39;49msurface, hemi\u001b[39m=\u001b[39;49mhemi, colormap\u001b[39m=\u001b[39;49mcolormap,\n\u001b[0;32m    652\u001b[0m         time_label\u001b[39m=\u001b[39;49mtime_label, smoothing_steps\u001b[39m=\u001b[39;49msmoothing_steps,\n\u001b[0;32m    653\u001b[0m         transparent\u001b[39m=\u001b[39;49mtransparent, alpha\u001b[39m=\u001b[39;49malpha, time_viewer\u001b[39m=\u001b[39;49mtime_viewer,\n\u001b[0;32m    654\u001b[0m         subjects_dir\u001b[39m=\u001b[39;49msubjects_dir, figure\u001b[39m=\u001b[39;49mfigure, views\u001b[39m=\u001b[39;49mviews,\n\u001b[0;32m    655\u001b[0m         colorbar\u001b[39m=\u001b[39;49mcolorbar, clim\u001b[39m=\u001b[39;49mclim, cortex\u001b[39m=\u001b[39;49mcortex, size\u001b[39m=\u001b[39;49msize,\n\u001b[0;32m    656\u001b[0m         background\u001b[39m=\u001b[39;49mbackground, foreground\u001b[39m=\u001b[39;49mforeground,\n\u001b[0;32m    657\u001b[0m         initial_time\u001b[39m=\u001b[39;49minitial_time, time_unit\u001b[39m=\u001b[39;49mtime_unit, backend\u001b[39m=\u001b[39;49mbackend,\n\u001b[0;32m    658\u001b[0m         spacing\u001b[39m=\u001b[39;49mspacing, title\u001b[39m=\u001b[39;49mtitle, show_traces\u001b[39m=\u001b[39;49mshow_traces,\n\u001b[0;32m    659\u001b[0m         src\u001b[39m=\u001b[39;49msrc, volume_options\u001b[39m=\u001b[39;49mvolume_options, view_layout\u001b[39m=\u001b[39;49mview_layout,\n\u001b[0;32m    660\u001b[0m         add_data_kwargs\u001b[39m=\u001b[39;49madd_data_kwargs, brain_kwargs\u001b[39m=\u001b[39;49mbrain_kwargs,\n\u001b[0;32m    661\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[0;32m    662\u001b[0m     \u001b[39mreturn\u001b[39;00m brain\n",
      "File \u001b[1;32m<decorator-gen-125>:10\u001b[0m, in \u001b[0;36mplot_source_estimates\u001b[1;34m(stc, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\mne\\viz\\_3d.py:1965\u001b[0m, in \u001b[0;36mplot_source_estimates\u001b[1;34m(stc, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n\u001b[0;32m   1962\u001b[0m _validate_type(stc, _BaseSourceEstimate, \u001b[39m'\u001b[39m\u001b[39mstc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msource estimate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1963\u001b[0m subjects_dir \u001b[39m=\u001b[39m get_subjects_dir(subjects_dir\u001b[39m=\u001b[39msubjects_dir,\n\u001b[0;32m   1964\u001b[0m                                 raise_error\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1965\u001b[0m subject \u001b[39m=\u001b[39m _check_subject(stc\u001b[39m.\u001b[39;49msubject, subject)\n\u001b[0;32m   1966\u001b[0m _check_option(\u001b[39m'\u001b[39m\u001b[39mbackend\u001b[39m\u001b[39m'\u001b[39m, backend,\n\u001b[0;32m   1967\u001b[0m               [\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpyvistaqt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnotebook\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m   1968\u001b[0m plot_mpl \u001b[39m=\u001b[39m backend \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\mne\\utils\\check.py:266\u001b[0m, in \u001b[0;36m_check_subject\u001b[1;34m(first, second, raise_error, first_kind, second_kind)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[39mreturn\u001b[39;00m first\n\u001b[0;32m    265\u001b[0m \u001b[39melif\u001b[39;00m raise_error \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNeither \u001b[39m\u001b[39m{\u001b[39;00msecond_kind\u001b[39m}\u001b[39;00m\u001b[39m subject nor \u001b[39m\u001b[39m{\u001b[39;00mfirst_kind\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    267\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mwas a string\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    268\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Neither input subject subject nor class subject attribute was a string"
     ]
    }
   ],
   "source": [
    "brain = stc.plot(**pp, brain_kwargs=dict(title=\"Ground Truth\"))\n",
    "brain.add_text(0.1, 0.9, \"Ground Truth\", 'title', font_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing STC to disk...\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "# evoked.save(\"../figures/solver_gallery/evoked-ave.fif\")\n",
    "stc.save(\"../figures/solver_gallery/source\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\Lukas\\Documents\\projects\\invert\\dev\\..\\figures\\solver_gallery\\evoked-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...      19.00 ms (No comment)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 1 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "evoked = mne.read_evokeds(\"../figures/solver_gallery/evoked-ave.fif\")[0]\n",
    "stc = mne.read_source_estimate(\"../figures/solver_gallery/source-lh.stc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Ground Truth and Inverse Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from invert import Solver\n",
    "from invert.config import all_solvers\n",
    "\n",
    "# Plot Ground Truth\n",
    "stc.data /= abs(stc.data[:, 0]).max()\n",
    "clim = dict(kind=\"values\", pos_lims=(0., 0.5, 1))\n",
    "pp[\"clim\"] = clim\n",
    "brain = stc.plot(**pp, subject=\"fsaverage\", brain_kwargs=dict(title=\"Ground Truth\"))\n",
    "brain.add_text(0.1, 0.9, \"Ground Truth\", 'title', font_size=16)\n",
    "img = brain.screenshot()\n",
    "brain.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "fname = f\"../figures/solver_gallery/GroundTruth\"\n",
    "plt.savefig(fname, dpi=150)\n",
    "plt.close()\n",
    "all_solvers = [\"FLEX\",]\n",
    "# Plot Source Estimates\n",
    "for solver_name in all_solvers:\n",
    "    solver = Solver(solver_name)\n",
    "    solver.make_inverse_operator(fwd, evoked, alpha=\"auto\")\n",
    "    stc_ = solver.apply_inverse_operator(evoked)\n",
    "    stc_.data /= abs(stc_.data[:, 0]).max()\n",
    "    clim = dict(kind=\"values\", pos_lims=(0., 0.5, 1))\n",
    "    pp[\"clim\"] = clim\n",
    "    brain = stc_.plot(**pp, subject=\"fsaverage\", brain_kwargs=dict(title=solver.name))\n",
    "    brain.add_text(0.1, 0.9, solver.name, 'title', font_size=16)\n",
    "    img = brain.screenshot()\n",
    "    brain.close()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    fname = f\"\"\"../figures/solver_gallery/{solver.name.replace(\" \", \"\")}\"\"\"\n",
    "    plt.savefig(fname, dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n",
      "r =  0.19636086828602\n",
      "L1 =  20.113617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.0476362  0.05874738 0.41511153]\n",
      "Using control points [0.0476362  0.05874738 0.41511153]\n",
      "Using control points [0.0476362  0.05874738 0.41511153]\n",
      "Using control points [0.0476362  0.05874738 0.41511153]\n",
      "Using control points [0.01255137 0.10915932 0.70373472]\n",
      "Using control points [0.01255137 0.10915932 0.70373472]\n",
      "Using control points [0.02688973 0.03550795 0.22265582]\n",
      "Using control points [0.01029644 0.04761037 0.63900793]\n",
      "Using control points [0.02688973 0.03550795 0.22265582]\n"
     ]
    }
   ],
   "source": [
    "# from invert import Solver\n",
    "# solver = Solver(\"lstm\")\n",
    "# solver.make_inverse_operator(fwd, evoked, alpha=\"auto\")\n",
    "stc_ = solver.apply_inverse_operator(evoked)\n",
    "\n",
    "stc_.data /= abs(stc_.data).max()\n",
    "brain = stc_.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, solver.name, 'title',\n",
    "               font_size=14)\n",
    "\n",
    "evoked_ = mne.EvokedArray(fwd[\"sol\"][\"data\"] @ stc_.data, info).set_eeg_reference(\"average\", projection=True)\n",
    "evoked_.plot_joint()\n",
    "\n",
    "print(\"r = \", pearsonr(abs(stc.data).mean(axis=-1), abs(stc_.data).mean(axis=-1))[0])\n",
    "print(\"L1 = \",  np.linalg.norm(stc_.data, ord=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invertenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "109cbb5ed194d0e1c7aea844cf0a4a10faadf2a56a1c0eb03142356ad9dcb9c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
