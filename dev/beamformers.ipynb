{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; \n",
    "sys.path.insert(0, '../../esinet')\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "from invert.cmaps import parula\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    3.8s remaining:    6.4s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    3.8s remaining:    2.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    1.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi64')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "leadfield -= leadfield.mean(axis=0)\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "dist = cdist(pos, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12.20it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1990.18it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 25.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyvistaqt 3d backend.\n",
      "\n",
      "Using control points [0.00000000e+00 0.00000000e+00 4.29914927e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    }
   ],
   "source": [
    "# settings = dict(number_of_sources=1, extents=40, duration_of_trial=0.01, target_snr=99999999999)\n",
    "settings = dict(number_of_sources=5, extents=(1, 2), duration_of_trial=0.05, target_snr=1e99)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "y = evoked.data\n",
    "x = stc.data\n",
    "y -= y.mean(axis=0)\n",
    "\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linearly Constrained minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.88078718e-08 2.38621381e-08 2.77730696e-01]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1d33e1eda00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.00 * np.linalg.svd(leadfield)[1].max()\n",
    "leadfield -= leadfield.mean(axis=0)\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[0].T\n",
    "W = W / np.linalg.norm(W, axis=0)\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"LCMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight-normalized minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [2.57903376e-05 2.75019254e-05 3.56001241e-05]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1d33e1ed6a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.0001 * np.linalg.svd(leadfield)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "C_inv_2 = np.linalg.inv(C_inv)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w = (C_inv @ l) / np.sqrt(l.T @ C_inv_2 @ l)\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"WNMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardized minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.00698223 0.00744559 0.00963966]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1d33e7c2f70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.00001 #* np.linalg.svd(leadfield)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "C_inv_2 = np.linalg.inv(C_inv)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w = (C_inv @ l) / np.sqrt(l.T @ C_inv @ l)\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"SMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher-Order minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [5.68246004e-20 6.07150307e-20 9.74930128e-13]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1d33e1d9f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.00 * np.linalg.svd(leadfield)[1].max()\n",
    "n = 3\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "C_inv_n = deepcopy(C_inv)\n",
    "\n",
    "for _ in range(n-1):\n",
    "    C_inv_n = np.linalg.inv(C_inv_n)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w = (C_inv_n @ l) / (l.T @ C_inv_n @ l)\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "W = W / np.linalg.norm(W, axis=0)\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"HOC-MV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenspace-based minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.21945604e-14 2.05090732e-14 9.26500364e-01]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1d3464acdf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from invert.util import find_corner\n",
    "alpha = 0.00 * np.linalg.svd(leadfield)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C = y@y.T\n",
    "\n",
    "U, s, _ = np.linalg.svd(C)\n",
    "j = find_corner(np.arange(len(s)), s)\n",
    "\n",
    "Us = U[:, :j]\n",
    "Un = U[:, j:]\n",
    "\n",
    "\n",
    "C_inv = np.linalg.inv(C + alpha * I)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w_mv = (C_inv @ l) / (l.T @ C_inv @ l)\n",
    "    w_esmv = Us @ Us.T @ w_mv\n",
    "    W.append(w_esmv)\n",
    "\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"EIGMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Constrained minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.06338215 0.07931784 0.67597901]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1d33e1ad6d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = deepcopy(leadfield)\n",
    "L -= L.mean(axis=0)\n",
    "# L /= np.linalg.norm(leadfield, axis=0)\n",
    "alpha = 0.00 * np.linalg.svd(L)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "W = C_inv @ L @ np.linalg.inv(L.T @ C_inv @ L)\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"MCMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Constrained Eigenspace MV Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.21171346e-14 2.01917349e-14 9.26500364e-01]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1d3529f4b80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from invert.util import find_corner\n",
    "alpha = 0.00 * np.linalg.svd(leadfield)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C = y@y.T\n",
    "\n",
    "U, s, _ = np.linalg.svd(C)\n",
    "j = find_corner(np.arange(len(s)), s)\n",
    "\n",
    "Us = U[:, :j]\n",
    "Un = U[:, j:]\n",
    "\n",
    "\n",
    "C_inv = np.linalg.inv(C + alpha * I)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w_mv = C_inv @ l *(1 / (l.T @ C_inv @ l))\n",
    "    w_esmv = Us @ Us.T @ w_mv\n",
    "    W.append(w_esmv)\n",
    "\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"EIG-MCMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReciPSIICOS Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [9.10439126e-15 1.17559969e-14 5.07660244e-01]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1d354d81f70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from invert.util import find_corner\n",
    "\n",
    "G = deepcopy(leadfield)\n",
    "G -= G.mean(axis=0)\n",
    "# G_pwr = np.stack([g[:, np.newaxis] @ g[:, np.newaxis].T for g in G], axis=0)\n",
    "\n",
    "# Prepare Data Covariance Matrix\n",
    "I = np.identity(n_chans)\n",
    "lam = 0.00\n",
    "alpha = np.linalg.svd(y@y.T)[1].max()\n",
    "C = y@y.T + lam * alpha * I\n",
    "\n",
    "# Step 1\n",
    "G_pwr = np.stack([g * g for g in G], axis=0)\n",
    "\n",
    "# Step 2\n",
    "U_pwr, S_pwr, V_pwr = np.linalg.svd(G_pwr, full_matrices=False)\n",
    "k = find_corner(np.arange(len(S_pwr)), S_pwr)\n",
    "P = U_pwr[:, :k] @ U_pwr[:, :k].T\n",
    "\n",
    "# Step 3\n",
    "C_x = (P@C).T #np.stack([p*c for p, c in zip(P, C)], axis=0).T\n",
    "\n",
    "# Step 4\n",
    "E, A, _ = np.linalg.svd(C_x, full_matrices=False)\n",
    "C_x = E @ np.diag(np.abs(A)) @ E.T\n",
    "C_x_inv = np.linalg.inv(C_x)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    w = np.linalg.inv(l.T @ C_x_inv @ l) @ l.T @ C_x_inv\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[0].T\n",
    "\n",
    "# W /= np.linalg.norm(W, axis=0)\n",
    "x_hat = W.T @ y\n",
    "\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"ReciPSIICOS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenspace Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.67677794 0.72169263 0.93420177]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1d33e21bd30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.64886661 0.66941376 0.75564227]\n",
      "Using control points [0.64886661 0.66941376 0.75564227]\n",
      "Using control points [0.24667187 0.25699729 0.29350401]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.001 * np.linalg.svd(leadfield)[1].max()\n",
    "G = deepcopy(leadfield)\n",
    "G -= G.mean(axis=0)\n",
    "I = np.identity(n_chans)\n",
    "C = y @ y.T\n",
    "C_inv = np.linalg.inv(C + alpha * I)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    g = leadfield[:, i][:, np.newaxis]\n",
    "    Omega = np.linalg.inv(g.T @ C_inv @ g) @ g.T @ np.linalg.inv(C_inv) @ g @ np.linalg.inv(g.T @ C_inv @ g)\n",
    "    w = (C_inv @ g @ np.linalg.inv(g.T @ C_inv @ g) ) / np.sqrt(Omega)\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "W[np.isnan(W)] = 0\n",
    "\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"LCMV\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1284)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('invertenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda1e5657e486f74a7b39841fb8103db2af51a77394f44c39a7821a371af47bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
