{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; \n",
    "sys.path.insert(0, '../../esinet')\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "from invert.cmaps import parula\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    2.7s remaining:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    2.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi64')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "leadfield -= leadfield.mean(axis=0)\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "dist = cdist(pos, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 17.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.22it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.00000000e+00 0.00000000e+00 3.68943151e-08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    }
   ],
   "source": [
    "# settings = dict(number_of_sources=1, extents=40, duration_of_trial=0.01, target_snr=99999999999)\n",
    "settings = dict(number_of_sources=3, extents=(1, 2), duration_of_trial=0.1, target_snr=1e99)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "y = evoked.data\n",
    "x = stc.data\n",
    "y -= y.mean(axis=0)\n",
    "\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linearly Constrained minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [4.98244354e-07 5.77181464e-07 2.07953722e-01]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x19e72cf3a90>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.00 * np.linalg.svd(leadfield)[1].max()\n",
    "leadfield -= leadfield.mean(axis=0)\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[0].T\n",
    "W = W / np.linalg.norm(W, axis=0)\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"LCMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight-normalized minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [3.32170934e-05 3.61216712e-05 5.07131357e-05]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x19ec2fd2190>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [3.94027262e-05 4.14323823e-05 4.50397172e-05]\n",
      "Using control points [3.94027262e-05 4.14323823e-05 4.50397172e-05]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0001 * np.linalg.svd(leadfield)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "C_inv_2 = np.linalg.inv(C_inv)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w = (C_inv @ l) / np.sqrt(l.T @ C_inv_2 @ l)\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"WNMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardized minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.00895977 0.00974578 0.01369014]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x19eca4e1250>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.01063278 0.01118369 0.01216406]\n",
      "Using control points [0.00011244 0.00011823 0.00012853]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.00001 #* np.linalg.svd(leadfield)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "C_inv_2 = np.linalg.inv(C_inv)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w = (C_inv @ l) / np.sqrt(l.T @ C_inv @ l)\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"SMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher-Order minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.93460237e-18 2.26793429e-18 1.61098280e-12]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x19ecbd83280>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [2.38517523e-20 2.81807238e-20 3.16121197e-13]\n",
      "Using control points [0.00000000e+00 0.00000000e+00 3.56600339e-08]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.00 * np.linalg.svd(leadfield)[1].max()\n",
    "n = 3\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "C_inv_n = deepcopy(C_inv)\n",
    "\n",
    "for _ in range(n-1):\n",
    "    C_inv_n = np.linalg.inv(C_inv_n)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w = (C_inv_n @ l) / (l.T @ C_inv_n @ l)\n",
    "    W.append(w)\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "W = W / np.linalg.norm(W, axis=0)\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"HOC-MV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenspace-based minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.10495282e-14 1.89606539e-14 4.31939588e-01]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x19ecdce1970>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.96416299e-14 3.34455927e-14 5.47908045e-01]\n"
     ]
    }
   ],
   "source": [
    "from invert.util import find_corner\n",
    "alpha = 0.00 * np.linalg.svd(leadfield)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C = y@y.T\n",
    "\n",
    "U, s, _ = np.linalg.svd(C)\n",
    "j = find_corner(np.arange(len(s)), s)\n",
    "\n",
    "Us = U[:, :j]\n",
    "Un = U[:, j:]\n",
    "\n",
    "\n",
    "C_inv = np.linalg.inv(C + alpha * I)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w_mv = (C_inv @ l) / (l.T @ C_inv @ l)\n",
    "    w_esmv = Us @ Us.T @ w_mv\n",
    "    W.append(w_esmv)\n",
    "\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"EIGMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Constrained minimum variance Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.06348538 0.09014199 0.6293157 ]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x19ecf669b50>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = deepcopy(leadfield)\n",
    "L -= L.mean(axis=0)\n",
    "# L /= np.linalg.norm(leadfield, axis=0)\n",
    "alpha = 0.00 * np.linalg.svd(L)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C_inv = np.linalg.inv(y@y.T + alpha * I)\n",
    "W = C_inv @ L @ np.linalg.inv(L.T @ C_inv @ L)\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"MCMV\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Constrained Eigenspace MV Beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = C_inv @ L @ np.linalg.inv(L.T @ C_inv @ L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.09915358e-14 1.89182569e-14 4.31939590e-01]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x19ed431f2e0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.98206652e-14 3.32850217e-14 5.47908046e-01]\n",
      "Using control points [0.38290875 0.44257064 1.08843471]\n",
      "Using control points [0.38290875 0.44257064 1.08843471]\n"
     ]
    }
   ],
   "source": [
    "from invert.util import find_corner\n",
    "alpha = 0.00 * np.linalg.svd(leadfield)[1].max()\n",
    "\n",
    "I = np.identity(n_chans)\n",
    "C = y@y.T\n",
    "\n",
    "U, s, _ = np.linalg.svd(C)\n",
    "j = find_corner(np.arange(len(s)), s)\n",
    "\n",
    "Us = U[:, :j]\n",
    "Un = U[:, j:]\n",
    "\n",
    "\n",
    "C_inv = np.linalg.inv(C + alpha * I)\n",
    "\n",
    "W = []\n",
    "for i in range(n_dipoles):\n",
    "    l = leadfield[:, i][:, np.newaxis]\n",
    "    # w = np.linalg.inv(l.T @ C_inv @ l ) * l.T @ C_inv\n",
    "    w_mv = C_inv @ l *(1 / (l.T @ C_inv @ l))\n",
    "    w_esmv = Us @ Us.T @ w_mv\n",
    "    W.append(w_esmv)\n",
    "\n",
    "W = np.stack(W, axis=1)[:, :, 0]\n",
    "# W = W / np.linalg.norm(W, axis=0)\n",
    "\n",
    "inverse_operator = W.T\n",
    "x_hat = inverse_operator@y\n",
    "stc_ = stc.copy()\n",
    "stc_.data = x_hat / x_hat.max()\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"EIG-MCMV\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('invertenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "109cbb5ed194d0e1c7aea844cf0a4a10faadf2a56a1c0eb03142356ad9dcb9c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
