{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cdist\n",
    "import mne\n",
    "\n",
    "from invert.forward import get_info, create_forward_model\n",
    "from invert.util import pos_from_forward\n",
    "from invert.evaluate import eval_mean_localization_error\n",
    "\n",
    "pp = dict(surface='inflated', hemi='both', verbose=0, cortex='low_contrast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>32 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Source space</th>\n",
       "        <td>Surface with 324 vertices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Source orientation</th>\n",
       "        <td>Fixed</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Forward | MEG channels: 0 | EEG channels: 32 | Source space: Surface with 324 vertices | Source orientation: Fixed>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling = \"ico2\"\n",
    "info = get_info(kind='biosemi32')\n",
    "fwd = create_forward_model(info=info, sampling=sampling)\n",
    "fwd[\"sol\"][\"data\"] /= np.linalg.norm(fwd[\"sol\"][\"data\"], axis=0) \n",
    "pos = pos_from_forward(fwd)\n",
    "leadfield = fwd[\"sol\"][\"data\"]\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "\n",
    "source_model = fwd['src']\n",
    "vertices = [source_model[0]['vertno'], source_model[1]['vertno']]\n",
    "adjacency = mne.spatial_src_adjacency(fwd[\"src\"], verbose=0)\n",
    "distance_matrix = cdist(pos, pos)\n",
    "fwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invert.simulate import generator\n",
    "sim_params = dict(\n",
    "    use_cov=False,\n",
    "    return_mask=False,\n",
    "    batch_repetitions=1,\n",
    "    batch_size=1,\n",
    "    n_sources=2,\n",
    "    n_orders=0,\n",
    "    # snr_range=(1, 1),\n",
    "    snr_range=(1e20, 1e21),\n",
    "    amplitude_range=(1, 1),\n",
    "    n_timecourses=200,\n",
    "    n_timepoints=50,\n",
    "    scale_data=False,\n",
    "    add_forward_error=False,\n",
    "    forward_error=0.1,\n",
    "    # inter_source_correlation=(0, 0.99),\n",
    "    inter_source_correlation=0,\n",
    "    return_info=True,\n",
    "    diffusion_parameter=0.1,\n",
    "    # correlation_mode=\"cholesky\",\n",
    "    # noise_color_coeff=(0, 0.99),\n",
    "    correlation_mode=None,\n",
    "    noise_color_coeff=0,\n",
    "    \n",
    "    random_seed=None)\n",
    "\n",
    "sim_params = dict(\n",
    "    use_cov=False,\n",
    "    return_mask=False,\n",
    "    batch_repetitions=1,\n",
    "    batch_size=1,\n",
    "    n_sources=(1, 10),\n",
    "    n_orders=(0, 0),\n",
    "    snr_range=(0.2, 10),\n",
    "    amplitude_range=(0.1, 1),\n",
    "    n_timecourses=200,\n",
    "    n_timepoints=50,\n",
    "    scale_data=False,\n",
    "    add_forward_error=False,\n",
    "    forward_error=0.1,\n",
    "    inter_source_correlation=(0, 1),\n",
    "    return_info=True,\n",
    "    diffusion_parameter=0.1,\n",
    "    correlation_mode=\"cholesky\",\n",
    "    noise_color_coeff=(0, 0.99),\n",
    "    normalize_leadfield=True,\n",
    "    \n",
    "    random_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">67,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">60,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">324</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">97,524</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m528\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m67,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m25,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m60,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m324\u001b[0m)            │        \u001b[38;5;34m97,524\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,336</span> (981.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m251,336\u001b[0m (981.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,336</span> (981.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m251,336\u001b[0m (981.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "# Assuming we have a function to generate initial EEG data and true dipoles\n",
    "def generate_initial_data(gen):\n",
    "    # This function should return initial EEG data\n",
    "    # and the true dipole parameters that generated the data.\n",
    "\n",
    "    # Generate random dipole parameters\n",
    "    x, y, _ = gen.__next__()\n",
    "    x = np.swapaxes(x, 1, 2)\n",
    "    y = np.swapaxes(y, 1, 2)\n",
    "    true_indices = [np.where(yy[:, 0]!=0)[0] for yy in y]\n",
    "    return x, true_indices, y\n",
    "\n",
    "# def outproject_from_data(data, leadfield, idc):\n",
    "#     L = leadfield[:, idc]\n",
    "#     # Y_est = L.T @ np.linalg.pinv(L @ L.T + np.identity(L.shape[0])*0.1) @ data\n",
    "#     # or simply:\n",
    "#     Y_est = np.linalg.pinv(L) @ data\n",
    "#     return data - L@Y_est\n",
    "#     # return L@Y_est - data\n",
    "\n",
    "def outproject_from_data(data, leadfield, idc: np.array, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Projects away the leadfield components at the indices idc from the EEG data.\n",
    "\n",
    "    Parameters:\n",
    "    data (np.array): Observed M/EEG data (n_chans x n_time).\n",
    "    leadfield (np.array): Leadfield matrix (n_chans x n_dipoles).\n",
    "    idc (np.array): Indices to project away from the leadfield.\n",
    "\n",
    "    Returns:\n",
    "    np.array: Data with the specified leadfield components removed.\n",
    "    \"\"\"\n",
    "    # Select the columns of the leadfield matrix corresponding to the indices\n",
    "    L_idc = leadfield[:, idc]\n",
    "\n",
    "    # Compute the projection matrix\n",
    "    # P = I - L(L.TL)^-1L.T\n",
    "    # where L = L_idc\n",
    "    L_idc_T = L_idc.T\n",
    "    projection_matrix = np.eye(leadfield.shape[0]) - L_idc @ np.linalg.pinv(L_idc_T @ L_idc + np.identity(len(idc)) * alpha) @ L_idc_T\n",
    "\n",
    "    # Apply the projection matrix to the data\n",
    "    data_without_idc = projection_matrix @ data\n",
    "\n",
    "    return data_without_idc\n",
    "\n",
    "def wrap_outproject_from_data(current_data, leadfield, estimated_dipole_idc, alpha=0.1):\n",
    "    # Wrapper function to outproject dipoles from the data\n",
    "    n_samples = current_data.shape[0]\n",
    "    new_data = np.zeros_like(current_data)\n",
    "    for i in range(n_samples):\n",
    "        new_data[i] = outproject_from_data(current_data[i], leadfield, np.array(estimated_dipole_idc[i]), alpha=alpha)\n",
    "    return new_data\n",
    "\n",
    "def predict(model, current_covs):\n",
    "    # Predict source estimate\n",
    "\n",
    "    # Predict the sources using the model\n",
    "    estimated_sources = model.predict(current_covs)  # Model's prediction\n",
    "    return estimated_sources\n",
    "    \n",
    "    # return new_data, estimated_dipole_idc\n",
    "\n",
    "# Function to compute residuals or stopping condition\n",
    "def compute_residual(current_data, new_data):\n",
    "    # Placeholder function to compute residual to decide when to stop the iteration\n",
    "    return tf.norm(current_data - new_data)\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import tensorflow as tf\n",
    "\n",
    "def spatially_weighted_cosine_loss(pos, sigma=10.0):\n",
    "    \"\"\"\n",
    "    Returns a loss function that combines cosine similarity with a spatial weighting\n",
    "    based on the positions of dipoles in the brain.\n",
    "    \n",
    "    Parameters:\n",
    "    - pos: numpy array of shape (n, 3) containing the positions of each dipole.\n",
    "    - sigma: controls the spread of the spatial influence (lower value -> steeper).\n",
    "\n",
    "    Returns:\n",
    "    - A loss function compatible with Keras.\n",
    "    \"\"\"\n",
    "    # Convert positions to a tensor and compute pairwise squared Euclidean distances\n",
    "    pos_tensor = tf.constant(pos, dtype=tf.float32)\n",
    "    pos_diff = tf.expand_dims(pos_tensor, 0) - tf.expand_dims(pos_tensor, 1)\n",
    "    sq_dist_matrix = tf.reduce_sum(tf.square(pos_diff), axis=-1)\n",
    "\n",
    "    # Create a Gaussian kernel from distances\n",
    "    spatial_kernel = tf.exp(-sq_dist_matrix / (2.0 * sigma**2))\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # Normalize y_true and y_pred to unit vectors along the last dimension\n",
    "        y_true_norm = tf.nn.l2_normalize(y_true, axis=-1)\n",
    "        y_pred_norm = tf.nn.l2_normalize(y_pred, axis=-1)\n",
    "\n",
    "        # Compute cosine similarity for each pair in the batch\n",
    "        cosine_sim = tf.reduce_sum(y_true_norm * y_pred_norm, axis=-1)  # Shape becomes [batch_size, n]\n",
    "\n",
    "        # Expand the spatial kernel and cosine similarity for broadcasting\n",
    "        expanded_spatial_kernel = tf.expand_dims(spatial_kernel, axis=0)  # Shape becomes [1, n, n]\n",
    "        expanded_cosine_sim = tf.expand_dims(cosine_sim, axis=1)  # Shape becomes [batch_size, 1, n]\n",
    "\n",
    "        # Apply spatial kernel\n",
    "        print(expanded_cosine_sim.shape, expanded_spatial_kernel.shape)\n",
    "        weighted_cosine_sim = expanded_cosine_sim * expanded_spatial_kernel\n",
    "        weighted_sum_cosine_sim = tf.reduce_sum(weighted_cosine_sim, axis=-1)  # Sum over last dim (n)\n",
    "        normalization = tf.reduce_sum(expanded_spatial_kernel, axis=-1)  # Sum spatial weights over n\n",
    "\n",
    "        # Calculate final loss by averaging over the batch and inverting the cosine similarity\n",
    "        weighted_cosine_loss = 1 - tf.reduce_mean(weighted_sum_cosine_sim / normalization)\n",
    "\n",
    "        return weighted_cosine_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_lower_triangular(C):\n",
    "    ''' Get the lower triangular part of a matrix C, excluding the diagonal\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    C: np.array\n",
    "        The matrix to extract the lower triangular part from\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array\n",
    "        The lower triangular part of the matrix C, excluding the diagonal\n",
    "    '''\n",
    "    C = np.tril(C, -1)\n",
    "    C = C[np.nonzero(C)]\n",
    "    return C\n",
    "\n",
    "\n",
    "\n",
    "# def custom_loss(distances):\n",
    "#     \"\"\"Closure to encapsulate the distances matrix.\"\"\"\n",
    "#     distances = tf.constant(distances, dtype=tf.float32)\n",
    "#     mean_dist = tf.reduce_mean(distances)\n",
    "\n",
    "#     def loss(y_true, y_pred):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#         y_true: Tensor of true values with shape (batch_size, n).\n",
    "#         y_pred: Tensor of predicted values with shape (batch_size, n).\n",
    "\n",
    "#         Returns:\n",
    "#         A scalar tensor representing the loss.\n",
    "#         \"\"\"\n",
    "#         # Normalize y_true and y_pred so that the maximum of each sample is 1\n",
    "#         max_y_true = tf.reduce_max(y_true, axis=1, keepdims=True)\n",
    "#         max_y_pred = tf.reduce_max(y_pred, axis=1, keepdims=True)\n",
    "#         y_true_scaled = y_true / max_y_true\n",
    "#         y_pred_scaled = y_pred / max_y_pred\n",
    "\n",
    "#         # Compute element-wise absolute differences\n",
    "#         # E = tf.abs(y_true_scaled - y_pred_scaled)  # shape (batch_size, n)\n",
    "#         E = tf.square(y_true_scaled - y_pred_scaled)  # shape (batch_size, n)\n",
    "        \n",
    "#         # Apply the distances weighting in a quadratic form\n",
    "#         # Diag(E) @ distances @ Diag(E)\n",
    "#         # First, compute diag(E) @ distances for each example in the batch\n",
    "#         weighted = tf.linalg.matmul(E, distances)  # shape (batch_size, n)\n",
    "        \n",
    "#         # Then multiply element-wise with E and sum over all elements\n",
    "#         # error = tf.reduce_sum(weighted * E, axis=1)  # sum across each sample, shape (batch_size,)\n",
    "#         error = tf.reduce_mean(weighted * E, axis=1)  # sum across each sample, shape (batch_size,)\n",
    "        \n",
    "#         # Finally, compute the mean over the batch to get a single scalar loss\n",
    "#         return (0.001*tf.reduce_mean(error) / mean_dist) + tf.reduce_mean(E)\n",
    "    \n",
    "#     return loss\n",
    "\n",
    "\n",
    "def custom_loss(distances):\n",
    "    \"\"\"Closure to encapsulate the distances matrix.\"\"\"\n",
    "    distances = tf.constant(distances, dtype=tf.float32)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        y_true: Tensor of true values with shape (batch_size, n).\n",
    "        y_pred: Tensor of predicted values with shape (batch_size, n).\n",
    "\n",
    "        Returns:\n",
    "        A scalar tensor representing the loss.\n",
    "        \"\"\"\n",
    "        # Normalize y_true and y_pred so that the maximum of each sample is 1\n",
    "        # max_y_true = tf.reduce_max(y_true, axis=1, keepdims=True)\n",
    "        # max_y_pred = tf.reduce_max(y_pred, axis=1, keepdims=True)\n",
    "\n",
    "        norm_y_true = tf.norm(y_true, axis=1, keepdims=True)\n",
    "        norm_y_pred = tf.norm(y_pred, axis=1, keepdims=True)\n",
    "\n",
    "        y_true_scaled = y_true / norm_y_true\n",
    "        y_pred_scaled = y_pred / norm_y_pred\n",
    "\n",
    "        # Compute element-wise absolute differences\n",
    "        E = tf.square(y_true_scaled - y_pred_scaled)  # shape (batch_size, n)\n",
    "        \n",
    "        # Apply the distances weighting in a quadratic form\n",
    "        # Diag(E) @ distances @ Diag(E)\n",
    "        # First, compute diag(E) @ distances for each example in the batch\n",
    "        weighted = tf.linalg.matmul(E, distances)  # shape (batch_size, n)\n",
    "        \n",
    "        # Then multiply element-wise with E and sum over all elements\n",
    "        error = tf.reduce_mean(weighted * E, axis=1)  # sum across each sample, shape (batch_size,)\n",
    "        \n",
    "        # Finally, compute the mean over the batch to get a single scalar loss\n",
    "        return tf.reduce_mean(error) #+ tf.reduce_mean(E)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def get_diag_and_lower(matrix):\n",
    "    \"\"\"\n",
    "    This function takes a square matrix and returns a flattened array\n",
    "    containing its diagonal and lower diagonal values.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (np.ndarray): A square matrix.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A flattened array of the diagonal and lower diagonal values.\n",
    "    \"\"\"\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        raise ValueError(\"The input matrix must be square.\")\n",
    "    \n",
    "    diag_and_lower = matrix[np.tril_indices(matrix.shape[0])]\n",
    "    \n",
    "    return diag_and_lower\n",
    "\n",
    "# Define the neural network architecture\n",
    "# input_size = int((n_chans**2-n_chans)/2)\n",
    "# input_shape = (None, input_size,1)  # Specify the input shape based on your data\n",
    "# model = keras.Sequential([\n",
    "#     # layers.Conv2D(n_chans, (1, n_chans), \n",
    "#     #       activation=\"tanh\", padding=\"valid\",\n",
    "#     #       input_shape=input_shape,\n",
    "#     #       name='CNN1'),\n",
    "#     # layers.Flatten(),\n",
    "\n",
    "#     # layers.Dense(input_size, activation='tanh', input_shape=input_shape),\n",
    "#     layers.Conv2D(n_chans*4, (1, input_size), activation='tanh', input_shape=input_shape),\n",
    "#     layers.Dense(100, activation='tanh'),\n",
    "#     # layers.Dense(n_dipoles, activation='linear')\n",
    "#     layers.Dense(n_dipoles, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "input_size = int((n_chans**2 - n_chans) / 2 + n_chans)\n",
    "input_shape = (input_size,)  # Specify the input shape based on your data\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Reshape input to match the expected input for Conv2D\n",
    "    layers.Reshape((1, input_size, 1), input_shape=input_shape),\n",
    "    \n",
    "    # Convolutional layer\n",
    "    layers.Conv2D(128, (1, input_size), activation='relu'),\n",
    "    \n",
    "    # Flatten the output from the Conv2D layer\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # Fully connected layers\n",
    "    layers.Dense(200, activation='relu'),\n",
    "    # Fully connected layers\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    \n",
    "    layers.Dense(n_dipoles, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.build(input_shape=(None, input_size))  # Build the model with the specified input shape\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='cosine_similarity', metrics=['accuracy'])  # Specify the loss function and optimizer\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=custom_loss(distance_matrix), metrics=['cosine_similarity'])  # Specify the loss function and optimizer\n",
    "model.build()\n",
    "model.summary()\n",
    "model.load_weights('.weights.keras')\n",
    "model2 = tf.keras.models.clone_model(model)\n",
    "# model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='cosine_similarity', metrics=['accuracy'])  # Specify the loss function and optimizer\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=custom_loss(distance_matrix), metrics=['cosine_similarity'])  # Specify the loss function and optimizer\n",
    "\n",
    "model2.load_weights('.rap-weights.keras')\n",
    "# model2.load_weights('.rap-weights.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 0.68, 0.09\n",
      "epoch 1 0.65, 0.09\n",
      "epoch 2 0.64, 0.08\n",
      "epoch 3 0.62, 0.08\n",
      "epoch 4 0.61, 0.07\n",
      "epoch 5 0.60, 0.07\n",
      "epoch 6 0.60, 0.07\n",
      "epoch 7 0.59, 0.07\n",
      "epoch 8 0.58, 0.06\n",
      "epoch 9 0.58, 0.06\n",
      "epoch 10 0.57, 0.06\n",
      "epoch 11 0.57, 0.06\n",
      "epoch 12 0.56, 0.07\n",
      "epoch 13 0.56, 0.07\n",
      "epoch 14 0.55, 0.07\n",
      "epoch 15 0.55, 0.07\n",
      "epoch 16 0.54, 0.07\n",
      "epoch 17 0.54, 0.07\n",
      "epoch 18 0.53, 0.08\n",
      "epoch 19 0.53, 0.08\n",
      "epoch 20 0.52, 0.08\n",
      "epoch 21 0.52, 0.09\n",
      "epoch 22 0.51, 0.09\n",
      "epoch 23 0.51, 0.10\n",
      "epoch 24 0.50, 0.11\n",
      "epoch 25 0.49, 0.11\n",
      "epoch 26 0.49, 0.12\n",
      "epoch 27 0.48, 0.13\n",
      "epoch 28 0.47, 0.14\n",
      "epoch 29 0.47, 0.14\n",
      "epoch 30 0.46, 0.15\n",
      "epoch 31 0.46, 0.16\n",
      "epoch 32 0.45, 0.16\n",
      "epoch 33 0.45, 0.17\n",
      "epoch 34 0.44, 0.17\n",
      "epoch 35 0.44, 0.18\n",
      "epoch 36 0.43, 0.19\n",
      "epoch 37 0.43, 0.19\n",
      "epoch 38 0.42, 0.20\n",
      "epoch 39 0.42, 0.20\n",
      "epoch 40 0.41, 0.21\n",
      "epoch 41 0.41, 0.21\n",
      "epoch 42 0.41, 0.22\n",
      "epoch 43 0.40, 0.22\n",
      "epoch 44 0.40, 0.23\n",
      "epoch 45 0.39, 0.23\n",
      "epoch 46 0.39, 0.24\n",
      "epoch 47 0.39, 0.24\n",
      "epoch 48 0.38, 0.25\n",
      "epoch 49 0.38, 0.25\n",
      "epoch 50 0.38, 0.26\n",
      "epoch 51 0.37, 0.26\n",
      "epoch 52 0.37, 0.27\n",
      "epoch 53 0.37, 0.27\n",
      "epoch 54 0.37, 0.27\n",
      "epoch 55 0.36, 0.28\n",
      "epoch 56 0.36, 0.28\n",
      "epoch 57 0.36, 0.28\n",
      "epoch 58 0.35, 0.29\n",
      "epoch 59 0.35, 0.29\n",
      "epoch 60 0.35, 0.29\n",
      "epoch 61 0.35, 0.30\n",
      "epoch 62 0.34, 0.30\n",
      "epoch 63 0.34, 0.30\n",
      "epoch 64 0.34, 0.31\n",
      "epoch 65 0.34, 0.31\n",
      "epoch 66 0.34, 0.31\n",
      "epoch 67 0.33, 0.32\n",
      "epoch 68 0.33, 0.32\n",
      "epoch 69 0.33, 0.32\n",
      "epoch 70 0.33, 0.32\n",
      "epoch 71 0.32, 0.33\n",
      "epoch 72 0.32, 0.33\n",
      "epoch 73 0.32, 0.33\n",
      "epoch 74 0.32, 0.34\n",
      "epoch 75 0.32, 0.34\n",
      "epoch 76 0.32, 0.34\n",
      "epoch 77 0.31, 0.34\n",
      "epoch 78 0.31, 0.35\n",
      "epoch 79 0.31, 0.35\n",
      "epoch 80 0.31, 0.35\n",
      "epoch 81 0.31, 0.35\n",
      "epoch 82 0.31, 0.35\n",
      "epoch 83 0.30, 0.36\n",
      "epoch 84 0.30, 0.36\n",
      "epoch 85 0.30, 0.36\n",
      "epoch 86 0.30, 0.36\n",
      "epoch 87 0.30, 0.36\n",
      "epoch 88 0.30, 0.37\n",
      "epoch 89 0.30, 0.37\n",
      "epoch 90 0.29, 0.37\n",
      "epoch 91 0.29, 0.37\n",
      "epoch 92 0.29, 0.37\n",
      "epoch 93 0.29, 0.38\n",
      "epoch 94 0.29, 0.38\n",
      "epoch 95 0.29, 0.38\n",
      "epoch 96 0.29, 0.38\n",
      "epoch 97 0.28, 0.38\n",
      "epoch 98 0.28, 0.38\n",
      "epoch 99 0.28, 0.39\n",
      "epoch 100 0.28, 0.39\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(np.where(y_true[0])[0])\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):  \n\u001b[1;32m---> 14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcovs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# print(f\"epoch {i}.{j} {loss[0]:.2f}, {loss[1]:.2f}\")\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:540\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 540\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[0;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:239\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    230\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[0;32m    231\u001b[0m         args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_cache.py:48\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[1;34m(self, function_type, context)\u001b[0m\n\u001b[0;32m     46\u001b[0m context \u001b[38;5;241m=\u001b[39m context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict:\n\u001b[1;32m---> 48\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary[(context, dispatch_type)]\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\type_dispatch.py:92\u001b[0m, in \u001b[0;36mTypeDispatchTable.dispatch\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     89\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m     91\u001b[0m most_specific_supertype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_table:\n\u001b[0;32m     93\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mis_supertype_of(other):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m most_specific_supertype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m other\u001b[38;5;241m.\u001b[39mis_supertype_of(\n\u001b[0;32m     95\u001b[0m         most_specific_supertype):\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:452\u001b[0m, in \u001b[0;36mFunctionType.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, FunctionType):\n\u001b[0;32m    450\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:150\u001b[0m, in \u001b[0;36mParameter.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Parameter):\n\u001b[0;32m    148\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\core\\function\\trace_type\\default_types.py:181\u001b[0m, in \u001b[0;36mWeakref.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    177\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m    179\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    182\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, trace\u001b[38;5;241m.\u001b[39mTraceType):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "sim_params_temp = deepcopy(sim_params)\n",
    "sim_params_temp[\"batch_size\"] = 1284#*5\n",
    "sim_params_temp[\"n_sources\"] = (1,5)\n",
    "sim_params_temp[\"n_orders\"] = 0#(1, 3)\n",
    "gen = generator(fwd, **sim_params_temp)\n",
    "for i in range(300):\n",
    "    X, y, _ = gen.__next__()\n",
    "    covs = [get_diag_and_lower(xx.T@xx) for xx in X]\n",
    "    covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "    y_true = np.stack([(yy!=0)[0,:].astype(float) for yy in y], axis=0).astype(float)\n",
    "    # print(np.where(y_true[0])[0])\n",
    "    for j in range(10):  \n",
    "        loss = model.train_on_batch(covs, y_true)\n",
    "        # print(f\"epoch {i}.{j} {loss[0]:.2f}, {loss[1]:.2f}\")\n",
    "    print(f\"epoch {i} {loss[0]:.2f}, {loss[1]:.2f}\")\n",
    "    # model.save('.weights.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - fixed number of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "gen = generator(fwd, **sim_params)\n",
    "\n",
    "epochs = 300\n",
    "epoch_distances = np.zeros(epochs)\n",
    "# Training loop within the RAP-MUSIC framework\n",
    "for epoch in range(epochs):  # Number of epochs\n",
    "    current_data, true_dipoles, Y = generate_initial_data(gen) \n",
    "    n_samples = len(true_dipoles)\n",
    "    estimated_dipole_idc = [list() for _ in range(n_samples)]\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    for i_iter in range(sim_params[\"n_sources\"]):\n",
    "        # Compute Covariances\n",
    "        current_covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "        current_covs = np.stack([cov/abs(cov).max() for cov in current_covs], axis=0)\n",
    "        \n",
    "        # Predict the sources using the model\n",
    "        estimated_sources = predict(model, current_covs)\n",
    "\n",
    "        # Check stopping criterion\n",
    "        # criterion = estimated_sources.max(axis=1) > 0.5  # Threshold for stopping (arbitrary value\n",
    "        # if criterion:\n",
    "        #     break\n",
    "        estimated_sources_temp = estimated_sources.copy()\n",
    "        for i_sample in range(n_samples):\n",
    "            estimated_sources_temp[i_sample, estimated_dipole_idc[i_sample]] = 0\n",
    "\n",
    "        new_dipole_idc = np.argmax(estimated_sources_temp, axis=1)  # Convert to dipole indices\n",
    "        \n",
    "        for i_idx, new_idx in enumerate(new_dipole_idc):\n",
    "            estimated_dipole_idc[i_idx].append(new_idx)\n",
    "\n",
    "        true_data_matched = np.zeros((n_samples, n_dipoles))\n",
    "        avg_dists = []\n",
    "        for i_sample in range(n_samples):\n",
    "            true_data_matched[i_sample, true_dipoles[i_sample]] = 1\n",
    "            estimated_positions = pos[np.array(estimated_dipole_idc[i_sample])]\n",
    "            true_positions = pos[true_dipoles[i_sample]]\n",
    "            pairwise_dist = cdist(true_positions, estimated_positions)\n",
    "            # select the true positions closest to the estimated ones\n",
    "            true_indices, estimated_indices = linear_sum_assignment(pairwise_dist)\n",
    "            avg_dists.append(pairwise_dist[true_indices, estimated_indices].min(axis=-1).mean())\n",
    "        print(\"average distances: \", round(np.mean(avg_dists), 2))\n",
    "        epoch_distances[epoch] = np.mean(avg_dists)\n",
    "\n",
    "        # Adjust parameters\n",
    "        loss = model.train_on_batch(current_covs, true_data_matched)\n",
    "        print(f\"\\tLoss: {np.mean(loss)}\")\n",
    "\n",
    "        # Outproject the dipoles from the respective data\n",
    "        current_data = wrap_outproject_from_data(current_data, leadfield, estimated_dipole_idc)\n",
    "        # print(f\"\\tResidual: {compute_residual(current_data, new_data)}\")\n",
    "# Save the model\n",
    "model.save('rap_music_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - progressing number of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "\t\tLoss: 0.698, 0.104\n",
      "\t\tLoss: 0.698, 0.104\n",
      "\t\tLoss: 0.697, 0.105\n",
      "\t\tLoss: 0.696, 0.105\n",
      "\t\tLoss: 0.695, 0.105\n",
      "\t\tLoss: 0.694, 0.105\n",
      "\t\tLoss: 0.692, 0.105\n",
      "\t\tLoss: 0.691, 0.105\n",
      "\t\tLoss: 0.689, 0.105\n",
      "\t\tLoss: 0.687, 0.105\n",
      "epoch 1\n",
      "\t\tLoss: 0.685, 0.105\n",
      "\t\tLoss: 0.683, 0.105\n",
      "\t\tLoss: 0.681, 0.105\n",
      "\t\tLoss: 0.679, 0.104\n",
      "\t\tLoss: 0.677, 0.104\n",
      "\t\tLoss: 0.675, 0.103\n",
      "\t\tLoss: 0.673, 0.103\n",
      "\t\tLoss: 0.671, 0.102\n",
      "\t\tLoss: 0.669, 0.102\n",
      "\t\tLoss: 0.667, 0.101\n",
      "epoch 2\n",
      "\t\tLoss: 0.665, 0.101\n",
      "\t\tLoss: 0.663, 0.100\n",
      "\t\tLoss: 0.662, 0.099\n",
      "\t\tLoss: 0.660, 0.098\n",
      "\t\tLoss: 0.659, 0.098\n",
      "\t\tLoss: 0.657, 0.097\n",
      "\t\tLoss: 0.656, 0.096\n",
      "\t\tLoss: 0.654, 0.096\n",
      "\t\tLoss: 0.653, 0.095\n",
      "\t\tLoss: 0.652, 0.094\n",
      "epoch 3\n",
      "\t\tLoss: 0.651, 0.094\n",
      "\t\tLoss: 0.650, 0.093\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from copy import deepcopy\n",
    "\n",
    "batch_size = 1024 // 5\n",
    "n_sources = np.arange(5)+1\n",
    "\n",
    "epochs = 300\n",
    "epoch_distances = np.zeros(epochs)\n",
    "# Training loop within the RAP-MUSIC framework\n",
    "for epoch in np.arange(0, 100).astype(int):  # Number of epochs\n",
    "    print(f\"epoch {epoch}\")\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for n_source in n_sources:\n",
    "        # print(f\"\\ttraining for {n_source} sources\")\n",
    "        sim_params[\"batch_size\"] = batch_size #// n_source\n",
    "        sim_params[\"n_sources\"] = (n_source, n_source)\n",
    "        gen = generator(fwd, **sim_params)\n",
    "        X, true_dipoles, Y = generate_initial_data(gen) \n",
    "        current_data = deepcopy(X)\n",
    "        n_samples = len(true_dipoles)\n",
    "        estimated_dipole_idc = [list() for _ in range(n_samples)]\n",
    "\n",
    "        for i_iter in range(n_source):\n",
    "            # Compute Covariances\n",
    "            current_covs = [get_diag_and_lower(xx@xx.T) for xx in current_data]\n",
    "            current_covs = np.stack([cov/abs(cov).max() for cov in current_covs], axis=0)\n",
    "            X_train.append(current_covs)\n",
    "            # Predict the sources using the model\n",
    "            estimated_sources = model2.predict(current_covs, verbose=0)\n",
    "\n",
    "            estimated_sources_temp = estimated_sources.copy()\n",
    "            for i_sample in range(n_samples):\n",
    "                estimated_sources_temp[i_sample, estimated_dipole_idc[i_sample]] = 0\n",
    "\n",
    "            new_dipole_idc = np.argmax(estimated_sources_temp, axis=1)  # Convert to dipole indices\n",
    "            \n",
    "            for i_idx, new_idx in enumerate(new_dipole_idc):\n",
    "                estimated_dipole_idc[i_idx].append(new_idx)\n",
    "            \n",
    "            Y_train.append((Y!=0).astype(int)[:, :, 0])\n",
    "            # Outproject the dipoles from the respective data\n",
    "            current_data = wrap_outproject_from_data(X, leadfield, estimated_dipole_idc, alpha=0)\n",
    "            \n",
    "    # Adjust parameters\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    Y_train = np.concatenate(Y_train, axis=0)\n",
    "    # print(model2.test_on_batch(X_train, Y_train))\n",
    "    for _ in range(10):\n",
    "        loss = model2.train_on_batch(X_train, Y_train)\n",
    "        print(f\"\\t\\tLoss: {np.mean(loss[0]):.3f}, {np.mean(loss[1]):.3f}\")\n",
    "\n",
    "    # Save the model\n",
    "    model2.save('.rap-weights.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - variable number of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "gen = generator(fwd, **sim_params)\n",
    "\n",
    "epochs = 50\n",
    "samples_per_epoch = 64\n",
    "n_train_cycles = 300\n",
    "\n",
    "# Training loop within the RAP-MUSIC framework\n",
    "for epoch in range(epochs):  # Number of epochs\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    # epoch_distances = np.zeros(samples_per_epoch)\n",
    "    for ii in range(samples_per_epoch):\n",
    "        print(f\"\\tsample {ii+1}/{samples_per_epoch}\")\n",
    "        current_data, true_dipoles, Y = generate_initial_data(gen)\n",
    "        n_samples = len(true_dipoles)\n",
    "        n_candidates = len(true_dipoles[0])\n",
    "        estimated_dipole_idc = [list() for _ in range(n_samples)]\n",
    "        \n",
    "        for n_candidate in range(n_candidates):\n",
    "            # print(f\"\\t\\tDipole {n_candidate+1}/{n_candidates}\")\n",
    "            # Compute Covariances\n",
    "            current_covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "            current_covs = np.stack([cov/abs(cov).max() for cov in current_covs], axis=0)\n",
    "            \n",
    "            # Predict the sources using the model\n",
    "            estimated_sources = model.predict(current_covs, verbose=0)  # Model's prediction\n",
    "            X_train.append(current_covs)\n",
    "\n",
    "            # Check stopping criterion\n",
    "            # criterion = estimated_sources.max(axis=1) > 0.5  # Threshold for stopping (arbitrary value\n",
    "            # if criterion:\n",
    "            #     break\n",
    "            estimated_sources_temp = estimated_sources.copy()\n",
    "            for i_sample in range(n_samples):\n",
    "                estimated_sources_temp[i_sample, estimated_dipole_idc[i_sample]] = 0\n",
    "\n",
    "            new_dipole_idc = np.argmax(estimated_sources_temp, axis=1)  # Convert to dipole indices\n",
    "            \n",
    "            for i_idx, new_idx in enumerate(new_dipole_idc):\n",
    "                estimated_dipole_idc[i_idx].append(new_idx)\n",
    "\n",
    "            true_data_matched = np.zeros((n_samples, n_dipoles))\n",
    "            avg_dists = []\n",
    "            for i_sample in range(n_samples):\n",
    "                true_data_matched[i_sample, true_dipoles[i_sample]] = 1\n",
    "                # estimated_positions = pos[np.array(estimated_dipole_idc[i_sample])]\n",
    "                # true_positions = pos[true_dipoles[i_sample]]\n",
    "                # pairwise_dist = cdist(true_positions, estimated_positions)\n",
    "                # # select the true positions closest to the estimated ones\n",
    "                # true_indices, estimated_indices = linear_sum_assignment(pairwise_dist)\n",
    "                # avg_dists.append(pairwise_dist[true_indices, estimated_indices].min(axis=-1).mean())\n",
    "            # print(\"average distances: \", round(np.mean(avg_dists), 2))\n",
    "            # epoch_distances[epoch] = np.mean(avg_dists)\n",
    "            Y_train.append(true_data_matched)\n",
    "            \n",
    "            # Outproject the dipoles from the respective data\n",
    "            current_data = wrap_outproject_from_data(current_data, leadfield, estimated_dipole_idc)\n",
    "\n",
    "    # Adjust parameters\n",
    "    # Training on the past iterations\n",
    "    for _ in range(n_train_cycles):\n",
    "        loss = model.train_on_batch(np.concatenate(X_train, axis=0), np.concatenate(Y_train, axis=0))\n",
    "        print(f\"\\t\\t\\tLoss: {np.mean(loss)}\")\n",
    "            \n",
    "\n",
    "# Save the model\n",
    "# model.save('rap_music_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "MLE: 0.00 mm\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from copy import deepcopy\n",
    "sim_params_temp = deepcopy(sim_params)\n",
    "sim_params_temp[\"batch_size\"] = 1\n",
    "sim_params_temp[\"n_sources\"] = 2\n",
    "sim_params_temp[\"inter_source_correlation\"] = 0.9\n",
    "\n",
    "# sim_params_temp[\"correlation_mode\"] = None\n",
    "sim_params_temp[\"correlation_mode\"] = \"cholesky\"\n",
    "sim_params_temp[\"noise_color_coeff\"] = 0.5\n",
    "\n",
    "sim_params_temp[\"snr_range\"] = (0, 0)\n",
    "sim_params_temp[\"amplitude_range\"] = (1, 1)\n",
    "\n",
    "sim_params_temp[\"n_orders\"] = 0# (1, 3)\n",
    "\n",
    "idx = 0\n",
    "\n",
    "# gen = generator(fwd, **sim_params_temp)\n",
    "# X, true_indices, Y = generate_initial_data(gen)\n",
    "current_data = deepcopy(X)\n",
    "# Compute Covariances\n",
    "covs = np.stack([get_diag_and_lower(x@x.T) for x in current_data], axis=0)\n",
    "covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "estimated_idc = [np.array([]) for _ in range(len(current_data))]\n",
    "\n",
    "for i_iter in range(sim_params_temp[\"n_sources\"]):\n",
    "    # estimated_sources = model2.predict(covs)\n",
    "    estimated_sources = model.predict(covs)\n",
    "    estimated_sources = np.stack([yy / yy.max() for yy in estimated_sources], axis=0)\n",
    "    estimated_sources_temp = estimated_sources.copy()\n",
    "    for i_sample in range(len(current_data)):\n",
    "        if i_iter > 0:\n",
    "            estimated_sources_temp[i_sample, estimated_idc[i_sample]] = 0\n",
    "        estimated_idc[i_sample] = np.append( estimated_idc[i_sample], np.argmax(estimated_sources_temp[i_sample]) ).astype(int)\n",
    "\n",
    "    \n",
    "\n",
    "    stc_ = mne.SourceEstimate(estimated_sources[idx], vertices, tmin=0, tstep=1/1000, \n",
    "                            subject=\"fsaverage\", verbose=0)\n",
    "    \n",
    "    mne.EvokedArray(current_data[idx], info).plot_topomap()\n",
    "    \n",
    "    brain = stc_.plot(brain_kwargs=dict(title=f\"Est. Source {i_iter+1}\"), **pp)\n",
    "    brain.add_text(0.1, 0.9, f\"Est. Source {i_iter+1}\", 'title',\n",
    "               font_size=14)\n",
    "\n",
    "    # selected_idx = np.argmax(stc_.data[:, 0])\n",
    "    # if pos[selected_idx, 0] < 0:\n",
    "    #     brain.add_foci(selected_idx, hemi=\"lh\", coords_as_verts=True, color=\"blue\", alpha=1)\n",
    "    # else:\n",
    "    #     brain.add_foci(selected_idx, hemi=\"rh\", coords_as_verts=True, color=\"blue\", alpha=1)\n",
    "\n",
    "\n",
    "    current_data = wrap_outproject_from_data(X.copy(), leadfield, estimated_idc, alpha=0)\n",
    "    # estimated_idc_trimmed = [np.array([es[-1],]) for es in estimated_idc]\n",
    "    # current_data = wrap_outproject_from_data(current_data, leadfield, estimated_idc_trimmed)\n",
    "\n",
    "    covs = np.stack([get_diag_and_lower(x@x.T) for x in current_data], axis=0)\n",
    "    covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "\n",
    "estimated_positions = pos[estimated_idc[idx]]\n",
    "true_positions = pos[true_indices[idx]]\n",
    "pairwise_dist = cdist(true_positions, estimated_positions)\n",
    "# select the true positions closest to the estimated ones\n",
    "true_sub_idc, estimated_sub_idc = linear_sum_assignment(pairwise_dist)\n",
    "mle = pairwise_dist[true_sub_idc, estimated_sub_idc].mean()\n",
    "print(f\"MLE: {mle:.2f} mm\")\n",
    "\n",
    "L = leadfield[:, estimated_idc[idx]]\n",
    "gradients = np.zeros((n_dipoles, len(estimated_idc[idx])))\n",
    "for ii, estimated_idx in enumerate(estimated_idc[idx]):\n",
    "    gradients[estimated_idx, ii] = 1\n",
    "Y_est = gradients @ L.T @ np.linalg.pinv(L @ L.T)\n",
    "stc_.data = Y_est\n",
    "brain = stc_.plot(brain_kwargs=dict(title=\"Final Source Estimate\"), **pp)\n",
    "brain.add_text(0.1, 0.9, \"Final Source Estimate\", 'title',\n",
    "               font_size=14)\n",
    "\n",
    "stc_.data = Y[idx]\n",
    "brain = stc_.plot(brain_kwargs=dict(title=\"Ground Truth\"), **pp)\n",
    "brain.add_text(0.1, 0.9, \"Ground Truth\", 'title',\n",
    "               font_size=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invert import Solver\n",
    "n_sources = sim_params_temp[\"n_sources\"]\n",
    "evoked = mne.EvokedArray(X[idx], info)\n",
    "solver = Solver(\"ap\")\n",
    "solver.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=True, n=n_sources, \n",
    "                             k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=10)\n",
    "\n",
    "stc_ = solver.apply_inverse_operator(evoked)\n",
    "# stc_.data /= abs(stc_.data).max()\n",
    "# brain = stc_.plot(**pp)\n",
    "# brain.add_text(0.1, 0.9, solver.name, 'title',\n",
    "#                font_size=14)\n",
    "\n",
    "# evoked_ = mne.EvokedArray(fwd[\"sol\"][\"data\"] @ stc_.data, info).set_eeg_reference(\"average\", projection=True)\n",
    "# evoked_.plot_joint()\n",
    "\n",
    "# print(solver.name, \" r = \", pearsonr(abs(stc.data).mean(axis=-1), abs(stc_.data).mean(axis=-1))[0])\n",
    "\n",
    "mle = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "print(f\"{solver.name}, mle = {mle:.2f} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1\n",
      "Sample 2\n",
      "Sample 3\n",
      "Sample 4\n",
      "Sample 5\n",
      "Sample 6\n",
      "Sample 7\n",
      "Sample 8\n",
      "Sample 9\n",
      "Sample 10\n",
      "Sample 11\n",
      "Sample 12\n",
      "Sample 13\n",
      "Sample 14\n",
      "Sample 15\n",
      "Sample 16\n",
      "Sample 17\n",
      "Sample 18\n",
      "Sample 19\n",
      "Sample 20\n",
      "Sample 21\n",
      "Sample 22\n",
      "Sample 23\n",
      "Sample 24\n",
      "Sample 25\n",
      "Sample 26\n",
      "Sample 27\n",
      "Sample 28\n",
      "Sample 29\n",
      "Sample 30\n",
      "Sample 31\n",
      "Sample 32\n",
      "Sample 33\n",
      "Sample 34\n",
      "Sample 35\n",
      "Sample 36\n",
      "Sample 37\n",
      "Sample 38\n",
      "Sample 39\n",
      "Sample 40\n",
      "Sample 41\n",
      "Sample 42\n",
      "Sample 43\n",
      "Sample 44\n",
      "Sample 45\n",
      "Sample 46\n",
      "Sample 47\n",
      "Sample 48\n",
      "Sample 49\n",
      "Sample 50\n",
      "Sample 51\n",
      "Sample 52\n",
      "Sample 53\n",
      "Sample 54\n",
      "Sample 55\n",
      "Sample 56\n",
      "Sample 57\n",
      "Sample 58\n",
      "Sample 59\n",
      "Sample 60\n",
      "Sample 61\n",
      "Sample 62\n",
      "Sample 63\n",
      "Sample 64\n",
      "Sample 65\n",
      "Sample 66\n",
      "Sample 67\n",
      "Sample 68\n",
      "Sample 69\n",
      "Sample 70\n",
      "Sample 71\n",
      "Sample 72\n",
      "Sample 73\n",
      "Sample 74\n",
      "Sample 75\n",
      "Sample 76\n",
      "Sample 77\n",
      "Sample 78\n",
      "Sample 79\n",
      "Sample 80\n",
      "Sample 81\n",
      "Sample 82\n",
      "Sample 83\n",
      "Sample 84\n",
      "Sample 85\n",
      "Sample 86\n",
      "Sample 87\n",
      "Sample 88\n",
      "Sample 89\n",
      "Sample 90\n",
      "Sample 91\n",
      "Sample 92\n",
      "Sample 93\n",
      "Sample 94\n",
      "Sample 95\n",
      "Sample 96\n",
      "Sample 97\n",
      "Sample 98\n",
      "Sample 99\n",
      "Sample 100\n",
      "Sample 101\n",
      "Sample 102\n",
      "Sample 103\n",
      "Sample 104\n",
      "Sample 105\n",
      "Sample 106\n",
      "Sample 107\n",
      "Sample 108\n",
      "Sample 109\n",
      "Sample 110\n",
      "Sample 111\n",
      "Sample 112\n",
      "Sample 113\n",
      "Sample 114\n",
      "Sample 115\n",
      "Sample 116\n",
      "Sample 117\n",
      "Sample 118\n",
      "Sample 119\n",
      "Sample 120\n",
      "Sample 121\n",
      "Sample 122\n",
      "Sample 123\n",
      "Sample 124\n",
      "Sample 125\n",
      "Sample 126\n",
      "Sample 127\n",
      "Sample 128\n",
      "Sample 129\n",
      "Sample 130\n",
      "Sample 131\n",
      "Sample 132\n",
      "Sample 133\n",
      "Sample 134\n",
      "Sample 135\n",
      "Sample 136\n",
      "Sample 137\n",
      "Sample 138\n",
      "Sample 139\n",
      "Sample 140\n",
      "Sample 141\n",
      "Sample 142\n",
      "Sample 143\n",
      "Sample 144\n",
      "Sample 145\n",
      "Sample 146\n",
      "Sample 147\n",
      "Sample 148\n",
      "Sample 149\n",
      "Sample 150\n",
      "Sample 151\n",
      "Sample 152\n",
      "Sample 153\n",
      "Sample 154\n",
      "Sample 155\n",
      "Sample 156\n",
      "Sample 157\n",
      "Sample 158\n",
      "Sample 159\n",
      "Sample 160\n",
      "Sample 161\n",
      "Sample 162\n",
      "Sample 163\n",
      "Sample 164\n",
      "Sample 165\n",
      "Sample 166\n",
      "Sample 167\n",
      "Sample 168\n",
      "Sample 169\n",
      "Sample 170\n",
      "Sample 171\n",
      "Sample 172\n",
      "Sample 173\n",
      "Sample 174\n",
      "Sample 175\n",
      "Sample 176\n",
      "Sample 177\n",
      "Sample 178\n",
      "Sample 179\n",
      "Sample 180\n",
      "Sample 181\n",
      "Sample 182\n",
      "Sample 183\n",
      "Sample 184\n",
      "Sample 185\n",
      "Sample 186\n",
      "Sample 187\n",
      "Sample 188\n",
      "Sample 189\n",
      "Sample 190\n",
      "Sample 191\n",
      "Sample 192\n",
      "Sample 193\n",
      "Sample 194\n",
      "Sample 195\n",
      "Sample 196\n",
      "Sample 197\n",
      "Sample 198\n",
      "Sample 199\n",
      "Sample 200\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from copy import deepcopy\n",
    "from invert import Solver\n",
    "\n",
    "sim_params_temp = deepcopy(sim_params)\n",
    "sim_params_temp[\"batch_size\"] = 1\n",
    "sim_params_temp[\"n_sources\"] = 2\n",
    "sim_params_temp[\"inter_source_correlation\"] = 0.75\n",
    "sim_params_temp[\"snr_range\"] = (0, 0)\n",
    "sim_params_temp[\"amplitude_range\"] = (1, 1)\n",
    "sim_params_temp[\"n_timepoints\"] = 50\n",
    "sim_params_temp[\"correlation_mode\"] = \"cholesky\"\n",
    "sim_params_temp[\"noise_color_coeff\"] = (0.01, 0.5)\n",
    "# sim_params_temp[\"correlation_mode\"] = None\n",
    "# sim_params_temp[\"noise_color_coeff\"] = 0.0\n",
    "\n",
    "n_repetitions = 200\n",
    "errors = []\n",
    "n_sources = sim_params_temp[\"n_sources\"]\n",
    "solver = Solver(\"ap\")\n",
    "solver_ssm = Solver(\"ssm\")\n",
    "idx = 0\n",
    "for i_samp in range(n_repetitions):\n",
    "    print(f\"Sample {i_samp+1}\")\n",
    "    gen = generator(fwd, **sim_params_temp)\n",
    "    X, true_indices, Y = generate_initial_data(gen)\n",
    "    \n",
    "    current_data = deepcopy(X)\n",
    "    # Compute Covariances\n",
    "    covs = np.stack([get_diag_and_lower(x@x.T) for x in current_data], axis=0)\n",
    "    covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "    estimated_idc = [np.array([]) for _ in range(len(current_data))]\n",
    "\n",
    "    for i_iter in range(sim_params_temp[\"n_sources\"]):\n",
    "        estimated_sources = model.predict(covs, verbose=0)\n",
    "        estimated_sources = np.stack([yy / yy.max() for yy in estimated_sources], axis=0)\n",
    "        estimated_sources_temp = estimated_sources.copy()\n",
    "        for i_sample in range(len(current_data)):\n",
    "            if i_iter > 0:\n",
    "                estimated_sources_temp[i_sample, estimated_idc[i_sample]] = 0\n",
    "            estimated_idc[i_sample] = np.append( estimated_idc[i_sample], np.argmax(estimated_sources_temp[i_sample]) ).astype(int)\n",
    "        source = np.zeros_like(estimated_sources[idx])\n",
    "        source[estimated_idc[idx]] = 1\n",
    "        stc_ = mne.SourceEstimate(source, vertices, tmin=0, tstep=1/1000, \n",
    "                                subject=\"fsaverage\", verbose=0)\n",
    "        # stc_.plot(**pp)\n",
    "        \n",
    "        current_data = wrap_outproject_from_data(X, leadfield, estimated_idc, alpha=1.)\n",
    "        # estimated_idc_trimmed = [np.array([es[-1],]) for es in estimated_idc]\n",
    "        # current_data = wrap_outproject_from_data(current_data, leadfield, estimated_idc_trimmed)\n",
    "\n",
    "        covs = np.stack([get_diag_and_lower(x@x.T) for x in current_data], axis=0)\n",
    "        covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "\n",
    "    # estimated_positions = pos[estimated_idc[idx]]\n",
    "    # true_positions = pos[true_indices[idx]]\n",
    "    # pairwise_dist = cdist(true_positions, estimated_positions)\n",
    "    # # select the true positions closest to the estimated ones\n",
    "    # true_sub_idc, estimated_sub_idc = linear_sum_assignment(pairwise_dist)\n",
    "    mle_cov = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "\n",
    "    error = dict(MLE=mle_cov, method=\"CovCNN\", i_sim=i_samp)\n",
    "    error.update(sim_params_temp)\n",
    "    errors.append(error)\n",
    "\n",
    "    current_data = deepcopy(X)\n",
    "    # Compute Covariances\n",
    "    covs = np.stack([get_diag_and_lower(x@x.T) for x in current_data], axis=0)\n",
    "    covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "    estimated_idc = [np.array([]) for _ in range(len(current_data))]\n",
    "\n",
    "    for i_iter in range(sim_params_temp[\"n_sources\"]):\n",
    "        estimated_sources = model2.predict(covs, verbose=0)\n",
    "        estimated_sources = np.stack([yy / yy.max() for yy in estimated_sources], axis=0)\n",
    "        estimated_sources_temp = estimated_sources.copy()\n",
    "        for i_sample in range(len(current_data)):\n",
    "            if i_iter > 0:\n",
    "                estimated_sources_temp[i_sample, estimated_idc[i_sample]] = 0\n",
    "            estimated_idc[i_sample] = np.append( estimated_idc[i_sample], np.argmax(estimated_sources_temp[i_sample]) ).astype(int)\n",
    "        source = np.zeros_like(estimated_sources[idx])\n",
    "        source[estimated_idc[idx]] = 1\n",
    "        stc_ = mne.SourceEstimate(source, vertices, tmin=0, tstep=1/1000, \n",
    "                                subject=\"fsaverage\", verbose=0)\n",
    "        # stc_.plot(**pp)\n",
    "        \n",
    "        current_data = wrap_outproject_from_data(X, leadfield, estimated_idc, alpha=1.)\n",
    "        # estimated_idc_trimmed = [np.array([es[-1],]) for es in estimated_idc]\n",
    "        # current_data = wrap_outproject_from_data(current_data, leadfield, estimated_idc_trimmed)\n",
    "\n",
    "        covs = np.stack([get_diag_and_lower(x@x.T) for x in current_data], axis=0)\n",
    "        covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "\n",
    "\n",
    "    mle_cov = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    error = dict(MLE=mle_cov, method=\"CovCNN2\", i_sim=i_samp)\n",
    "    error.update(sim_params_temp)\n",
    "    errors.append(error)\n",
    "    evoked = mne.EvokedArray(X[idx], info).set_eeg_reference(\"average\", projection=True, verbose=0).apply_proj(verbose=0)\n",
    "\n",
    "    # AP\n",
    "    solver.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=False, n=n_sources, \n",
    "                             k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=6)\n",
    "    stc_ = solver.apply_inverse_operator(evoked)\n",
    "    mle_ap = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    error = dict(MLE=mle_ap, method=\"AP\", i_sim=i_samp)\n",
    "    error.update(sim_params_temp)\n",
    "    errors.append(error)\n",
    "\n",
    "    # AP refined\n",
    "    solver.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=True, n=n_sources, \n",
    "                             k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=6)\n",
    "    stc_ = solver.apply_inverse_operator(evoked)\n",
    "    mle_ap = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    error = dict(MLE=mle_ap, method=\"AP-refined\", i_sim=i_samp)\n",
    "    error.update(sim_params_temp)\n",
    "    errors.append(error)\n",
    "\n",
    "    # # SSM\n",
    "    # solver_ssm.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=False, n=n_sources, \n",
    "    #                          k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=5)\n",
    "    # stc_ = solver_ssm.apply_inverse_operator(evoked)\n",
    "    # mle_ssm = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    # error = dict(MLE=mle_ssm, method=\"SSM\", i_sim=i_samp)\n",
    "    # error.update(sim_params_temp)\n",
    "    # errors.append(error)\n",
    "\n",
    "    # # SSM refined\n",
    "    # solver_ssm.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=True, n=n_sources, \n",
    "    #                          k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=5)\n",
    "    # stc_ = solver_ssm.apply_inverse_operator(evoked)\n",
    "    # mle_ssm = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    # error = dict(MLE=mle_ssm, method=\"SSM-refined\", i_sim=i_samp)\n",
    "    # error.update(sim_params_temp)\n",
    "    # errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>200.0</td>\n",
       "      <td>19.788046</td>\n",
       "      <td>15.192160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.402744</td>\n",
       "      <td>17.513922</td>\n",
       "      <td>30.285538</td>\n",
       "      <td>68.292397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP-refined</th>\n",
       "      <td>200.0</td>\n",
       "      <td>8.982255</td>\n",
       "      <td>13.883832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.925038</td>\n",
       "      <td>58.525006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CovCNN</th>\n",
       "      <td>200.0</td>\n",
       "      <td>16.875289</td>\n",
       "      <td>14.796841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.272034</td>\n",
       "      <td>26.131984</td>\n",
       "      <td>75.366973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CovCNN2</th>\n",
       "      <td>200.0</td>\n",
       "      <td>16.605202</td>\n",
       "      <td>15.022538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.111201</td>\n",
       "      <td>25.027291</td>\n",
       "      <td>62.050213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count       mean        std  min       25%        50%        75%  \\\n",
       "method                                                                         \n",
       "AP          200.0  19.788046  15.192160  0.0  8.402744  17.513922  30.285538   \n",
       "AP-refined  200.0   8.982255  13.883832  0.0  0.000000   0.000000  14.925038   \n",
       "CovCNN      200.0  16.875289  14.796841  0.0  0.000000  15.272034  26.131984   \n",
       "CovCNN2     200.0  16.605202  15.022538  0.0  0.000000  14.111201  25.027291   \n",
       "\n",
       "                  max  \n",
       "method                 \n",
       "AP          68.292397  \n",
       "AP-refined  58.525006  \n",
       "CovCNN      75.366973  \n",
       "CovCNN2     62.050213  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(errors)\n",
    "for estimator in (np.mean, np.median):\n",
    "    title = f\"\"\"{estimator.__name__} n={sim_params_temp[\"n_sources\"]}, snr={sim_params_temp[\"snr_range\"][0]}, rho={sim_params_temp[\"inter_source_correlation\"]},\\nT={sim_params_temp[\"n_timepoints\"]}, noise={sim_params_temp[\"correlation_mode\"]}\"\"\"\n",
    "    plt.figure()\n",
    "    sns.barplot(data=df, x=\"method\", y=\"MLE\", estimator=estimator)\n",
    "    plt.title(title)\n",
    "    plt.ylim(0, 40)\n",
    "\n",
    "df.groupby(\"method\").describe()[\"MLE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "n_dipoles = 100\n",
    "\n",
    "dists = []\n",
    "errors = []\n",
    "mses = []\n",
    "for _ in range(10000):\n",
    "    pos = np.random.randint(-10, 10, (n_dipoles, 3))\n",
    "    pos = np.sort(pos, axis=0)\n",
    "    distances = cdist(pos, pos)\n",
    "\n",
    "    idc_gt = np.array([1, 3, 5])\n",
    "    X_True = np.zeros(n_dipoles)\n",
    "    X_True[idc_gt] = 1\n",
    "\n",
    "    # idc_est = np.array([1, 3, 6])\n",
    "    idc_est = np.random.randint(0, n_dipoles, 3)\n",
    "    X_Est = np.zeros(n_dipoles)\n",
    "    X_Est[idc_est] = 1\n",
    "\n",
    "    get_euclidean_distance = lambda x, y: np.sqrt(((x - y)**2).sum())\n",
    "\n",
    "    euclidean_distance = get_euclidean_distance(pos[idc_gt], pos[idc_est])\n",
    "    mse = ((X_True - X_Est)**2).mean()\n",
    "    E = abs(X_True - X_Est)\n",
    "    error = np.sum( np.diag(E) @ distances @ np.diag(E) )\n",
    "    # error = np.sum( distances @ np.diag(E) )\n",
    "\n",
    "    errors.append(error)\n",
    "    dists.append(euclidean_distance)\n",
    "    mses.append(mse)\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "print(pearsonr(errors, dists))\n",
    "print(pearsonr(errors, mses))\n",
    "print(pearsonr(dists, mses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.diag(E) @ distances @ np.diag(E))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4174609413959075\n",
      "41.746094139590745\n",
      "4.1746097\n"
     ]
    }
   ],
   "source": [
    "def single_loss(y_true: np.array, y_pred: np.array, distances: np.array):\n",
    "    y_true /= y_true.max()\n",
    "    y_pred /= y_pred.max()\n",
    "\n",
    "    E = (y_true - y_pred)**2\n",
    "    error = np.mean( np.diag(E) @ distances @ np.diag(E) )\n",
    "    return error\n",
    "    \n",
    "\n",
    "\n",
    "# def custom_loss(distances):\n",
    "    \n",
    "#     distances = tf.constant(distances, dtype=tf.float32)\n",
    "\n",
    "#     def loss(y_true, y_pred):\n",
    "#         # Normalize predictions and labels\n",
    "#         y_true_normalized = y_true / tf.reduce_max(y_true)\n",
    "#         y_pred_normalized = y_pred / tf.reduce_max(y_pred)\n",
    "\n",
    "#         # Calculate squared error\n",
    "#         E = tf.square(y_true_normalized - y_pred_normalized)\n",
    "\n",
    "#         # Compute the error using the distance matrix\n",
    "#         # Assuming `distances` is a constant tensor that has been defined outside\n",
    "#         weighted_error = tf.linalg.diag(E) @ distances @ tf.linalg.diag(E)\n",
    "#         mean_error = tf.reduce_mean(weighted_error)\n",
    "\n",
    "#         return mean_error\n",
    "    \n",
    "    \n",
    "#     def wrap_loss(y_true, y_pred):\n",
    "#         # y_true = tf.constant(y_true, dtype=tf.float32)\n",
    "#         # y_pred = tf.constant(y_pred, dtype=tf.float32)\n",
    "#         # errors = tf.map_fn(lambda x1,x2: loss(x1,x2), (y_true, y_pred))\n",
    "#         errors = tf.map_fn(lambda x: \n",
    "#                            loss(x[0], x[1]),\n",
    "#                             (y_true, y_pred),\n",
    "#                             dtype=tf.float32)\n",
    "#         return tf.reduce_mean(errors)\n",
    "\n",
    "#     return wrap_loss\n",
    "\n",
    "def custom_loss(distances):\n",
    "    \"\"\"Closure to encapsulate the distances matrix.\"\"\"\n",
    "    distances = tf.constant(distances, dtype=tf.float32)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        y_true: Tensor of true values with shape (batch_size, n).\n",
    "        y_pred: Tensor of predicted values with shape (batch_size, n).\n",
    "\n",
    "        Returns:\n",
    "        A scalar tensor representing the loss.\n",
    "        \"\"\"\n",
    "        # Normalize y_true and y_pred so that the maximum of each sample is 1\n",
    "        max_y_true = tf.reduce_max(y_true, axis=1, keepdims=True)\n",
    "        max_y_pred = tf.reduce_max(y_pred, axis=1, keepdims=True)\n",
    "        y_true_scaled = y_true / max_y_true\n",
    "        y_pred_scaled = y_pred / max_y_pred\n",
    "\n",
    "        # Compute element-wise absolute differences\n",
    "        E = tf.square(y_true_scaled - y_pred_scaled)  # shape (batch_size, n)\n",
    "        \n",
    "        # Apply the distances weighting in a quadratic form\n",
    "        # Diag(E) @ distances @ Diag(E)\n",
    "        # First, compute diag(E) @ distances for each example in the batch\n",
    "        weighted = tf.linalg.matmul(E, distances)  # shape (batch_size, n)\n",
    "        \n",
    "        # Then multiply element-wise with E and sum over all elements\n",
    "        error = tf.reduce_mean(weighted * E, axis=1)  # sum across each sample, shape (batch_size,)\n",
    "        \n",
    "        # Finally, compute the mean over the batch to get a single scalar loss\n",
    "        return tf.reduce_mean(error)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "n_dipoles = 10\n",
    "batch_size = 32\n",
    "\n",
    "pos = np.random.randint(-10, 10, (n_dipoles, 3))\n",
    "distances = cdist(pos, pos)\n",
    "Y_true = np.random.rand(batch_size, n_dipoles).astype(np.float32)\n",
    "Y_pred = np.random.rand(batch_size, n_dipoles).astype(np.float32)\n",
    "\n",
    "# loss(y_true, y_pred, distances)\n",
    "loss_values = []\n",
    "for y_true, y_pred in zip(Y_true, Y_pred):\n",
    "    loss_value = single_loss(y_true.copy(), y_pred.copy(), distances)\n",
    "    loss_values.append(loss_value)\n",
    "\n",
    "print(np.mean(loss_values))\n",
    "\n",
    "print(loss_batch(Y_true, Y_pred, distances))\n",
    "print(custom_loss(distances)(Y_true, Y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([0.33151948, 1.3343446 , 0.44019866, 0.27137184, 0.9453046 ,\n",
       "       0.39746952, 0.8163638 , 0.5956382 , 0.10287427, 0.6663029 ,\n",
       "       0.18912897, 0.43097982, 0.12820558, 0.50591487, 0.3866617 ,\n",
       "       0.36399338, 0.62589973, 0.21296214, 0.31961787, 0.2665819 ,\n",
       "       0.67624503, 0.11978657, 0.4011897 , 0.12013169, 0.07625904,\n",
       "       0.7434409 , 0.6922216 , 0.09477747, 0.3204877 , 0.12135329,\n",
       "       0.12599353, 0.22905941], dtype=float32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_loss(distances)(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26166277025776163\n",
      "0.26166277025776163\n"
     ]
    }
   ],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    # Normalize predictions and labels\n",
    "    y_true_normalized = y_true / tf.reduce_max(y_true, axis=0)\n",
    "    y_pred_normalized = y_pred / tf.reduce_max(y_pred, axis=0)\n",
    "\n",
    "    # Calculate squared error\n",
    "    E = tf.square(y_true_normalized - y_pred_normalized)\n",
    "\n",
    "    # Compute the error using the distance matrix\n",
    "    # Assuming `distances` is a constant tensor that has been defined outside\n",
    "    weighted_error = tf.linalg.diag(E) @ distances @ tf.linalg.diag(E)\n",
    "    mean_error = tf.reduce_mean(weighted_error)\n",
    "\n",
    "    return mean_error\n",
    "\n",
    "n_dipoles = 100\n",
    "batch_size = 32\n",
    "\n",
    "pos = np.random.randint(-10, 10, (n_dipoles, 3))\n",
    "distances = cdist(pos, pos)\n",
    "Y_true = np.random.rand( 100)\n",
    "Y_pred = np.random.rand( 100)\n",
    "print(loss(Y_true, Y_pred).numpy())\n",
    "print(single_loss(Y_true, Y_pred, distances))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esienv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
