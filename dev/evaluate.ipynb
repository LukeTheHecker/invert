{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    2.3s remaining:    3.9s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    2.3s remaining:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi64')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "n_chans, n_dipoles = leadfield.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]c:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\esinet\\simulation.py:387: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.simulation_info = self.simulation_info.append(d, ignore_index=True)\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.91it/s]c:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\esinet\\simulation.py:387: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.simulation_info = self.simulation_info.append(d, ignore_index=True)\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.79it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 10) (1284, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 667.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyvistaqt 3d backend.\n",
      "\n",
      "Using control points [1.78290634e-08 2.84350922e-08 5.15943702e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    }
   ],
   "source": [
    "settings = dict(number_of_sources=3, extents=(25, 40), duration_of_trial=0.01, target_snr=25)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 332.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 1000) (1284, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNE\n",
      "wMNE\n",
      "dSPM\n",
      "alpha must be set to a float when using Dynamic Statistical Parametric Mapping, auto does not work yet.\n",
      "LORETA\n"
     ]
    }
   ],
   "source": [
    "from invert import Solver\n",
    "from invert.config import all_solvers\n",
    "from invert.evaluate import nmse, corr\n",
    "from invert.adapters import contextualize_bd\n",
    "import pickle as pkl\n",
    "\n",
    "if \"LUCAS\" in all_solvers:\n",
    "    all_solvers.remove(\"LUCAS\")\n",
    "\n",
    "settings = dict(number_of_sources=(1,10), extents=(1, 40), duration_of_trial=1, target_snr=(1,25))\n",
    "errors = {sname: [] for sname in all_solvers}\n",
    "solvers = dict()\n",
    "\n",
    "for i in range(200):\n",
    "    # print(i)\n",
    "    sim = Simulation(fwd, info, settings).simulate(2)\n",
    "    stc = sim.source_data[0]\n",
    "    evoked = sim.eeg_data[0].average()\n",
    "\n",
    "    for solver_name in all_solvers:\n",
    "        print(solver_name)\n",
    "        solver = Solver(solver=solver_name)\n",
    "        if (not solver_name in solvers) or (\"sparse\" in solver_name.lower() or \"bayes\" in solver_name.lower()):\n",
    "            solvers[solver_name] = solver.make_inverse_operator(fwd, evoked, alpha=\"auto\")\n",
    "        stc_hat = solvers[solver_name].apply_inverse_operator(evoked)\n",
    "        # stc_hat.plot(**pp, brain_kwargs=dict(title=solver.name))\n",
    "        error = np.mean(corr(stc.data, stc_hat.data))\n",
    "        errors[solver_name].append( error )\n",
    "        \n",
    "        solver_name = \"c\" + solver_name\n",
    "        if not solver_name in errors:\n",
    "            errors[solver_name] = []\n",
    "        stc_hat = contextualize_bd(stc_hat, fwd, fast=True)\n",
    "        error = np.mean(corr(stc.data, stc_hat.data))\n",
    "        \n",
    "        errors[solver_name].append( error )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fn = \"errors.pkl\"\n",
    "    with open(fn, 'wb') as f:\n",
    "        pkl.dump(errors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MNE',\n",
       " 'wMNE',\n",
       " 'dSPM',\n",
       " 'LORETA',\n",
       " 'sLORETA',\n",
       " 'eLORETA',\n",
       " 'LAURA',\n",
       " 'Backus-Gilbert',\n",
       " 'S-MAP',\n",
       " 'Multiple Sparse Priors',\n",
       " 'Bayesian LORETA',\n",
       " 'Bayesian MNE',\n",
       " 'Bayesian Beamformer',\n",
       " 'Bayesian Beamformer LORETA',\n",
       " 'Fully-Connected']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=0.8)\n",
    "df = pd.DataFrame(errors)\n",
    "sorted_index = df.median().sort_values().index\n",
    "df = df[sorted_index]\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(data=df)\n",
    "plt.title(\"Correlation with ground truth\")\n",
    "\n",
    "\n",
    "df_mean_var = pd.concat([df.mean(), df.std()], axis=1)\n",
    "df_mean_var = df_mean_var.rename(columns={0: \"Median\", 1: \"Variance\"})\n",
    "df_mean_var[\"MedVar\"] = df_mean_var[\"Median\"] / df_mean_var[\"Variance\"]\n",
    "df_mean_var[\"Method\"] = df_mean_var.index\n",
    "display(df_mean_var)\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(x=\"Median\", y=\"Variance\", hue=\"Method\", size=\"MedVar\", data=df_mean_var)\n",
    "plt.xlabel(\"Median\")\n",
    "plt.ylabel(\"Variance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.minimum_norm import make_inverse_operator as mne_inverse\n",
    "from mne.minimum_norm import apply_inverse as mne_apply\n",
    "from mne import make_ad_hoc_cov\n",
    "noise_cov = make_ad_hoc_cov(evoked.info, verbose=0)\n",
    "mne_io = mne_inverse(evoked.info, fwd, noise_cov=noise_cov, fixed=True, loose=0, depth=0, verbose=0)\n",
    "stc_hat = mne_apply(evoked, mne_io, method=\"MNE\", verbose=0)\n",
    "stc_hat.plot(**pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('invertenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda1e5657e486f74a7b39841fb8103db2af51a77394f44c39a7821a371af47bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
