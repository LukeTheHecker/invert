{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    2.1s remaining:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    2.1s remaining:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi64')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "n_chans, n_dipoles = leadfield.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]c:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\esinet\\simulation.py:387: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.simulation_info = self.simulation_info.append(d, ignore_index=True)\n",
      " 50%|█████     | 1/2 [00:00<00:00,  2.45it/s]c:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\esinet\\simulation.py:387: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.simulation_info = self.simulation_info.append(d, ignore_index=True)\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.83it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 10) (1284, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 664.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyvistaqt 3d backend.\n",
      "\n",
      "Using control points [1.22247783e-08 2.38480528e-08 6.58575229e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    }
   ],
   "source": [
    "settings = dict(number_of_sources=3, extents=(25, 40), duration_of_trial=0.01, target_snr=25)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 111.08it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 400.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 1000) (1284, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNE\n",
      "wMNE\n",
      "dSPM\n",
      "alpha must be set to a float when using Dynamic Statistical Parametric Mapping, auto does not work yet.\n",
      "LORETA\n",
      "sLORETA\n",
      "eLORETA\n"
     ]
    }
   ],
   "source": [
    "from invert import Solver\n",
    "from invert.config import all_solvers\n",
    "from invert.evaluate import nmse, corr\n",
    "from invert.adapters import contextualize_bd\n",
    "import pickle as pkl\n",
    "\n",
    "if \"LUCAS\" in all_solvers:\n",
    "    all_solvers.remove(\"LUCAS\")\n",
    "\n",
    "settings = dict(number_of_sources=(1,10), extents=(1, 40), duration_of_trial=1, target_snr=(1,25))\n",
    "errors = {sname: [] for sname in all_solvers}\n",
    "solvers = dict()\n",
    "\n",
    "for i in range(200):\n",
    "    # print(i)\n",
    "    sim = Simulation(fwd, info, settings).simulate(2)\n",
    "    stc = sim.source_data[0]\n",
    "    evoked = sim.eeg_data[0].average()\n",
    "\n",
    "    for solver_name in all_solvers:\n",
    "        print(solver_name)\n",
    "        solver = Solver(solver=solver_name)\n",
    "        if (not solver_name in solvers) or (\"sparse\" in solver_name.lower() or \"bayes\" in solver_name.lower()):\n",
    "            solvers[solver_name] = solver.make_inverse_operator(fwd, evoked, alpha=\"auto\")\n",
    "        stc_hat = solvers[solver_name].apply_inverse_operator(evoked)\n",
    "        # stc_hat.plot(**pp, brain_kwargs=dict(title=solver.name))\n",
    "        error = np.mean(corr(stc.data, stc_hat.data))\n",
    "        errors[solver_name].append( error )\n",
    "        \n",
    "        solver_name = \"c\" + solver_name\n",
    "        if not solver_name in errors:\n",
    "            errors[solver_name] = []\n",
    "        stc_hat = contextualize_bd(stc_hat, fwd, fast=True)\n",
    "        error = np.mean(corr(stc.data, stc_hat.data))\n",
    "        \n",
    "        errors[solver_name].append( error )\n",
    "\n",
    "\n",
    "\n",
    "    if i > 22:\n",
    "        fn = \"errors.pkl\"\n",
    "        with open(fn, 'wb') as f:\n",
    "            pkl.dump(errors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "fn = \"errors.pkl\"\n",
    "with open(fn, 'rb') as f:\n",
    "    errors = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>MedVar</th>\n",
       "      <th>Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cBayesian Beamformer</th>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>0.083097</td>\n",
       "      <td>cBayesian Beamformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Beamformer</th>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.053111</td>\n",
       "      <td>0.041083</td>\n",
       "      <td>Bayesian Beamformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cBackus-Gilbert</th>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.115713</td>\n",
       "      <td>0.381973</td>\n",
       "      <td>cBackus-Gilbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backus-Gilbert</th>\n",
       "      <td>0.035868</td>\n",
       "      <td>0.094927</td>\n",
       "      <td>0.377851</td>\n",
       "      <td>Backus-Gilbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cBayesian LORETA</th>\n",
       "      <td>0.077309</td>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.939014</td>\n",
       "      <td>cBayesian LORETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian LORETA</th>\n",
       "      <td>0.072263</td>\n",
       "      <td>0.065586</td>\n",
       "      <td>1.101808</td>\n",
       "      <td>Bayesian LORETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wMNE</th>\n",
       "      <td>0.080970</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>2.904499</td>\n",
       "      <td>wMNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cwMNE</th>\n",
       "      <td>0.096279</td>\n",
       "      <td>0.039392</td>\n",
       "      <td>2.444103</td>\n",
       "      <td>cwMNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cLAURA</th>\n",
       "      <td>0.127542</td>\n",
       "      <td>0.118207</td>\n",
       "      <td>1.078978</td>\n",
       "      <td>cLAURA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cMultiple Sparse Priors</th>\n",
       "      <td>0.102152</td>\n",
       "      <td>0.067876</td>\n",
       "      <td>1.504986</td>\n",
       "      <td>cMultiple Sparse Priors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multiple Sparse Priors</th>\n",
       "      <td>0.104202</td>\n",
       "      <td>0.056560</td>\n",
       "      <td>1.842315</td>\n",
       "      <td>Multiple Sparse Priors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian MNE</th>\n",
       "      <td>0.112248</td>\n",
       "      <td>0.066083</td>\n",
       "      <td>1.698589</td>\n",
       "      <td>Bayesian MNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cBayesian MNE</th>\n",
       "      <td>0.123224</td>\n",
       "      <td>0.093441</td>\n",
       "      <td>1.318745</td>\n",
       "      <td>cBayesian MNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAURA</th>\n",
       "      <td>0.140239</td>\n",
       "      <td>0.102737</td>\n",
       "      <td>1.365030</td>\n",
       "      <td>LAURA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S-MAP</th>\n",
       "      <td>0.175604</td>\n",
       "      <td>0.145311</td>\n",
       "      <td>1.208467</td>\n",
       "      <td>S-MAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dSPM</th>\n",
       "      <td>0.132065</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>2.590144</td>\n",
       "      <td>dSPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LORETA</th>\n",
       "      <td>0.188178</td>\n",
       "      <td>0.156672</td>\n",
       "      <td>1.201102</td>\n",
       "      <td>LORETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cdSPM</th>\n",
       "      <td>0.143207</td>\n",
       "      <td>0.061355</td>\n",
       "      <td>2.334067</td>\n",
       "      <td>cdSPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eLORETA</th>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.068783</td>\n",
       "      <td>2.061696</td>\n",
       "      <td>eLORETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cS-MAP</th>\n",
       "      <td>0.241210</td>\n",
       "      <td>0.212072</td>\n",
       "      <td>1.137399</td>\n",
       "      <td>cS-MAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ceLORETA</th>\n",
       "      <td>0.157826</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>1.607756</td>\n",
       "      <td>ceLORETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cMNE</th>\n",
       "      <td>0.187030</td>\n",
       "      <td>0.119631</td>\n",
       "      <td>1.563393</td>\n",
       "      <td>cMNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cLORETA</th>\n",
       "      <td>0.236453</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>1.112720</td>\n",
       "      <td>cLORETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Beamformer LORETA</th>\n",
       "      <td>0.179643</td>\n",
       "      <td>0.150379</td>\n",
       "      <td>1.194606</td>\n",
       "      <td>Bayesian Beamformer LORETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sLORETA</th>\n",
       "      <td>0.178486</td>\n",
       "      <td>0.060638</td>\n",
       "      <td>2.943460</td>\n",
       "      <td>sLORETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNE</th>\n",
       "      <td>0.170164</td>\n",
       "      <td>0.083223</td>\n",
       "      <td>2.044672</td>\n",
       "      <td>MNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fully-Connected</th>\n",
       "      <td>0.205923</td>\n",
       "      <td>0.158027</td>\n",
       "      <td>1.303092</td>\n",
       "      <td>Fully-Connected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cFully-Connected</th>\n",
       "      <td>0.244311</td>\n",
       "      <td>0.200814</td>\n",
       "      <td>1.216605</td>\n",
       "      <td>cFully-Connected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cBayesian Beamformer LORETA</th>\n",
       "      <td>0.217216</td>\n",
       "      <td>0.186489</td>\n",
       "      <td>1.164766</td>\n",
       "      <td>cBayesian Beamformer LORETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csLORETA</th>\n",
       "      <td>0.240827</td>\n",
       "      <td>0.080203</td>\n",
       "      <td>3.002731</td>\n",
       "      <td>csLORETA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Median  Variance    MedVar  \\\n",
       "cBayesian Beamformer         0.002265  0.027258  0.083097   \n",
       "Bayesian Beamformer          0.002182  0.053111  0.041083   \n",
       "cBackus-Gilbert              0.044199  0.115713  0.381973   \n",
       "Backus-Gilbert               0.035868  0.094927  0.377851   \n",
       "cBayesian LORETA             0.077309  0.082330  0.939014   \n",
       "Bayesian LORETA              0.072263  0.065586  1.101808   \n",
       "wMNE                         0.080970  0.027878  2.904499   \n",
       "cwMNE                        0.096279  0.039392  2.444103   \n",
       "cLAURA                       0.127542  0.118207  1.078978   \n",
       "cMultiple Sparse Priors      0.102152  0.067876  1.504986   \n",
       "Multiple Sparse Priors       0.104202  0.056560  1.842315   \n",
       "Bayesian MNE                 0.112248  0.066083  1.698589   \n",
       "cBayesian MNE                0.123224  0.093441  1.318745   \n",
       "LAURA                        0.140239  0.102737  1.365030   \n",
       "S-MAP                        0.175604  0.145311  1.208467   \n",
       "dSPM                         0.132065  0.050987  2.590144   \n",
       "LORETA                       0.188178  0.156672  1.201102   \n",
       "cdSPM                        0.143207  0.061355  2.334067   \n",
       "eLORETA                      0.141810  0.068783  2.061696   \n",
       "cS-MAP                       0.241210  0.212072  1.137399   \n",
       "ceLORETA                     0.157826  0.098165  1.607756   \n",
       "cMNE                         0.187030  0.119631  1.563393   \n",
       "cLORETA                      0.236453  0.212500  1.112720   \n",
       "Bayesian Beamformer LORETA   0.179643  0.150379  1.194606   \n",
       "sLORETA                      0.178486  0.060638  2.943460   \n",
       "MNE                          0.170164  0.083223  2.044672   \n",
       "Fully-Connected              0.205923  0.158027  1.303092   \n",
       "cFully-Connected             0.244311  0.200814  1.216605   \n",
       "cBayesian Beamformer LORETA  0.217216  0.186489  1.164766   \n",
       "csLORETA                     0.240827  0.080203  3.002731   \n",
       "\n",
       "                                                  Method  \n",
       "cBayesian Beamformer                cBayesian Beamformer  \n",
       "Bayesian Beamformer                  Bayesian Beamformer  \n",
       "cBackus-Gilbert                          cBackus-Gilbert  \n",
       "Backus-Gilbert                            Backus-Gilbert  \n",
       "cBayesian LORETA                        cBayesian LORETA  \n",
       "Bayesian LORETA                          Bayesian LORETA  \n",
       "wMNE                                                wMNE  \n",
       "cwMNE                                              cwMNE  \n",
       "cLAURA                                            cLAURA  \n",
       "cMultiple Sparse Priors          cMultiple Sparse Priors  \n",
       "Multiple Sparse Priors            Multiple Sparse Priors  \n",
       "Bayesian MNE                                Bayesian MNE  \n",
       "cBayesian MNE                              cBayesian MNE  \n",
       "LAURA                                              LAURA  \n",
       "S-MAP                                              S-MAP  \n",
       "dSPM                                                dSPM  \n",
       "LORETA                                            LORETA  \n",
       "cdSPM                                              cdSPM  \n",
       "eLORETA                                          eLORETA  \n",
       "cS-MAP                                            cS-MAP  \n",
       "ceLORETA                                        ceLORETA  \n",
       "cMNE                                                cMNE  \n",
       "cLORETA                                          cLORETA  \n",
       "Bayesian Beamformer LORETA    Bayesian Beamformer LORETA  \n",
       "sLORETA                                          sLORETA  \n",
       "MNE                                                  MNE  \n",
       "Fully-Connected                          Fully-Connected  \n",
       "cFully-Connected                        cFully-Connected  \n",
       "cBayesian Beamformer LORETA  cBayesian Beamformer LORETA  \n",
       "csLORETA                                        csLORETA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Variance')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=0.8)\n",
    "df = pd.DataFrame(errors)\n",
    "sorted_index = df.median().sort_values().index\n",
    "df = df[sorted_index]\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(data=df)\n",
    "plt.title(\"Correlation with ground truth\")\n",
    "\n",
    "\n",
    "df_mean_var = pd.concat([df.mean(), df.std()], axis=1)\n",
    "df_mean_var = df_mean_var.rename(columns={0: \"Median\", 1: \"Variance\"})\n",
    "df_mean_var[\"MedVar\"] = df_mean_var[\"Median\"] / df_mean_var[\"Variance\"]\n",
    "df_mean_var[\"Method\"] = df_mean_var.index\n",
    "display(df_mean_var)\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(x=\"Median\", y=\"Variance\", hue=\"Method\", size=\"MedVar\", data=df_mean_var)\n",
    "plt.xlabel(\"Median\")\n",
    "plt.ylabel(\"Variance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('invertenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda1e5657e486f74a7b39841fb8103db2af51a77394f44c39a7821a371af47bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
