{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; \n",
    "sys.path.insert(0, '../../esinet')\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    1.7s remaining:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi64')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "dist = cdist(pos, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2004.45it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 401.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyvistaqt 3d backend.\n",
      "\n",
      "Using control points [0.0000000e+00 0.0000000e+00 1.2234291e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    }
   ],
   "source": [
    "# settings = dict(number_of_sources=1, extents=40, duration_of_trial=0.01, target_snr=99999999999)\n",
    "settings = dict(number_of_sources=1, extents=(1, 40), duration_of_trial=0.001, target_snr=99999)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "y = evoked.data\n",
    "x = stc.data\n",
    "\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 1) (1, 1284)\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Using control points [0. 0. 1.]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1be8b0ea400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from invert.solvers import generator\n",
    "\n",
    "gen = generator(fwd, \"cov\", batch_size=1, n_sources=4, n_timepoints=20, snr_range=(100, 101))\n",
    "x_test, y_test = gen.__next__()\n",
    "print(x_test.shape, y_test.shape)\n",
    "i = 0\n",
    "%matplotlib qt\n",
    "evoked_ = mne.EvokedArray(x_test[i, :, :, 0].T, evoked.info)\n",
    "evoked_.plot_joint(title=\"Sample\")\n",
    "\n",
    "stc_ = stc.copy()\n",
    "\n",
    "stc_.data[:, 0] = y_test[i]\n",
    "stc_.plot(**pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: -0.2988 - val_loss: -0.6092\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 2s 52ms/step - loss: -0.3093 - val_loss: -0.6065\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 2s 60ms/step - loss: -0.3037 - val_loss: -0.6037\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 2s 51ms/step - loss: -0.3117 - val_loss: -0.6002\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 2s 50ms/step - loss: -0.3098 - val_loss: -0.5888\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 2s 49ms/step - loss: -0.3215 - val_loss: -0.5803\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 2s 42ms/step - loss: -0.3228 - val_loss: -0.5690\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 2s 39ms/step - loss: -0.3384 - val_loss: -0.5671\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.3404 - val_loss: -0.5610\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.3406 - val_loss: -0.5519\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 2s 40ms/step - loss: -0.3576 - val_loss: -0.5564\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 39ms/step - loss: -0.3543 - val_loss: -0.5522\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.3533 - val_loss: -0.5448\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.3554 - val_loss: -0.5461\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.3605 - val_loss: -0.5379\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.3647 - val_loss: -0.5444\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 2s 39ms/step - loss: -0.3740 - val_loss: -0.5484\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.3726 - val_loss: -0.5448\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.3790 - val_loss: -0.5458\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.3778 - val_loss: -0.5396\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.3772 - val_loss: -0.5372\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.3801 - val_loss: -0.5347\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.3854 - val_loss: -0.5316\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 2s 40ms/step - loss: -0.3819 - val_loss: -0.5351\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 3s 46ms/step - loss: -0.3939 - val_loss: -0.5318\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 2s 41ms/step - loss: -0.3836 - val_loss: -0.5232\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 2s 41ms/step - loss: -0.3913 - val_loss: -0.5246\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 2s 41ms/step - loss: -0.4004 - val_loss: -0.5267\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 2s 44ms/step - loss: -0.3991 - val_loss: -0.5063\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4042 - val_loss: -0.5181\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4108 - val_loss: -0.5212\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.3993 - val_loss: -0.5210\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 2s 44ms/step - loss: -0.4077 - val_loss: -0.5196\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4050 - val_loss: -0.5175\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 2s 38ms/step - loss: -0.4049 - val_loss: -0.5215\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4059 - val_loss: -0.5115\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4183 - val_loss: -0.5163\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4084 - val_loss: -0.5057\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4140 - val_loss: -0.5134\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 2s 46ms/step - loss: -0.4092 - val_loss: -0.5089\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 2s 38ms/step - loss: -0.4173 - val_loss: -0.5097\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.4200 - val_loss: -0.5137\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 2s 43ms/step - loss: -0.4216 - val_loss: -0.5108\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 2s 36ms/step - loss: -0.4168 - val_loss: -0.5120\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.4154 - val_loss: -0.5083\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4257 - val_loss: -0.5079\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 2s 38ms/step - loss: -0.4307 - val_loss: -0.5101\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4344 - val_loss: -0.5037\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 36ms/step - loss: -0.4188 - val_loss: -0.5047\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 2s 51ms/step - loss: -0.4305 - val_loss: -0.4971\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4311 - val_loss: -0.4947\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4231 - val_loss: -0.4926\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.4358 - val_loss: -0.5057\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 2s 38ms/step - loss: -0.4225 - val_loss: -0.4936\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4249 - val_loss: -0.4967\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4314 - val_loss: -0.4954\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 2s 48ms/step - loss: -0.4436 - val_loss: -0.4978\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4415 - val_loss: -0.4935\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.4296 - val_loss: -0.4918\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4309 - val_loss: -0.4923\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4402 - val_loss: -0.4912\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 2s 38ms/step - loss: -0.4320 - val_loss: -0.4854\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4429 - val_loss: -0.4877\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4465 - val_loss: -0.4836\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4405 - val_loss: -0.4869\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4476 - val_loss: -0.4950\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.4366 - val_loss: -0.4903\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4488 - val_loss: -0.4878\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4427 - val_loss: -0.4897\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4511 - val_loss: -0.4970\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.4377 - val_loss: -0.4902\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4582 - val_loss: -0.4895\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.4445 - val_loss: -0.4936\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 2s 50ms/step - loss: -0.4557 - val_loss: -0.4934\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4484 - val_loss: -0.4896\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 2s 36ms/step - loss: -0.4541 - val_loss: -0.4867\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 2s 41ms/step - loss: -0.4584 - val_loss: -0.4898\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 2s 37ms/step - loss: -0.4532 - val_loss: -0.4741\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 36ms/step - loss: -0.4589 - val_loss: -0.4782\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 37ms/step - loss: -0.4517 - val_loss: -0.4812\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 2s 38ms/step - loss: -0.4577 - val_loss: -0.4859\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 1s 38ms/step - loss: -0.4660 - val_loss: -0.4820\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 2s 41ms/step - loss: -0.4577 - val_loss: -0.4813\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lukas\\Documents\\projects\\invert\\dev\\new_ann_cov.ipynb Zelle 8\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/Documents/projects/invert/dev/new_ann_cov.ipynb#X10sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m gen_val \u001b[39m=\u001b[39m generator(fwd, \u001b[39m\"\u001b[39m\u001b[39mcov\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgen_args)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/Documents/projects/invert/dev/new_ann_cov.ipynb#X10sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(patience\u001b[39m=\u001b[39mepochs, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lukas/Documents/projects/invert/dev/new_ann_cov.ipynb#X10sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mgen, epochs\u001b[39m=\u001b[39;49mepochs, steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch, validation_data\u001b[39m=\u001b[39;49mgen_val\u001b[39m.\u001b[39;49m\u001b[39m__next__\u001b[39;49m(), callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "n_channels = evoked.data.shape[0]\n",
    "n_dipoles = x.shape[0]\n",
    "\n",
    "# Architecture Params\n",
    "n_filters = 256\n",
    "activation_function = \"tanh\"\n",
    "batch_size = int(n_dipoles)\n",
    "\n",
    "# Simulation Params\n",
    "n_sources = 10\n",
    "n_orders = 2\n",
    "n_timepoints = 20\n",
    "batch_repetitions = 10\n",
    "snr_range = (1e99,2e99)\n",
    "amplitude_range = (0.99,1)\n",
    "gen_args = dict(batch_size=batch_size, batch_repetitions=batch_repetitions, \n",
    "                n_sources=n_sources, n_orders=n_orders, n_timepoints=n_timepoints,\n",
    "                snr_range=snr_range, amplitude_range=amplitude_range)\n",
    "\n",
    "\n",
    "# Training Params\n",
    "epochs = 300\n",
    "steps_per_epoch = batch_repetitions\n",
    "\n",
    "n_hl = 1\n",
    "\n",
    "inputs = tf.keras.Input(shape=(n_channels, n_channels, 1), name='Input')\n",
    "\n",
    "cnn1 = Conv2D(n_filters, (1, n_channels),\n",
    "            activation=activation_function, padding=\"valid\",\n",
    "            name='CNN1')(inputs)\n",
    "# cnn1 = BatchNormalization()(cnn1)\n",
    "# cnn1 = Conv2D(n_filters, (n_channels, 1),\n",
    "#             activation=activation_function, padding=\"valid\",\n",
    "#             name='CNN2')(cnn1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flat = Flatten()(cnn1)\n",
    "\n",
    "fc1 = Dense(300, \n",
    "            activation=activation_function, \n",
    "            name='FC1')(flat)\n",
    "# fc1 = Dense(300, \n",
    "#             activation=activation_function, \n",
    "#             name='FC2')(fc1)\n",
    "\n",
    "out = Dense(n_dipoles, \n",
    "            activation=\"sigmoid\", \n",
    "            name='Output')(fc1)\n",
    "\n",
    "\n",
    "# model = tf.keras.Model(inputs=inputs, outputs=out, name='CovCNN')\n",
    "# model.compile(loss=\"cosine_similarity\", optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3))\n",
    "# model.summary()\n",
    "\n",
    "gen = generator(fwd, \"cov\", **gen_args)\n",
    "gen_args[\"batch_size\"] = 1024\n",
    "gen_val = generator(fwd, \"cov\", **gen_args)\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=epochs, restore_best_weights=True),]\n",
    "model.fit(x=gen, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_data=gen_val.__next__(), callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Temp\\ipykernel_11324\\2140372095.py:16: RuntimeWarning: All data were zero\n",
      "  stc_.plot(**pp, brain_kwargs=dict(title=\"Ground Truths\"), colormap=\"Reds\", clim=clim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n",
      "Using control points [4.52346001e-07 6.53062199e-06 1.12960853e-05]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1be90e27ee0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\mne\\viz\\utils.py\", line 60, in safe_event\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"c:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py\", line 731, in _clean\n",
      "    self.clear_glyphs()\n",
      "  File \"c:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py\", line 1629, in clear_glyphs\n",
      "    assert sum(len(v) for v in self.picked_points.values()) == 0\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "clim = dict(kind=\"percent\", lims=(0,0.5,1))\n",
    "\n",
    "gen_args = dict(batch_size=batch_size, batch_repetitions=batch_repetitions, \n",
    "                n_sources=n_sources, n_orders=n_orders, n_timepoints=n_timepoints)\n",
    "gen_args[\"batch_size\"] = 10\n",
    "gen_args[\"amplitude_range\"] = (0.99, 1)\n",
    "\n",
    "gen_tst = generator(fwd, \"cov\", **gen_args)\n",
    "\n",
    "x_test, y_test = gen_tst.__next__()\n",
    "\n",
    "y_hat = model.predict(x_test, verbose=0)\n",
    "\n",
    "stc_ = stc.copy()\n",
    "stc_.data = (y_test.T / y_test.max( axis=1))\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"Ground Truths\"), colormap=\"Reds\", clim=clim)\n",
    "\n",
    "stc_ = stc.copy()\n",
    "stc_.data = (y_hat.T / y_hat.max( axis=1))\n",
    "stc_.plot(**pp, brain_kwargs=dict(title=\"Preds\"), colormap=\"Reds\", clim=clim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1284)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1284)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('invertenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda1e5657e486f74a7b39841fb8103db2af51a77394f44c39a7821a371af47bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
