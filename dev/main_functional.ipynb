{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Forward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    3.2s remaining:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    3.3s remaining:    1.9s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.6s remaining:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi32')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "n_chans, n_dipoles = leadfield.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.64it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 286.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 1000) (1284, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 16.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [2.30927956e-09 1.03316335e-08 6.45904458e-08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    }
   ],
   "source": [
    "# settings = dict(number_of_sources=1, extents=40, duration_of_trial=0.01, target_snr=99999999999)\n",
    "settings = dict(number_of_sources=3, extents=(25, 40), duration_of_trial=1, target_snr=2)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "M = evoked.data\n",
    "\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx = 85, r=27.185882427329428\n",
      "Using control points [3.95379424e-09 4.75624675e-09 1.60955668e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n",
      "Using control points [6.57975177e-09 7.97935469e-09 2.52496222e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1f295766850>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [5.28368710e-09 6.21174898e-09 1.14259712e-08]\n",
      "Using control points [3.41780286e-09 4.01039544e-09 8.91672514e-09]\n",
      "Using control points [5.28368710e-09 6.21174898e-09 1.14259712e-08]\n",
      "Using control points [1.46377819e-09 5.15575336e-09 1.84379291e-08]\n"
     ]
    }
   ],
   "source": [
    "from invert.solvers.minimum_norm_estimates import SolverMinimumNorm\n",
    "\n",
    "solver = SolverMinimumNorm()\n",
    "\n",
    "solver.make_inverse_operator(fwd, alpha='auto')\n",
    "stc_hat = solver.apply_inverse_operator(evoked)\n",
    "stc_hat.plot(**pp)\n",
    "\n",
    "solver.make_inverse_operator(fwd, alpha=0)\n",
    "stc_hat = solver.apply_inverse_operator(evoked)\n",
    "stc_hat.plot(**pp)\n",
    "\n",
    "# solver.make_inverse_operator(fwd, alpha=1e10)\n",
    "# stc_hat = solver.apply_inverse_operator(evoked)\n",
    "# stc_hat.plot(**pp)\n",
    "\n",
    "# solver.make_inverse_operator(fwd, alpha=1e11)\n",
    "# stc_hat = solver.apply_inverse_operator(evoked)\n",
    "# stc_hat.plot(**pp)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing inverse operator with 32 channels.\n",
      "    32 out of 32 channels remain after picking\n",
      "Selected 32 channels\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.8e-18 (2.2e-16 eps * 32 dim * 0.0004  max singular value)\n",
      "    Estimated rank (eeg): 31\n",
      "    EEG: rank 31 computed from 32 data channels with 1 projector\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 3.25404\n",
      "    scaling factor to adjust the trace = 3.07424e+21 (nchan = 32 nzero = 1)\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Created the whitener using a noise covariance matrix with rank 31 (1 small eigenvalues omitted)\n",
      "Applying inverse operator to \"1\"...\n",
      "    Picked 32 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  94.0% variance\n",
      "[done]\n",
      "Using control points [2.21503699e-09 2.65759766e-09 9.21726161e-09]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1f29fc2ffd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.39855642e-09 1.65036569e-09 4.33651143e-09]\n",
      "Using control points [3.41780286e-09 4.01039544e-09 8.91672514e-09]\n",
      "Using control points [5.28368710e-09 6.21174898e-09 1.14259712e-08]\n",
      "Using control points [1.39855642e-09 1.65036569e-09 4.33651143e-09]\n",
      "Using control points [3.63611051e-09 4.27780042e-09 1.07905916e-08]\n",
      "Using control points [1.99579652e-09 2.35524405e-09 6.61545605e-09]\n"
     ]
    }
   ],
   "source": [
    "from mne.minimum_norm import make_inverse_operator as mne_inverse\n",
    "from mne.minimum_norm import apply_inverse as mne_apply\n",
    "from mne import make_ad_hoc_cov\n",
    "noise_cov = make_ad_hoc_cov(evoked.info)\n",
    "mne_io = mne_inverse(evoked.info, fwd, noise_cov=noise_cov, fixed=True, loose=0, depth=0)\n",
    "stc_hat = mne_apply(evoked, mne_io, method=\"MNE\")\n",
    "stc_hat.plot(**pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('invertenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda1e5657e486f74a7b39841fb8103db2af51a77394f44c39a7821a371af47bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
