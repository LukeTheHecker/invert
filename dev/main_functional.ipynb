{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (c:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\keras\\preprocessing\\sequence.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lukas\\Documents\\projects\\invert\\dev\\main_functional.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lukas/Documents/projects/invert/dev/main_functional.ipynb#ch0000000?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m pearsonr\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lukas/Documents/projects/invert/dev/main_functional.ipynb#ch0000000?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmne\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lukas/Documents/projects/invert/dev/main_functional.ipynb#ch0000000?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mesinet\u001b[39;00m \u001b[39mimport\u001b[39;00m Simulation\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/Documents/projects/invert/dev/main_functional.ipynb#ch0000000?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mesinet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mforward\u001b[39;00m \u001b[39mimport\u001b[39;00m get_info, create_forward_model\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/Documents/projects/invert/dev/main_functional.ipynb#ch0000000?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mesinet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m unpack_fwd\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\esinet\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msimulation\u001b[39;00m \u001b[39mimport\u001b[39;00m Simulation\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnet\u001b[39;00m \u001b[39mimport\u001b[39;00m Net\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\esinet\\simulation.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmne\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtime\u001b[39;00m \u001b[39mimport\u001b[39;00m time\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m util\n\u001b[0;32m     17\u001b[0m DEFAULT_SETTINGS \u001b[39m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mstandard\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnumber_of_sources\u001b[39m\u001b[39m'\u001b[39m: (\u001b[39m1\u001b[39m, \u001b[39m25\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msource_number_weighting\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     30\u001b[0m }\n\u001b[0;32m     32\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSimulation\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\esinet\\util\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\esinet\\util\\util.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_pdf\u001b[39;00m \u001b[39mimport\u001b[39;00m PdfPages\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m simulation\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m net\n\u001b[0;32m     18\u001b[0m \u001b[39m# from .. import Simulation\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# from .. import Net\u001b[39;00m\n\u001b[0;32m     21\u001b[0m EPOCH_INSTANCES \u001b[39m=\u001b[39m (mne\u001b[39m.\u001b[39mepochs\u001b[39m.\u001b[39mEpochsArray, mne\u001b[39m.\u001b[39mEpochs, mne\u001b[39m.\u001b[39mEpochsArray, mne\u001b[39m.\u001b[39mepochs\u001b[39m.\u001b[39mEpochsFIF)\n",
      "File \u001b[1;32mc:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\esinet\\net.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Lambda\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequence\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequences\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimize\u001b[39;00m \u001b[39mimport\u001b[39;00m minimize_scalar\n\u001b[0;32m     16\u001b[0m \u001b[39m# import pickle as pkl\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (c:\\Users\\Lukas\\Envs\\invertenv\\lib\\site-packages\\keras\\preprocessing\\sequence.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import mne \n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Forward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    2.6s remaining:    4.4s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    2.6s remaining:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi32')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "n_chans, n_dipoles = leadfield.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 5124\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.11s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00, 58.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (5124, 1000) (5124, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [3.27471165e-11 1.81211507e-10 3.33690064e-08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    }
   ],
   "source": [
    "# settings = dict(number_of_sources=1, extents=40, duration_of_trial=0.01, target_snr=99999999999)\n",
    "settings = dict(number_of_sources=3, extents=(1, 40), duration_of_trial=1, target_snr=2)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "M = evoked.data\n",
    "\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sloreta_inverse_operator(leadfield, alpha=0.001, noise_cov=None):\n",
    "    \"\"\" Calculate the inverse operator using standardized Low Resolution\n",
    "    TomogrAphy (sLORETA).\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    leadfield : numpy.ndarray\n",
    "        Leadfield (or gain matrix) G which constitutes the forward model of M =\n",
    "        J @ G, where sources J are projected through the leadfield producing the\n",
    "        observed EEG matrix M.\n",
    "    adjacency : numpy.ndarray\n",
    "        The source adjacency matrix (n_dipoles x n_dipoles) which represents the\n",
    "        connections of the dipole mesh.\n",
    "    alpha : float\n",
    "        The regularization parameter.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    inverse_operator : numpy.ndarray\n",
    "        The inverse operator that is used to calculate source.\n",
    "\n",
    "    \"\"\"\n",
    "    n_chans, _ = leadfield.shape\n",
    "    if noise_cov is None:\n",
    "        noise_cov = np.identity(n_chans)\n",
    "        \n",
    "    if alpha.lower() == 'auto':\n",
    "        eigenvals = np.linalg.eig(leadfield @leadfield.T)[0]\n",
    "        alpha = np.max(eigenvals) / 2e4\n",
    "        alphas = [alpha*r for r in range(12)]\n",
    "    else:\n",
    "        alphas = [alpha,]\n",
    "    # create one inverse operator for each level of regularization\n",
    "    inverse_operators = []\n",
    "    for alpha in alphas:\n",
    "        K_MNE = leadfield.T @ np.linalg.inv(leadfield @ leadfield.T + alpha * noise_cov)\n",
    "        W_diag = 1 / np.diag(K_MNE @ leadfield)\n",
    "        W_slor = np.sqrt(np.diag(W_diag))\n",
    "        \n",
    "        inverse_operator = W_slor @ K_MNE\n",
    "        inverse_operators.append( inverse_operator )\n",
    "    return inverse_operators\n",
    "\n",
    "\n",
    "class InverseOperator:\n",
    "    ''' This class holds the inverse operator, which may be a simple\n",
    "    numpy.ndarray matrix or some object like an esinet.net()\n",
    "    '''\n",
    "    def __init__(self, inverse_operator, solver_name):\n",
    "        self.solver_name = solver_name\n",
    "        self.data = inverse_operator\n",
    "        self.handle_inverse_operator()\n",
    "\n",
    "        self.has_multiple_operators()\n",
    "    def has_multiple_operators(self):\n",
    "        ''' Check if there are multiple inverse_operators.'''\n",
    "        if type(self.data) == list:\n",
    "            if len(self.data) > 1:\n",
    "                return True\n",
    "        return False\n",
    "    def handle_inverse_operator(self, inverse_operator):\n",
    "        if type(self.data) != list:\n",
    "            self.data = [self.data,]\n",
    "        self.type = type(self.data[0])\n",
    "        \n",
    "    \n",
    "    def apply(self, evoked, forward, verbose=0):\n",
    "        ''' Apply the inverse operator to the evoked object to calculate the source.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        evoked : mne.EvokedArray\n",
    "            The evoked object containing evoked M/EEG data.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        stc : mne.SourceEstimate\n",
    "            The source estimate object containing the source\n",
    "        '''\n",
    "        # Do some preprocessing/ whitening?\n",
    "        M = evoked.data\n",
    "        assert type(self.data) == list, \"self.data is not a list so something is terribly wrong\"\n",
    "\n",
    "        if len(self.data) > 1:\n",
    "            # Do the L corner thingy\n",
    "        else:\n",
    "            if self.type == np.ndarray:\n",
    "                inverse_operator.data @ M \n",
    "\n",
    "\n",
    "        elif inverse_operator.type == list:\n",
    "            maximum_a_posteriori, A, S = inverse_operator.data\n",
    "            # transform data M with spatial (A) and temporal (S) projector\n",
    "            M_ = A @ M @ S\n",
    "            # invert transformed data M_ to tansformed sources J_\n",
    "            J_ = maximum_a_posteriori @ M_\n",
    "            # Project tansformed sources J_ back to original time frame using temporal projector S\n",
    "            source_mat =  J_ @ S.T \n",
    "        elif inverse_operator.type == esinet.Net:\n",
    "            source_mat = inverse_operator.data.predict(evoked)[0].data\n",
    "        else:\n",
    "            msg = f\"type of inverse operator ({inverse_operator.type}) unknown\"\n",
    "            raise AttributeError(msg)\n",
    "        \n",
    "        # Convert source to mne.SourceEstimate object\n",
    "        source_model = forward['src']\n",
    "        vertices = [source_model[0]['vertno'], source_model[1]['vertno']]\n",
    "        tmin = evoked.tmin\n",
    "        sfreq = evoked.info[\"sfreq\"]\n",
    "        tstep = 1/sfreq\n",
    "        subject = evoked.info[\"subject_info\"]\n",
    "\n",
    "        if subject is None:\n",
    "            subject = \"fsaverage\"\n",
    "        \n",
    "        stc = mne.SourceEstimate(source_mat, vertices, tmin=tmin, tstep=tstep, subject=subject, verbose=verbose)\n",
    "        return stc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [3.29159778e-08 3.71957356e-08 7.63551158e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x2940f69aee0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [2.71529166e-08 3.01263004e-08 4.82658874e-08]\n",
      "Using control points [2.64545841e-11 1.36834743e-10 1.57361275e-08]\n"
     ]
    }
   ],
   "source": [
    "from invert import make_inverse_operator, apply_inverse_operator, InverseOperator\n",
    "from invert.evaluate import nmse, corr\n",
    "# from invert.solvers.loreta import make_sloreta_inverse_operator\n",
    "from tqdm.notebook import tqdm\n",
    "solver = \"slor\"\n",
    "alpha = 1/settings[\"target_snr\"]**2\n",
    "\n",
    "# inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, alpha=alpha, verbose=0)\n",
    "inverse_operator = make_sloreta_inverse_operator(leadfield, alpha='auto')\n",
    "inverse_operator = InverseOperator(inverse_operator, solver)\n",
    "stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "stc_hat.plot(**pp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [6.52956037e-05 7.85430437e-05 1.65699895e-04]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x2480de520d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [4.54311450e-05 5.30130690e-05 7.36848788e-05]\n",
      "Using control points [4.54311450e-05 5.30130690e-05 7.36848788e-05]\n"
     ]
    }
   ],
   "source": [
    "solver = \"dSPM\"\n",
    "# alpha_heuristic = 1/settings[\"target_snr\"]**2\n",
    "alpha = 2000\n",
    "inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, alpha=alpha, verbose=0)\n",
    "stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "stc_hat.plot(**pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:863: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  warn(\"Method 'bounded' does not support relative tolerance in x; \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=0.0260\n",
      "Using control points [2.69993792e-09 3.79865658e-09 1.90327871e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1975446e2b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.33156213e-09 2.41506867e-09 3.25942281e-08]\n",
      "Using control points [2.45756571e-09 3.58205804e-09 7.57540420e-09]\n"
     ]
    }
   ],
   "source": [
    "from invert import make_inverse_operator, apply_inverse_operator\n",
    "from invert.adapters import contextualize_bd\n",
    "from invert.evaluate import nmse\n",
    "\n",
    "solver = \"lstm\"\n",
    "# inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, verbose=1)\n",
    "\n",
    "stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "error = np.median(nmse(stc.data, stc_hat.data))\n",
    "print(f\"error={error:.4f}\")\n",
    "stc_hat.plot(**pp, brain_kwargs=dict(title=solver))\n",
    "\n",
    "# stc_hat.data = contextualize_bd(stc_hat.data, leadfield, num_epochs=20)\n",
    "# error = np.median(nmse(stc.data, stc_hat.data))\n",
    "# print(f\"error={error:.4f}\")\n",
    "# stc_hat.plot(**pp, brain_kwargs=dict(title=solver + \" contextualized\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invert import all_solvers, make_inverse_operator, apply_inverse_operator\n",
    "from invert.adapters import contextualize_bd\n",
    "from invert.evaluate import nmse, corr\n",
    "stc.plot(**pp, brain_kwargs=dict(title=\"Ground Truth\"))\n",
    "errors = dict()\n",
    "for solver in all_solvers:\n",
    "    print(solver)\n",
    "    inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, alpha=1/4.5)\n",
    "    stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "    # stc_hat.plot(**pp, brain_kwargs=dict(title=solver))\n",
    "    errors[solver] = corr(stc.data, stc_hat.data)\n",
    "    \n",
    "solver = \"esinet\"\n",
    "stc_hat = net.predict(evoked)[0]\n",
    "# stc_hat.plot(**pp, brain_kwargs=dict(title=solver))\n",
    "errors[solver] = corr(stc.data, stc_hat.data)\n",
    "\n",
    "solver += \" contextualized\"\n",
    "stc_hat.data = contextualize_bd(stc_hat.data, leadfield)\n",
    "errors[solver] = corr(stc.data, stc_hat.data)\n",
    "# stc_hat.plot(**pp, brain_kwargs=dict(title=solver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = \"LORETA\"\n",
    "inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, alpha=1/4.5)\n",
    "stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "stc_hat.plot(**pp, brain_kwargs=dict(title=solver))\n",
    "\n",
    "stc_hat.data = contextualize_bd(stc_hat.data, leadfield, steps_per_ep=25, verbose=1)\n",
    "errors[solver] = corr(stc.data, stc_hat.data)\n",
    "stc_hat.plot(**pp, brain_kwargs=dict(title=solver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib qt\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "# ax.set_yscale(\"log\")\n",
    "sns.boxplot(data=pd.DataFrame(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (invertenv)",
   "language": "python",
   "name": "invertenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9587d79750f5d7fc5c0560e15a7a8a49dff11015373bda407c2fe4ab31d0fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
