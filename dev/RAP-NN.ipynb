{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "\n",
    "import sys; sys.path.insert(0, '../') \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cdist\n",
    "import mne\n",
    "\n",
    "from invert.forward import get_info, create_forward_model\n",
    "from invert.util import pos_from_forward\n",
    "from invert.evaluate import eval_mean_localization_error\n",
    "\n",
    "pp = dict(surface='inflated', hemi='both', verbose=0, cortex='low_contrast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>32 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Source space</th>\n",
       "        <td>Surface with 324 vertices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Source orientation</th>\n",
       "        <td>Fixed</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Forward | MEG channels: 0 | EEG channels: 32 | Source space: Surface with 324 vertices | Source orientation: Fixed>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling = \"ico2\"\n",
    "info = get_info(kind='biosemi32')\n",
    "fwd = create_forward_model(info=info, sampling=sampling)\n",
    "fwd[\"sol\"][\"data\"] /= np.linalg.norm(fwd[\"sol\"][\"data\"], axis=0) \n",
    "pos = pos_from_forward(fwd)\n",
    "leadfield = fwd[\"sol\"][\"data\"]\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "\n",
    "source_model = fwd['src']\n",
    "vertices = [source_model[0]['vertno'], source_model[1]['vertno']]\n",
    "adjacency = mne.spatial_src_adjacency(fwd[\"src\"], verbose=0)\n",
    "distance_matrix = cdist(pos, pos)\n",
    "fwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invert.simulate import generator\n",
    "sim_params = dict(\n",
    "    use_cov=False,\n",
    "    return_mask=False,\n",
    "    batch_repetitions=1,\n",
    "    batch_size=1,\n",
    "    n_sources=2,\n",
    "    n_orders=0,\n",
    "    # snr_range=(1, 1),\n",
    "    snr_range=(1e20, 1e21),\n",
    "    amplitude_range=(1, 1),\n",
    "    n_timecourses=200,\n",
    "    n_timepoints=50,\n",
    "    scale_data=False,\n",
    "    add_forward_error=False,\n",
    "    forward_error=0.1,\n",
    "    # inter_source_correlation=(0, 0.99),\n",
    "    inter_source_correlation=0,\n",
    "    return_info=True,\n",
    "    diffusion_parameter=0.1,\n",
    "    # correlation_mode=\"cholesky\",\n",
    "    # noise_color_coeff=(0, 0.99),\n",
    "    correlation_mode=None,\n",
    "    noise_color_coeff=0,\n",
    "    \n",
    "    random_seed=None)\n",
    "\n",
    "sim_params = dict(\n",
    "    use_cov=False,\n",
    "    return_mask=False,\n",
    "    batch_repetitions=1,\n",
    "    batch_size=1,\n",
    "    n_sources=(1, 10),\n",
    "    n_orders=(0, 0),\n",
    "    snr_range=(0.2, 10),\n",
    "    amplitude_range=(0.1, 1),\n",
    "    n_timecourses=200,\n",
    "    n_timepoints=50,\n",
    "    scale_data=False,\n",
    "    add_forward_error=False,\n",
    "    forward_error=0.1,\n",
    "    inter_source_correlation=(0, 1),\n",
    "    return_info=True,\n",
    "    diffusion_parameter=0.1,\n",
    "    correlation_mode=\"cholesky\",\n",
    "    noise_color_coeff=(0, 0.99),\n",
    "    \n",
    "    random_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ CNN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">324</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,724</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ CNN1 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m102,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m324\u001b[0m)            │        \u001b[38;5;34m32,724\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,280</span> (532.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m136,280\u001b[0m (532.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,280</span> (532.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m136,280\u001b[0m (532.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "# Assuming we have a function to generate initial EEG data and true dipoles\n",
    "def generate_initial_data(gen):\n",
    "    # This function should return initial EEG data\n",
    "    # and the true dipole parameters that generated the data.\n",
    "\n",
    "    # Generate random dipole parameters\n",
    "    x, y, _ = gen.__next__()\n",
    "    x = np.swapaxes(x, 1, 2)\n",
    "    y = np.swapaxes(y, 1, 2)\n",
    "    true_indices = [np.where(yy[:, 0]!=0)[0] for yy in y]\n",
    "    return x, true_indices, y\n",
    "\n",
    "# def outproject_from_data(data, leadfield, idc):\n",
    "#     L = leadfield[:, idc]\n",
    "#     # Y_est = L.T @ np.linalg.pinv(L @ L.T + np.identity(L.shape[0])*0.1) @ data\n",
    "#     # or simply:\n",
    "#     Y_est = np.linalg.pinv(L) @ data\n",
    "#     return data - L@Y_est\n",
    "#     # return L@Y_est - data\n",
    "\n",
    "def outproject_from_data(data, leadfield, idc: np.array, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Projects away the leadfield components at the indices idc from the EEG data.\n",
    "\n",
    "    Parameters:\n",
    "    data (np.array): Observed M/EEG data (n_chans x n_time).\n",
    "    leadfield (np.array): Leadfield matrix (n_chans x n_dipoles).\n",
    "    idc (np.array): Indices to project away from the leadfield.\n",
    "\n",
    "    Returns:\n",
    "    np.array: Data with the specified leadfield components removed.\n",
    "    \"\"\"\n",
    "    # Select the columns of the leadfield matrix corresponding to the indices\n",
    "    L_idc = leadfield[:, idc]\n",
    "\n",
    "    # Compute the projection matrix\n",
    "    # P = I - L(L.TL)^-1L.T\n",
    "    # where L = L_idc\n",
    "    L_idc_T = L_idc.T\n",
    "    projection_matrix = np.eye(leadfield.shape[0]) - L_idc @ np.linalg.pinv(L_idc_T @ L_idc + np.identity(len(idc)) * alpha) @ L_idc_T\n",
    "\n",
    "    # Apply the projection matrix to the data\n",
    "    data_without_idc = projection_matrix @ data\n",
    "\n",
    "    return data_without_idc\n",
    "\n",
    "def wrap_outproject_from_data(current_data, leadfield, estimated_dipole_idc, alpha=0.1):\n",
    "    # Wrapper function to outproject dipoles from the data\n",
    "    n_samples = current_data.shape[0]\n",
    "    new_data = np.zeros_like(current_data)\n",
    "    for i in range(n_samples):\n",
    "        new_data[i] = outproject_from_data(current_data[i], leadfield, np.array(estimated_dipole_idc[i]), alpha=alpha)\n",
    "    return new_data\n",
    "\n",
    "def predict(model, current_covs):\n",
    "    # Predict source estimate\n",
    "\n",
    "    # Predict the sources using the model\n",
    "    estimated_sources = model.predict(current_covs)  # Model's prediction\n",
    "    return estimated_sources\n",
    "    \n",
    "    # return new_data, estimated_dipole_idc\n",
    "\n",
    "# Function to compute residuals or stopping condition\n",
    "def compute_residual(current_data, new_data):\n",
    "    # Placeholder function to compute residual to decide when to stop the iteration\n",
    "    return tf.norm(current_data - new_data)\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import tensorflow as tf\n",
    "\n",
    "def spatially_weighted_cosine_loss(pos, sigma=10.0):\n",
    "    \"\"\"\n",
    "    Returns a loss function that combines cosine similarity with a spatial weighting\n",
    "    based on the positions of dipoles in the brain.\n",
    "    \n",
    "    Parameters:\n",
    "    - pos: numpy array of shape (n, 3) containing the positions of each dipole.\n",
    "    - sigma: controls the spread of the spatial influence (lower value -> steeper).\n",
    "\n",
    "    Returns:\n",
    "    - A loss function compatible with Keras.\n",
    "    \"\"\"\n",
    "    # Convert positions to a tensor and compute pairwise squared Euclidean distances\n",
    "    pos_tensor = tf.constant(pos, dtype=tf.float32)\n",
    "    pos_diff = tf.expand_dims(pos_tensor, 0) - tf.expand_dims(pos_tensor, 1)\n",
    "    sq_dist_matrix = tf.reduce_sum(tf.square(pos_diff), axis=-1)\n",
    "\n",
    "    # Create a Gaussian kernel from distances\n",
    "    spatial_kernel = tf.exp(-sq_dist_matrix / (2.0 * sigma**2))\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # Normalize y_true and y_pred to unit vectors along the last dimension\n",
    "        y_true_norm = tf.nn.l2_normalize(y_true, axis=-1)\n",
    "        y_pred_norm = tf.nn.l2_normalize(y_pred, axis=-1)\n",
    "\n",
    "        # Compute cosine similarity for each pair in the batch\n",
    "        cosine_sim = tf.reduce_sum(y_true_norm * y_pred_norm, axis=-1)  # Shape becomes [batch_size, n]\n",
    "\n",
    "        # Expand the spatial kernel and cosine similarity for broadcasting\n",
    "        expanded_spatial_kernel = tf.expand_dims(spatial_kernel, axis=0)  # Shape becomes [1, n, n]\n",
    "        expanded_cosine_sim = tf.expand_dims(cosine_sim, axis=1)  # Shape becomes [batch_size, 1, n]\n",
    "\n",
    "        # Apply spatial kernel\n",
    "        print(expanded_cosine_sim.shape, expanded_spatial_kernel.shape)\n",
    "        weighted_cosine_sim = expanded_cosine_sim * expanded_spatial_kernel\n",
    "        weighted_sum_cosine_sim = tf.reduce_sum(weighted_cosine_sim, axis=-1)  # Sum over last dim (n)\n",
    "        normalization = tf.reduce_sum(expanded_spatial_kernel, axis=-1)  # Sum spatial weights over n\n",
    "\n",
    "        # Calculate final loss by averaging over the batch and inverting the cosine similarity\n",
    "        weighted_cosine_loss = 1 - tf.reduce_mean(weighted_sum_cosine_sim / normalization)\n",
    "\n",
    "        return weighted_cosine_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def custom_loss(distances, scaler=1):\n",
    "    distances = tf.constant(distances, dtype=tf.float32)  # Ensure distances is a tensor\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # Normalize each sample in the batch\n",
    "        y_true_norm = y_true / tf.reduce_max(tf.abs(y_true), axis=1, keepdims=True)\n",
    "        y_pred_norm = y_pred / tf.reduce_max(tf.abs(y_pred), axis=1, keepdims=True)\n",
    "        # Calculate the absolute differences\n",
    "        # diff = tf.abs(y_true_norm - y_pred_norm)\n",
    "        diff = tf.square(y_true_norm - y_pred_norm)\n",
    "        \n",
    "        \n",
    "        # Perform element-wise multiplication with distances\n",
    "        weighted_diff = tf.reduce_mean( tf.matmul(tf.matmul(diff, distances),  tf.transpose(diff)))\n",
    "        # Compute the mean across the batch\n",
    "        error = tf.reduce_mean(weighted_diff)# + tf.reduce_mean(diff)\n",
    "        return error * scaler\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_shape = (n_chans, n_chans, 1)  # Specify the input shape based on your data\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(n_chans, (1, n_chans), \n",
    "          activation=\"tanh\", padding=\"valid\",\n",
    "          input_shape=input_shape,\n",
    "          name='CNN1'),\n",
    "    layers.Flatten(),\n",
    "    # layers.Dense(n_chans, activation='tanh'),\n",
    "    layers.Dense(100, activation='tanh'),\n",
    "    # layers.Dense(n_dipoles, activation='linear')\n",
    "    layers.Dense(n_dipoles, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(optimizer='adam', loss=lambda y_true, y_pred: wasserstein_distance_loss(y_true, y_pred, pos), metrics=['cosine_similarity'])\n",
    "model.compile(optimizer='adam', loss='cosine_similarity', metrics=['accuracy'])  # Specify the loss function and optimizer\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Specify the loss function and optimizer\n",
    "model.build()\n",
    "model.summary()\n",
    "# model.load_weights('.weights.h5')\n",
    "model2 = tf.keras.models.clone_model(model)\n",
    "model2.compile(optimizer='adam', loss='cosine_similarity', metrics=['accuracy'])  # Specify the loss function and optimizer\n",
    "# model2.load_weights('.weights.h5')\n",
    "# model2.load_weights('.rap-weights.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0.0 -0.09, 0.00\n",
      "epoch 0.1 -0.09, 0.00\n",
      "epoch 0.2 -0.09, 0.00\n",
      "epoch 0.3 -0.09, 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([(yy\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m yy \u001b[38;5;129;01min\u001b[39;00m y], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):  \n\u001b[1;32m---> 16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcovs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:540\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 540\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\invert\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "# model2 = tf.keras.models.clone_model(model)\n",
    "# model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=custom_loss(tf.cast(distance_matrix/np.max(distance_matrix), dtype=tf.float32), scaler=1), metrics=['cosine_similarity'])\n",
    "# model2.build()\n",
    "# model2.load_weights('.weights.h5')\n",
    "sim_params_temp = deepcopy(sim_params)\n",
    "sim_params_temp[\"batch_size\"] = 1024*20\n",
    "sim_params_temp[\"n_sources\"] = (1,5)\n",
    "gen = generator(fwd, **sim_params_temp)\n",
    "for i in range(50):\n",
    "    X, y, _ = gen.__next__()\n",
    "    covs = [xx.T@xx for xx in X]\n",
    "    covs = np.stack([xx/abs(xx).max() for xx in covs], axis=0)\n",
    "    y_true = np.stack([(yy!=0)[0,:].astype(float) for yy in y], axis=0).astype(int)\n",
    "    for j in range(10):  \n",
    "        loss = model2.train_on_batch(covs, y_true)\n",
    "        print(f\"epoch {i}.{j} {loss[0]:.2f}, {loss[1]:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - fixed number of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "gen = generator(fwd, **sim_params)\n",
    "\n",
    "epochs = 50\n",
    "epoch_distances = np.zeros(epochs)\n",
    "# Training loop within the RAP-MUSIC framework\n",
    "for epoch in range(epochs):  # Number of epochs\n",
    "    current_data, true_dipoles, Y = generate_initial_data(gen) \n",
    "    n_samples = len(true_dipoles)\n",
    "    estimated_dipole_idc = [list() for _ in range(n_samples)]\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    for i_iter in range(sim_params[\"n_sources\"]):\n",
    "        # Compute Covariances\n",
    "        current_covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "        current_covs = np.stack([cov/abs(cov).max() for cov in current_covs], axis=0)\n",
    "        \n",
    "        # Predict the sources using the model\n",
    "        estimated_sources = predict(model, current_covs)\n",
    "\n",
    "        # Check stopping criterion\n",
    "        # criterion = estimated_sources.max(axis=1) > 0.5  # Threshold for stopping (arbitrary value\n",
    "        # if criterion:\n",
    "        #     break\n",
    "        estimated_sources_temp = estimated_sources.copy()\n",
    "        for i_sample in range(n_samples):\n",
    "            estimated_sources_temp[i_sample, estimated_dipole_idc[i_sample]] = 0\n",
    "\n",
    "        new_dipole_idc = np.argmax(estimated_sources_temp, axis=1)  # Convert to dipole indices\n",
    "        \n",
    "        for i_idx, new_idx in enumerate(new_dipole_idc):\n",
    "            estimated_dipole_idc[i_idx].append(new_idx)\n",
    "\n",
    "        true_data_matched = np.zeros((n_samples, n_dipoles))\n",
    "        avg_dists = []\n",
    "        for i_sample in range(n_samples):\n",
    "            true_data_matched[i_sample, true_dipoles[i_sample]] = 1\n",
    "            estimated_positions = pos[np.array(estimated_dipole_idc[i_sample])]\n",
    "            true_positions = pos[true_dipoles[i_sample]]\n",
    "            pairwise_dist = cdist(true_positions, estimated_positions)\n",
    "            # select the true positions closest to the estimated ones\n",
    "            true_indices, estimated_indices = linear_sum_assignment(pairwise_dist)\n",
    "            avg_dists.append(pairwise_dist[true_indices, estimated_indices].min(axis=-1).mean())\n",
    "        print(\"average distances: \", round(np.mean(avg_dists), 2))\n",
    "        epoch_distances[epoch] = np.mean(avg_dists)\n",
    "\n",
    "        # Adjust parameters\n",
    "        loss = model.train_on_batch(current_covs, true_data_matched)\n",
    "        print(f\"\\tLoss: {np.mean(loss)}\")\n",
    "\n",
    "        # Outproject the dipoles from the respective data\n",
    "        current_data = wrap_outproject_from_data(current_data, leadfield, estimated_dipole_idc)\n",
    "        # print(f\"\\tResidual: {compute_residual(current_data, new_data)}\")\n",
    "# Save the model\n",
    "# model.save('rap_music_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - progressing number of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "\t\tLoss: -0.307, 0.245\n",
      "\t\tLoss: -0.307, 0.246\n",
      "\t\tLoss: -0.308, 0.248\n",
      "\t\tLoss: -0.309, 0.250\n",
      "\t\tLoss: -0.310, 0.251\n",
      "epoch 1\n",
      "\t\tLoss: -0.311, 0.252\n",
      "\t\tLoss: -0.312, 0.254\n",
      "\t\tLoss: -0.313, 0.255\n",
      "\t\tLoss: -0.313, 0.256\n",
      "\t\tLoss: -0.314, 0.257\n",
      "epoch 2\n",
      "\t\tLoss: -0.315, 0.258\n",
      "\t\tLoss: -0.316, 0.259\n",
      "\t\tLoss: -0.317, 0.261\n",
      "\t\tLoss: -0.317, 0.262\n",
      "\t\tLoss: -0.318, 0.262\n",
      "epoch 3\n",
      "\t\tLoss: -0.319, 0.263\n",
      "\t\tLoss: -0.320, 0.264\n",
      "\t\tLoss: -0.320, 0.265\n",
      "\t\tLoss: -0.321, 0.266\n",
      "\t\tLoss: -0.322, 0.267\n",
      "epoch 4\n",
      "\t\tLoss: -0.323, 0.268\n",
      "\t\tLoss: -0.323, 0.268\n",
      "\t\tLoss: -0.324, 0.269\n",
      "\t\tLoss: -0.325, 0.270\n",
      "\t\tLoss: -0.326, 0.271\n",
      "epoch 5\n",
      "\t\tLoss: -0.326, 0.271\n",
      "\t\tLoss: -0.327, 0.272\n",
      "\t\tLoss: -0.328, 0.273\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from copy import deepcopy\n",
    "\n",
    "batch_size = 1024\n",
    "n_sources = np.arange(5)+1\n",
    "\n",
    "epochs = 1000\n",
    "epoch_distances = np.zeros(epochs)\n",
    "# Training loop within the RAP-MUSIC framework\n",
    "for epoch in range(epochs):  # Number of epochs\n",
    "    print(f\"epoch {epoch}\")\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for n_source in n_sources:\n",
    "        # print(f\"\\ttraining for {n_source} sources\")\n",
    "        sim_params[\"batch_size\"] = batch_size #// n_source\n",
    "        sim_params[\"n_sources\"] = (n_source, n_source)\n",
    "        gen = generator(fwd, **sim_params)\n",
    "        X, true_dipoles, Y = generate_initial_data(gen) \n",
    "        current_data = deepcopy(X)\n",
    "        n_samples = len(true_dipoles)\n",
    "        estimated_dipole_idc = [list() for _ in range(n_samples)]\n",
    "\n",
    "        for i_iter in range(n_source):\n",
    "            # Compute Covariances\n",
    "            current_covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "            current_covs = np.stack([cov/abs(cov).max() for cov in current_covs], axis=0)\n",
    "            X_train.append(current_covs)\n",
    "            # Predict the sources using the model\n",
    "            estimated_sources = model2.predict(current_covs, verbose=0)\n",
    "\n",
    "            \n",
    "            estimated_sources_temp = estimated_sources.copy()\n",
    "            for i_sample in range(n_samples):\n",
    "                estimated_sources_temp[i_sample, estimated_dipole_idc[i_sample]] = 0\n",
    "\n",
    "            new_dipole_idc = np.argmax(estimated_sources_temp, axis=1)  # Convert to dipole indices\n",
    "            \n",
    "            for i_idx, new_idx in enumerate(new_dipole_idc):\n",
    "                estimated_dipole_idc[i_idx].append(new_idx)\n",
    "\n",
    "            true_data_matched = np.zeros((n_samples, n_dipoles))\n",
    "            avg_dists = []\n",
    "            for i_sample in range(n_samples):\n",
    "                true_data_matched[i_sample, true_dipoles[i_sample]] = 1\n",
    "\n",
    "            Y_train.append(true_data_matched)\n",
    "            # Outproject the dipoles from the respective data\n",
    "            current_data = wrap_outproject_from_data(X, leadfield, estimated_dipole_idc)\n",
    "            \n",
    "    # Adjust parameters\n",
    "    for _ in range(5):\n",
    "        loss = model2.train_on_batch(np.concatenate(X_train, axis=0), np.concatenate(Y_train, axis=0))\n",
    "        print(f\"\\t\\tLoss: {np.mean(loss[0]):.3f}, {np.mean(loss[1]):.3f}\")\n",
    "\n",
    "# Save the model\n",
    "model2.save('.rap-weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - variable number of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\tsample 1/64\n",
      "\tsample 2/64\n",
      "\tsample 3/64\n",
      "\tsample 4/64\n",
      "\tsample 5/64\n",
      "\tsample 6/64\n",
      "\tsample 7/64\n",
      "\tsample 8/64\n",
      "\tsample 9/64\n",
      "\tsample 10/64\n",
      "\tsample 11/64\n",
      "\tsample 12/64\n",
      "\tsample 13/64\n",
      "\tsample 14/64\n",
      "\tsample 15/64\n",
      "\tsample 16/64\n",
      "\tsample 17/64\n",
      "\tsample 18/64\n",
      "\tsample 19/64\n",
      "\tsample 20/64\n",
      "\tsample 21/64\n",
      "\tsample 22/64\n",
      "\tsample 23/64\n",
      "\tsample 24/64\n",
      "\tsample 25/64\n",
      "\tsample 26/64\n",
      "\tsample 27/64\n",
      "\tsample 28/64\n",
      "\tsample 29/64\n",
      "\tsample 30/64\n",
      "\tsample 31/64\n",
      "\tsample 32/64\n",
      "\tsample 33/64\n",
      "\tsample 34/64\n",
      "\tsample 35/64\n",
      "\tsample 36/64\n",
      "\tsample 37/64\n",
      "\tsample 38/64\n",
      "\tsample 39/64\n",
      "\tsample 40/64\n",
      "\tsample 41/64\n",
      "\tsample 42/64\n",
      "\tsample 43/64\n",
      "\tsample 44/64\n",
      "\tsample 45/64\n",
      "\tsample 46/64\n",
      "\tsample 47/64\n",
      "\tsample 48/64\n",
      "\tsample 49/64\n",
      "\tsample 50/64\n",
      "\tsample 51/64\n",
      "\tsample 52/64\n",
      "\tsample 53/64\n",
      "\tsample 54/64\n",
      "\tsample 55/64\n",
      "\tsample 56/64\n",
      "\tsample 57/64\n",
      "\tsample 58/64\n",
      "\tsample 59/64\n",
      "\tsample 60/64\n",
      "\tsample 61/64\n",
      "\tsample 62/64\n",
      "\tsample 63/64\n",
      "\tsample 64/64\n",
      "\t\t\tLoss: -0.06881794333457947\n",
      "\t\t\tLoss: -0.06870947033166885\n",
      "\t\t\tLoss: -0.06861625611782074\n",
      "\t\t\tLoss: -0.06854335963726044\n",
      "\t\t\tLoss: -0.06849012523889542\n",
      "\t\t\tLoss: -0.06841747462749481\n",
      "\t\t\tLoss: -0.0683523416519165\n",
      "\t\t\tLoss: -0.06831344217061996\n",
      "\t\t\tLoss: -0.06830259412527084\n",
      "\t\t\tLoss: -0.06829623878002167\n",
      "\t\t\tLoss: -0.0683012530207634\n",
      "\t\t\tLoss: -0.06832465529441833\n",
      "\t\t\tLoss: -0.06832828372716904\n",
      "\t\t\tLoss: -0.06834480911493301\n",
      "\t\t\tLoss: -0.0683877244591713\n",
      "\t\t\tLoss: -0.06843051314353943\n",
      "\t\t\tLoss: -0.06850318610668182\n",
      "\t\t\tLoss: -0.06860573589801788\n",
      "\t\t\tLoss: -0.06872954964637756\n",
      "\t\t\tLoss: -0.06888020038604736\n",
      "\t\t\tLoss: -0.06905660033226013\n",
      "\t\t\tLoss: -0.06924380362033844\n",
      "\t\t\tLoss: -0.06945602595806122\n",
      "\t\t\tLoss: -0.06969122588634491\n",
      "\t\t\tLoss: -0.06994854658842087\n",
      "\t\t\tLoss: -0.07022790610790253\n",
      "\t\t\tLoss: -0.07053597271442413\n",
      "\t\t\tLoss: -0.07084185630083084\n",
      "\t\t\tLoss: -0.07114532589912415\n",
      "\t\t\tLoss: -0.07144621759653091\n",
      "\t\t\tLoss: -0.07176576554775238\n",
      "\t\t\tLoss: -0.07211770117282867\n",
      "\t\t\tLoss: -0.07247951626777649\n",
      "\t\t\tLoss: -0.07285065203905106\n",
      "\t\t\tLoss: -0.07323035597801208\n",
      "\t\t\tLoss: -0.07362528890371323\n",
      "\t\t\tLoss: -0.07402059435844421\n",
      "\t\t\tLoss: -0.07442289590835571\n",
      "\t\t\tLoss: -0.07484575361013412\n",
      "\t\t\tLoss: -0.07528859376907349\n",
      "\t\t\tLoss: -0.07575078308582306\n",
      "\t\t\tLoss: -0.07622450590133667\n",
      "\t\t\tLoss: -0.07668127119541168\n",
      "\t\t\tLoss: -0.07715592533349991\n",
      "\t\t\tLoss: -0.07764091342687607\n",
      "\t\t\tLoss: -0.07813572138547897\n",
      "\t\t\tLoss: -0.07863302528858185\n",
      "\t\t\tLoss: -0.07915329188108444\n",
      "\t\t\tLoss: -0.07966839522123337\n",
      "\t\t\tLoss: -0.08020558208227158\n",
      "\t\t\tLoss: -0.08075061440467834\n",
      "\t\t\tLoss: -0.08131004124879837\n",
      "\t\t\tLoss: -0.08188344538211823\n",
      "\t\t\tLoss: -0.08246367424726486\n",
      "\t\t\tLoss: -0.08305706828832626\n",
      "\t\t\tLoss: -0.08365659415721893\n",
      "\t\t\tLoss: -0.08426862955093384\n",
      "\t\t\tLoss: -0.08487953245639801\n",
      "\t\t\tLoss: -0.08549568057060242\n",
      "\t\t\tLoss: -0.08610357344150543\n",
      "\t\t\tLoss: -0.08674268424510956\n",
      "\t\t\tLoss: -0.08737307786941528\n",
      "\t\t\tLoss: -0.08800771832466125\n",
      "\t\t\tLoss: -0.08863333612680435\n",
      "\t\t\tLoss: -0.08925633132457733\n",
      "\t\t\tLoss: -0.08988957107067108\n",
      "\t\t\tLoss: -0.09051983058452606\n",
      "\t\t\tLoss: -0.09117278456687927\n",
      "\t\t\tLoss: -0.09182874858379364\n",
      "\t\t\tLoss: -0.09248757362365723\n",
      "\t\t\tLoss: -0.09314905107021332\n",
      "\t\t\tLoss: -0.09380665421485901\n",
      "\t\t\tLoss: -0.09446025639772415\n",
      "\t\t\tLoss: -0.09511612355709076\n",
      "\t\t\tLoss: -0.09576773643493652\n",
      "\t\t\tLoss: -0.09640873968601227\n",
      "\t\t\tLoss: -0.09705789387226105\n",
      "\t\t\tLoss: -0.09772126376628876\n",
      "\t\t\tLoss: -0.09838610887527466\n",
      "\t\t\tLoss: -0.099052295088768\n",
      "\t\t\tLoss: -0.09971967339515686\n",
      "\t\t\tLoss: -0.10038195550441742\n",
      "\t\t\tLoss: -0.10104523599147797\n",
      "\t\t\tLoss: -0.10170324146747589\n",
      "\t\t\tLoss: -0.10237420350313187\n",
      "\t\t\tLoss: -0.10303959995508194\n",
      "\t\t\tLoss: -0.10370529443025589\n",
      "\t\t\tLoss: -0.1043829470872879\n",
      "\t\t\tLoss: -0.10504759848117828\n",
      "\t\t\tLoss: -0.10571195185184479\n",
      "\t\t\tLoss: -0.10636568069458008\n",
      "\t\t\tLoss: -0.10702010989189148\n",
      "\t\t\tLoss: -0.10767947882413864\n",
      "\t\t\tLoss: -0.10832685232162476\n",
      "\t\t\tLoss: -0.10897499322891235\n",
      "\t\t\tLoss: -0.10963968932628632\n",
      "\t\t\tLoss: -0.11028586328029633\n",
      "\t\t\tLoss: -0.11094433069229126\n",
      "\t\t\tLoss: -0.11160735785961151\n",
      "\t\t\tLoss: -0.11225789040327072\n",
      "\t\t\tLoss: -0.11290831863880157\n",
      "\t\t\tLoss: -0.11356301605701447\n",
      "\t\t\tLoss: -0.1142052561044693\n",
      "\t\t\tLoss: -0.11484698951244354\n",
      "\t\t\tLoss: -0.11548715829849243\n",
      "\t\t\tLoss: -0.11610911786556244\n",
      "\t\t\tLoss: -0.11674179881811142\n",
      "\t\t\tLoss: -0.11737856268882751\n",
      "\t\t\tLoss: -0.11799711734056473\n",
      "\t\t\tLoss: -0.11861465871334076\n",
      "\t\t\tLoss: -0.11924749612808228\n",
      "\t\t\tLoss: -0.1198619082570076\n",
      "\t\t\tLoss: -0.1204918622970581\n",
      "\t\t\tLoss: -0.12112534046173096\n",
      "\t\t\tLoss: -0.12175705283880234\n",
      "\t\t\tLoss: -0.12237027287483215\n",
      "\t\t\tLoss: -0.12300440669059753\n",
      "\t\t\tLoss: -0.12361498177051544\n",
      "\t\t\tLoss: -0.12422975897789001\n",
      "\t\t\tLoss: -0.12485915422439575\n",
      "\t\t\tLoss: -0.12546992301940918\n",
      "\t\t\tLoss: -0.12609519064426422\n",
      "\t\t\tLoss: -0.1267184168100357\n",
      "\t\t\tLoss: -0.12732364237308502\n",
      "\t\t\tLoss: -0.12792721390724182\n",
      "\t\t\tLoss: -0.12854501605033875\n",
      "\t\t\tLoss: -0.12914982438087463\n",
      "\t\t\tLoss: -0.12975254654884338\n",
      "\t\t\tLoss: -0.13036929070949554\n",
      "\t\t\tLoss: -0.13096243143081665\n",
      "\t\t\tLoss: -0.13156971335411072\n",
      "\t\t\tLoss: -0.13215896487236023\n",
      "\t\t\tLoss: -0.1327514946460724\n",
      "\t\t\tLoss: -0.13334718346595764\n",
      "\t\t\tLoss: -0.13393011689186096\n",
      "\t\t\tLoss: -0.1345108449459076\n",
      "\t\t\tLoss: -0.13508406281471252\n",
      "\t\t\tLoss: -0.13565507531166077\n",
      "\t\t\tLoss: -0.136208176612854\n",
      "\t\t\tLoss: -0.13678526878356934\n",
      "\t\t\tLoss: -0.13732346892356873\n",
      "\t\t\tLoss: -0.13788028061389923\n",
      "\t\t\tLoss: -0.13841387629508972\n",
      "\t\t\tLoss: -0.13897651433944702\n",
      "\t\t\tLoss: -0.13951638340950012\n",
      "\t\t\tLoss: -0.14005422592163086\n",
      "\t\t\tLoss: -0.14061538875102997\n",
      "\t\t\tLoss: -0.14112764596939087\n",
      "\t\t\tLoss: -0.14168453216552734\n",
      "\t\t\tLoss: -0.14220932126045227\n",
      "\t\t\tLoss: -0.14273199439048767\n",
      "\t\t\tLoss: -0.14328768849372864\n",
      "\t\t\tLoss: -0.14379079639911652\n",
      "\t\t\tLoss: -0.1443326771259308\n",
      "\t\t\tLoss: -0.14488214254379272\n",
      "\t\t\tLoss: -0.14539407193660736\n",
      "\t\t\tLoss: -0.14594420790672302\n",
      "\t\t\tLoss: -0.14648710191249847\n",
      "\t\t\tLoss: -0.14701272547245026\n",
      "\t\t\tLoss: -0.14756618440151215\n",
      "\t\t\tLoss: -0.1480925977230072\n",
      "\t\t\tLoss: -0.14861656725406647\n",
      "\t\t\tLoss: -0.14915822446346283\n",
      "\t\t\tLoss: -0.14968308806419373\n",
      "\t\t\tLoss: -0.15020069479942322\n",
      "\t\t\tLoss: -0.1507258415222168\n",
      "\t\t\tLoss: -0.15125377476215363\n",
      "\t\t\tLoss: -0.151755228638649\n",
      "\t\t\tLoss: -0.15227878093719482\n",
      "\t\t\tLoss: -0.15279527008533478\n",
      "\t\t\tLoss: -0.153304785490036\n",
      "\t\t\tLoss: -0.1538168489933014\n",
      "\t\t\tLoss: -0.1543169617652893\n",
      "\t\t\tLoss: -0.15482421219348907\n",
      "\t\t\tLoss: -0.15532854199409485\n",
      "\t\t\tLoss: -0.15582957863807678\n",
      "\t\t\tLoss: -0.1563425064086914\n",
      "\t\t\tLoss: -0.15682612359523773\n",
      "\t\t\tLoss: -0.15731358528137207\n",
      "\t\t\tLoss: -0.15780311822891235\n",
      "\t\t\tLoss: -0.15828536450862885\n",
      "\t\t\tLoss: -0.15878039598464966\n",
      "\t\t\tLoss: -0.1592501699924469\n",
      "\t\t\tLoss: -0.1597408950328827\n",
      "\t\t\tLoss: -0.1602204293012619\n",
      "\t\t\tLoss: -0.16067031025886536\n",
      "\t\t\tLoss: -0.16114123165607452\n",
      "\t\t\tLoss: -0.16158704459667206\n",
      "\t\t\tLoss: -0.16203121840953827\n",
      "\t\t\tLoss: -0.16250567138195038\n",
      "\t\t\tLoss: -0.16294589638710022\n",
      "\t\t\tLoss: -0.16338446736335754\n",
      "\t\t\tLoss: -0.16384394466876984\n",
      "\t\t\tLoss: -0.16427406668663025\n",
      "\t\t\tLoss: -0.16471625864505768\n",
      "\t\t\tLoss: -0.16516560316085815\n",
      "\t\t\tLoss: -0.165603905916214\n",
      "\t\t\tLoss: -0.16605406999588013\n",
      "\t\t\tLoss: -0.16651582717895508\n",
      "\t\t\tLoss: -0.16695302724838257\n",
      "\t\t\tLoss: -0.16740180552005768\n",
      "\t\t\tLoss: -0.16784408688545227\n",
      "\t\t\tLoss: -0.16829310357570648\n",
      "\t\t\tLoss: -0.1687488704919815\n",
      "\t\t\tLoss: -0.16920220851898193\n",
      "\t\t\tLoss: -0.16962720453739166\n",
      "\t\t\tLoss: -0.1700730323791504\n",
      "\t\t\tLoss: -0.1705000102519989\n",
      "\t\t\tLoss: -0.17092537879943848\n",
      "\t\t\tLoss: -0.17135749757289886\n",
      "\t\t\tLoss: -0.17177435755729675\n",
      "\t\t\tLoss: -0.17220699787139893\n",
      "\t\t\tLoss: -0.17264260351657867\n",
      "\t\t\tLoss: -0.17306354641914368\n",
      "\t\t\tLoss: -0.17349570989608765\n",
      "\t\t\tLoss: -0.17392152547836304\n",
      "\t\t\tLoss: -0.1743541955947876\n",
      "\t\t\tLoss: -0.17478534579277039\n",
      "\t\t\tLoss: -0.17521479725837708\n",
      "\t\t\tLoss: -0.17565105855464935\n",
      "\t\t\tLoss: -0.1760639101266861\n",
      "\t\t\tLoss: -0.17647932469844818\n",
      "\t\t\tLoss: -0.17690172791481018\n",
      "\t\t\tLoss: -0.17730966210365295\n",
      "\t\t\tLoss: -0.17773720622062683\n",
      "\t\t\tLoss: -0.17814591526985168\n",
      "\t\t\tLoss: -0.17855292558670044\n",
      "\t\t\tLoss: -0.17897531390190125\n",
      "\t\t\tLoss: -0.17937487363815308\n",
      "\t\t\tLoss: -0.1797896921634674\n",
      "\t\t\tLoss: -0.1801985800266266\n",
      "\t\t\tLoss: -0.18062257766723633\n",
      "\t\t\tLoss: -0.18102386593818665\n",
      "\t\t\tLoss: -0.1814444363117218\n",
      "\t\t\tLoss: -0.18185073137283325\n",
      "\t\t\tLoss: -0.18227186799049377\n",
      "\t\t\tLoss: -0.1826743185520172\n",
      "\t\t\tLoss: -0.18307027220726013\n",
      "\t\t\tLoss: -0.18345987796783447\n",
      "\t\t\tLoss: -0.18385624885559082\n",
      "\t\t\tLoss: -0.1842564046382904\n",
      "\t\t\tLoss: -0.18467208743095398\n",
      "\t\t\tLoss: -0.1850651204586029\n",
      "\t\t\tLoss: -0.185460165143013\n",
      "\t\t\tLoss: -0.18586644530296326\n",
      "\t\t\tLoss: -0.18625932931900024\n",
      "\t\t\tLoss: -0.18665429949760437\n",
      "\t\t\tLoss: -0.18704754114151\n",
      "\t\t\tLoss: -0.18743160367012024\n",
      "\t\t\tLoss: -0.18783441185951233\n",
      "\t\t\tLoss: -0.1882191151380539\n",
      "\t\t\tLoss: -0.18860656023025513\n",
      "\t\t\tLoss: -0.18900072574615479\n",
      "\t\t\tLoss: -0.18939314782619476\n",
      "\t\t\tLoss: -0.18977200984954834\n",
      "\t\t\tLoss: -0.1901455819606781\n",
      "\t\t\tLoss: -0.1905335634946823\n",
      "\t\t\tLoss: -0.1909080147743225\n",
      "\t\t\tLoss: -0.19128909707069397\n",
      "\t\t\tLoss: -0.1916607916355133\n",
      "\t\t\tLoss: -0.19203487038612366\n",
      "\t\t\tLoss: -0.19240757822990417\n",
      "\t\t\tLoss: -0.19277101755142212\n",
      "\t\t\tLoss: -0.19313301146030426\n",
      "\t\t\tLoss: -0.19349360466003418\n",
      "\t\t\tLoss: -0.1938646137714386\n",
      "\t\t\tLoss: -0.19422250986099243\n",
      "\t\t\tLoss: -0.19457504153251648\n",
      "\t\t\tLoss: -0.19493791460990906\n",
      "\t\t\tLoss: -0.1952800303697586\n",
      "\t\t\tLoss: -0.1956363171339035\n",
      "\t\t\tLoss: -0.19597959518432617\n",
      "\t\t\tLoss: -0.19632546603679657\n",
      "\t\t\tLoss: -0.19666612148284912\n",
      "\t\t\tLoss: -0.19700929522514343\n",
      "\t\t\tLoss: -0.1973317265510559\n",
      "\t\t\tLoss: -0.1976795196533203\n",
      "\t\t\tLoss: -0.19800221920013428\n",
      "\t\t\tLoss: -0.19834980368614197\n",
      "\t\t\tLoss: -0.19866859912872314\n",
      "\t\t\tLoss: -0.19900676608085632\n",
      "\t\t\tLoss: -0.1993447244167328\n",
      "\t\t\tLoss: -0.19963958859443665\n",
      "\t\t\tLoss: -0.19998198747634888\n",
      "\t\t\tLoss: -0.20030799508094788\n",
      "\t\t\tLoss: -0.20062220096588135\n",
      "\t\t\tLoss: -0.20097264647483826\n",
      "\t\t\tLoss: -0.20126892626285553\n",
      "\t\t\tLoss: -0.2016095519065857\n",
      "\t\t\tLoss: -0.20193038880825043\n",
      "\t\t\tLoss: -0.20222723484039307\n",
      "\t\t\tLoss: -0.2025715708732605\n",
      "\t\t\tLoss: -0.2028851956129074\n",
      "\t\t\tLoss: -0.20319008827209473\n",
      "\t\t\tLoss: -0.20353087782859802\n",
      "\t\t\tLoss: -0.20383727550506592\n",
      "\t\t\tLoss: -0.20413514971733093\n",
      "\t\t\tLoss: -0.20445767045021057\n",
      "\t\t\tLoss: -0.20474600791931152\n",
      "\t\t\tLoss: -0.20504802465438843\n",
      "Epoch 2/50\n",
      "\tsample 1/64\n",
      "\tsample 2/64\n",
      "\tsample 3/64\n",
      "\tsample 4/64\n",
      "\tsample 5/64\n",
      "\tsample 6/64\n",
      "\tsample 7/64\n",
      "\tsample 8/64\n",
      "\tsample 9/64\n",
      "\tsample 10/64\n",
      "\tsample 11/64\n",
      "\tsample 12/64\n",
      "\tsample 13/64\n",
      "\tsample 14/64\n",
      "\tsample 15/64\n",
      "\tsample 16/64\n",
      "\tsample 17/64\n",
      "\tsample 18/64\n",
      "\tsample 19/64\n",
      "\tsample 20/64\n",
      "\tsample 21/64\n",
      "\tsample 22/64\n",
      "\tsample 23/64\n",
      "\tsample 24/64\n",
      "\tsample 25/64\n",
      "\tsample 26/64\n",
      "\tsample 27/64\n",
      "\tsample 28/64\n",
      "\tsample 29/64\n",
      "\tsample 30/64\n",
      "\tsample 31/64\n",
      "\tsample 32/64\n",
      "\tsample 33/64\n",
      "\tsample 34/64\n",
      "\tsample 35/64\n",
      "\tsample 36/64\n",
      "\tsample 37/64\n",
      "\tsample 38/64\n",
      "\tsample 39/64\n",
      "\tsample 40/64\n",
      "\tsample 41/64\n",
      "\tsample 42/64\n",
      "\tsample 43/64\n",
      "\tsample 44/64\n",
      "\tsample 45/64\n",
      "\tsample 46/64\n",
      "\tsample 47/64\n",
      "\tsample 48/64\n",
      "\tsample 49/64\n",
      "\tsample 50/64\n",
      "\tsample 51/64\n",
      "\tsample 52/64\n",
      "\tsample 53/64\n",
      "\tsample 54/64\n",
      "\tsample 55/64\n",
      "\tsample 56/64\n",
      "\tsample 57/64\n",
      "\tsample 58/64\n",
      "\tsample 59/64\n",
      "\tsample 60/64\n",
      "\tsample 61/64\n",
      "\tsample 62/64\n",
      "\tsample 63/64\n",
      "\tsample 64/64\n",
      "\t\t\tLoss: -0.2046927809715271\n",
      "\t\t\tLoss: -0.20436811447143555\n",
      "\t\t\tLoss: -0.20405355095863342\n",
      "\t\t\tLoss: -0.20376262068748474\n",
      "\t\t\tLoss: -0.20347166061401367\n",
      "\t\t\tLoss: -0.20320022106170654\n",
      "\t\t\tLoss: -0.20291849970817566\n",
      "\t\t\tLoss: -0.20262253284454346\n",
      "\t\t\tLoss: -0.20233309268951416\n",
      "\t\t\tLoss: -0.2020590901374817\n",
      "\t\t\tLoss: -0.20180551707744598\n",
      "\t\t\tLoss: -0.20157012343406677\n",
      "\t\t\tLoss: -0.20135843753814697\n",
      "\t\t\tLoss: -0.20116204023361206\n",
      "\t\t\tLoss: -0.20097273588180542\n",
      "\t\t\tLoss: -0.20080065727233887\n",
      "\t\t\tLoss: -0.20064517855644226\n",
      "\t\t\tLoss: -0.2004844844341278\n",
      "\t\t\tLoss: -0.2003358155488968\n",
      "\t\t\tLoss: -0.2002127319574356\n",
      "\t\t\tLoss: -0.20010769367218018\n",
      "\t\t\tLoss: -0.2000202238559723\n",
      "\t\t\tLoss: -0.19994986057281494\n",
      "\t\t\tLoss: -0.19988533854484558\n",
      "\t\t\tLoss: -0.19983655214309692\n",
      "\t\t\tLoss: -0.19979581236839294\n",
      "\t\t\tLoss: -0.19977673888206482\n",
      "\t\t\tLoss: -0.1997716724872589\n",
      "\t\t\tLoss: -0.19977661967277527\n",
      "\t\t\tLoss: -0.19979795813560486\n",
      "\t\t\tLoss: -0.19982823729515076\n",
      "\t\t\tLoss: -0.19986698031425476\n",
      "\t\t\tLoss: -0.1999104619026184\n",
      "\t\t\tLoss: -0.19996514916419983\n",
      "\t\t\tLoss: -0.20003420114517212\n",
      "\t\t\tLoss: -0.20011714100837708\n",
      "\t\t\tLoss: -0.20021021366119385\n",
      "\t\t\tLoss: -0.20030619204044342\n",
      "\t\t\tLoss: -0.2004013955593109\n",
      "\t\t\tLoss: -0.2005023956298828\n",
      "\t\t\tLoss: -0.2006089687347412\n",
      "\t\t\tLoss: -0.20072084665298462\n",
      "\t\t\tLoss: -0.20083439350128174\n",
      "\t\t\tLoss: -0.20094937086105347\n",
      "\t\t\tLoss: -0.20106901228427887\n",
      "\t\t\tLoss: -0.20119652152061462\n",
      "\t\t\tLoss: -0.20133166015148163\n",
      "\t\t\tLoss: -0.20146748423576355\n",
      "\t\t\tLoss: -0.20160718262195587\n",
      "\t\t\tLoss: -0.20175060629844666\n",
      "\t\t\tLoss: -0.2019043117761612\n",
      "\t\t\tLoss: -0.20206469297409058\n",
      "\t\t\tLoss: -0.20223501324653625\n",
      "\t\t\tLoss: -0.2024083435535431\n",
      "\t\t\tLoss: -0.20257799327373505\n",
      "\t\t\tLoss: -0.202743798494339\n",
      "\t\t\tLoss: -0.20290905237197876\n",
      "\t\t\tLoss: -0.20307691395282745\n",
      "\t\t\tLoss: -0.2032473236322403\n",
      "\t\t\tLoss: -0.20343664288520813\n",
      "\t\t\tLoss: -0.2036249041557312\n",
      "\t\t\tLoss: -0.20381863415241241\n",
      "\t\t\tLoss: -0.20401445031166077\n",
      "\t\t\tLoss: -0.20420892536640167\n",
      "\t\t\tLoss: -0.20440861582756042\n",
      "\t\t\tLoss: -0.2046133279800415\n",
      "\t\t\tLoss: -0.20481981337070465\n",
      "\t\t\tLoss: -0.20502793788909912\n",
      "\t\t\tLoss: -0.20524084568023682\n",
      "\t\t\tLoss: -0.20545201003551483\n",
      "\t\t\tLoss: -0.20565810799598694\n",
      "\t\t\tLoss: -0.20587530732154846\n",
      "\t\t\tLoss: -0.20609375834465027\n",
      "\t\t\tLoss: -0.20631346106529236\n",
      "\t\t\tLoss: -0.20652782917022705\n",
      "\t\t\tLoss: -0.20674654841423035\n",
      "\t\t\tLoss: -0.20696309208869934\n",
      "\t\t\tLoss: -0.20717746019363403\n",
      "\t\t\tLoss: -0.20738957822322845\n",
      "\t\t\tLoss: -0.2075994312763214\n",
      "\t\t\tLoss: -0.20780697464942932\n",
      "\t\t\tLoss: -0.20800897479057312\n",
      "\t\t\tLoss: -0.20821182429790497\n",
      "\t\t\tLoss: -0.2084154337644577\n",
      "\t\t\tLoss: -0.20862294733524323\n",
      "\t\t\tLoss: -0.20883426070213318\n",
      "\t\t\tLoss: -0.20905250310897827\n",
      "\t\t\tLoss: -0.2092745006084442\n",
      "\t\t\tLoss: -0.20949384570121765\n",
      "\t\t\tLoss: -0.2097136676311493\n",
      "\t\t\tLoss: -0.20993709564208984\n",
      "\t\t\tLoss: -0.21016094088554382\n",
      "\t\t\tLoss: -0.21038511395454407\n",
      "\t\t\tLoss: -0.21060656011104584\n",
      "\t\t\tLoss: -0.21082830429077148\n",
      "\t\t\tLoss: -0.21104413270950317\n",
      "\t\t\tLoss: -0.21126019954681396\n",
      "\t\t\tLoss: -0.21147657930850983\n",
      "\t\t\tLoss: -0.2116931825876236\n",
      "\t\t\tLoss: -0.21190688014030457\n",
      "\t\t\tLoss: -0.21211767196655273\n",
      "\t\t\tLoss: -0.21232862770557404\n",
      "\t\t\tLoss: -0.21253976225852966\n",
      "\t\t\tLoss: -0.21274793148040771\n",
      "\t\t\tLoss: -0.21295621991157532\n",
      "\t\t\tLoss: -0.21316154301166534\n",
      "\t\t\tLoss: -0.213363915681839\n",
      "\t\t\tLoss: -0.21356329321861267\n",
      "\t\t\tLoss: -0.21376270055770874\n",
      "\t\t\tLoss: -0.21396219730377197\n",
      "\t\t\tLoss: -0.21415865421295166\n",
      "\t\t\tLoss: -0.21435514092445374\n",
      "\t\t\tLoss: -0.21455159783363342\n",
      "\t\t\tLoss: -0.2147480547428131\n",
      "\t\t\tLoss: -0.21494147181510925\n",
      "\t\t\tLoss: -0.21513482928276062\n",
      "\t\t\tLoss: -0.215328186750412\n",
      "\t\t\tLoss: -0.215521439909935\n",
      "\t\t\tLoss: -0.21571463346481323\n",
      "\t\t\tLoss: -0.21590769290924072\n",
      "\t\t\tLoss: -0.21610066294670105\n",
      "\t\t\tLoss: -0.2162935435771942\n",
      "\t\t\tLoss: -0.21648924052715302\n",
      "\t\t\tLoss: -0.21668481826782227\n",
      "\t\t\tLoss: -0.21688023209571838\n",
      "\t\t\tLoss: -0.21707549691200256\n",
      "\t\t\tLoss: -0.21726757287979126\n",
      "\t\t\tLoss: -0.21745947003364563\n",
      "\t\t\tLoss: -0.21765121817588806\n",
      "\t\t\tLoss: -0.2178427278995514\n",
      "\t\t\tLoss: -0.2180340588092804\n",
      "\t\t\tLoss: -0.21822220087051392\n",
      "\t\t\tLoss: -0.21840721368789673\n",
      "\t\t\tLoss: -0.21859200298786163\n",
      "\t\t\tLoss: -0.21877658367156982\n",
      "\t\t\tLoss: -0.2189638465642929\n",
      "\t\t\tLoss: -0.21915671229362488\n",
      "\t\t\tLoss: -0.21934932470321655\n",
      "\t\t\tLoss: -0.21954163908958435\n",
      "\t\t\tLoss: -0.21973659098148346\n",
      "\t\t\tLoss: -0.2199370563030243\n",
      "\t\t\tLoss: -0.22013717889785767\n",
      "\t\t\tLoss: -0.22033700346946716\n",
      "\t\t\tLoss: -0.2205365002155304\n",
      "\t\t\tLoss: -0.22073854506015778\n",
      "\t\t\tLoss: -0.2209402322769165\n",
      "\t\t\tLoss: -0.22114157676696777\n",
      "\t\t\tLoss: -0.22134257853031158\n",
      "\t\t\tLoss: -0.22154033184051514\n",
      "\t\t\tLoss: -0.22174058854579926\n",
      "\t\t\tLoss: -0.22194337844848633\n",
      "\t\t\tLoss: -0.22214291989803314\n",
      "\t\t\tLoss: -0.22234207391738892\n",
      "\t\t\tLoss: -0.22254085540771484\n",
      "\t\t\tLoss: -0.22274208068847656\n",
      "\t\t\tLoss: -0.22293725609779358\n",
      "\t\t\tLoss: -0.2231292426586151\n",
      "\t\t\tLoss: -0.2233208268880844\n",
      "\t\t\tLoss: -0.22351206839084625\n",
      "\t\t\tLoss: -0.2237057387828827\n",
      "\t\t\tLoss: -0.22390183806419373\n",
      "\t\t\tLoss: -0.22409752011299133\n",
      "\t\t\tLoss: -0.2242928296327591\n",
      "\t\t\tLoss: -0.2244848906993866\n",
      "\t\t\tLoss: -0.22467941045761108\n",
      "\t\t\tLoss: -0.2248706966638565\n",
      "\t\t\tLoss: -0.2250615954399109\n",
      "\t\t\tLoss: -0.22525209188461304\n",
      "\t\t\tLoss: -0.2254449725151062\n",
      "\t\t\tLoss: -0.22563186287879944\n",
      "\t\t\tLoss: -0.22581833600997925\n",
      "\t\t\tLoss: -0.22600999474525452\n",
      "\t\t\tLoss: -0.2262040078639984\n",
      "\t\t\tLoss: -0.22640308737754822\n",
      "\t\t\tLoss: -0.2266017496585846\n",
      "\t\t\tLoss: -0.22679448127746582\n",
      "\t\t\tLoss: -0.22698675096035004\n",
      "\t\t\tLoss: -0.22717857360839844\n",
      "\t\t\tLoss: -0.2273699939250946\n",
      "\t\t\tLoss: -0.22756095230579376\n",
      "\t\t\tLoss: -0.2277514934539795\n",
      "\t\t\tLoss: -0.227941632270813\n",
      "\t\t\tLoss: -0.22813130915164948\n",
      "\t\t\tLoss: -0.22832328081130981\n",
      "\t\t\tLoss: -0.2285175621509552\n",
      "\t\t\tLoss: -0.22871136665344238\n",
      "\t\t\tLoss: -0.22890476882457733\n",
      "\t\t\tLoss: -0.22909769415855408\n",
      "\t\t\tLoss: -0.229290172457695\n",
      "\t\t\tLoss: -0.22948220372200012\n",
      "\t\t\tLoss: -0.2296764850616455\n",
      "\t\t\tLoss: -0.22986763715744019\n",
      "\t\t\tLoss: -0.2300529181957245\n",
      "\t\t\tLoss: -0.23023776710033417\n",
      "\t\t\tLoss: -0.23041948676109314\n",
      "\t\t\tLoss: -0.23060081899166107\n",
      "\t\t\tLoss: -0.23078171908855438\n",
      "\t\t\tLoss: -0.23096218705177307\n",
      "\t\t\tLoss: -0.23114225268363953\n",
      "\t\t\tLoss: -0.23132984340190887\n",
      "\t\t\tLoss: -0.2315170168876648\n",
      "\t\t\tLoss: -0.2317037731409073\n",
      "\t\t\tLoss: -0.23189003765583038\n",
      "\t\t\tLoss: -0.23207589983940125\n",
      "\t\t\tLoss: -0.2322613000869751\n",
      "\t\t\tLoss: -0.23244094848632812\n",
      "\t\t\tLoss: -0.23262019455432892\n",
      "\t\t\tLoss: -0.2328016608953476\n",
      "\t\t\tLoss: -0.23298268020153046\n",
      "\t\t\tLoss: -0.2331632375717163\n",
      "\t\t\tLoss: -0.23334340751171112\n",
      "\t\t\tLoss: -0.2335204929113388\n",
      "\t\t\tLoss: -0.23369717597961426\n",
      "\t\t\tLoss: -0.2338734269142151\n",
      "\t\t\tLoss: -0.2340492457151413\n",
      "\t\t\tLoss: -0.23422466218471527\n",
      "\t\t\tLoss: -0.23439964652061462\n",
      "\t\t\tLoss: -0.23457422852516174\n",
      "\t\t\tLoss: -0.23475097119808197\n",
      "\t\t\tLoss: -0.23492729663848877\n",
      "\t\t\tLoss: -0.2351083755493164\n",
      "\t\t\tLoss: -0.23528644442558289\n",
      "\t\t\tLoss: -0.23546148836612701\n",
      "\t\t\tLoss: -0.2356361448764801\n",
      "\t\t\tLoss: -0.23581290245056152\n",
      "\t\t\tLoss: -0.2359892576932907\n",
      "\t\t\tLoss: -0.23616519570350647\n",
      "\t\t\tLoss: -0.2363407015800476\n",
      "\t\t\tLoss: -0.2365158051252365\n",
      "\t\t\tLoss: -0.23669305443763733\n",
      "\t\t\tLoss: -0.23686981201171875\n",
      "\t\t\tLoss: -0.23704619705677032\n",
      "\t\t\tLoss: -0.23722214996814728\n",
      "\t\t\tLoss: -0.2373976707458496\n",
      "\t\t\tLoss: -0.2375727891921997\n",
      "\t\t\tLoss: -0.2377474457025528\n",
      "\t\t\tLoss: -0.23792168498039246\n",
      "\t\t\tLoss: -0.23809555172920227\n",
      "\t\t\tLoss: -0.2382740080356598\n",
      "\t\t\tLoss: -0.23844954371452332\n",
      "\t\t\tLoss: -0.2386246621608734\n",
      "\t\t\tLoss: -0.2387993335723877\n",
      "\t\t\tLoss: -0.23897358775138855\n",
      "\t\t\tLoss: -0.23914743959903717\n",
      "\t\t\tLoss: -0.23932336270809174\n",
      "\t\t\tLoss: -0.23949888348579407\n",
      "\t\t\tLoss: -0.2396739423274994\n",
      "\t\t\tLoss: -0.23984861373901367\n",
      "\t\t\tLoss: -0.24002037942409515\n",
      "\t\t\tLoss: -0.24019169807434082\n",
      "\t\t\tLoss: -0.24036511778831482\n",
      "\t\t\tLoss: -0.24053815007209778\n",
      "\t\t\tLoss: -0.24071070551872253\n",
      "\t\t\tLoss: -0.24088537693023682\n",
      "\t\t\tLoss: -0.24105963110923767\n",
      "\t\t\tLoss: -0.24123342335224152\n",
      "\t\t\tLoss: -0.24140435457229614\n",
      "\t\t\tLoss: -0.24157488346099854\n",
      "\t\t\tLoss: -0.2417449653148651\n",
      "\t\t\tLoss: -0.24191468954086304\n",
      "\t\t\tLoss: -0.24208642542362213\n",
      "\t\t\tLoss: -0.24225780367851257\n",
      "\t\t\tLoss: -0.24242624640464783\n",
      "\t\t\tLoss: -0.24259188771247864\n",
      "\t\t\tLoss: -0.2427571415901184\n",
      "\t\t\tLoss: -0.24292200803756714\n",
      "\t\t\tLoss: -0.24308647215366364\n",
      "\t\t\tLoss: -0.2432505190372467\n",
      "\t\t\tLoss: -0.24341420829296112\n",
      "\t\t\tLoss: -0.2435774803161621\n",
      "\t\t\tLoss: -0.24374037981033325\n",
      "\t\t\tLoss: -0.24390289187431335\n",
      "\t\t\tLoss: -0.24406501650810242\n",
      "\t\t\tLoss: -0.24422675371170044\n",
      "\t\t\tLoss: -0.24438568949699402\n",
      "\t\t\tLoss: -0.24454182386398315\n",
      "\t\t\tLoss: -0.24469763040542603\n",
      "\t\t\tLoss: -0.24485301971435547\n",
      "\t\t\tLoss: -0.24500808119773865\n",
      "\t\t\tLoss: -0.2451627552509308\n",
      "\t\t\tLoss: -0.24531710147857666\n",
      "\t\t\tLoss: -0.2454710602760315\n",
      "\t\t\tLoss: -0.24562229216098785\n",
      "\t\t\tLoss: -0.245775505900383\n",
      "\t\t\tLoss: -0.24592837691307068\n",
      "\t\t\tLoss: -0.2460809051990509\n",
      "\t\t\tLoss: -0.24623307585716248\n",
      "\t\t\tLoss: -0.2463849037885666\n",
      "\t\t\tLoss: -0.24653637409210205\n",
      "\t\t\tLoss: -0.24668510258197784\n",
      "\t\t\tLoss: -0.24683347344398499\n",
      "\t\t\tLoss: -0.24697913229465485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# Adjust parameters\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Training on the past iterations\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_train_cycles):\n\u001b[1;32m---> 65\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(loss)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# model.save('rap_music_model.h5')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:540\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 540\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "gen = generator(fwd, **sim_params)\n",
    "\n",
    "epochs = 50\n",
    "samples_per_epoch = 64\n",
    "n_train_cycles = 300\n",
    "\n",
    "# Training loop within the RAP-MUSIC framework\n",
    "for epoch in range(epochs):  # Number of epochs\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    # epoch_distances = np.zeros(samples_per_epoch)\n",
    "    for ii in range(samples_per_epoch):\n",
    "        print(f\"\\tsample {ii+1}/{samples_per_epoch}\")\n",
    "        current_data, true_dipoles, Y = generate_initial_data(gen)\n",
    "        n_samples = len(true_dipoles)\n",
    "        n_candidates = len(true_dipoles[0])\n",
    "        estimated_dipole_idc = [list() for _ in range(n_samples)]\n",
    "        \n",
    "        for n_candidate in range(n_candidates):\n",
    "            # print(f\"\\t\\tDipole {n_candidate+1}/{n_candidates}\")\n",
    "            # Compute Covariances\n",
    "            current_covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "            current_covs = np.stack([cov/abs(cov).max() for cov in current_covs], axis=0)\n",
    "            \n",
    "            # Predict the sources using the model\n",
    "            estimated_sources = model.predict(current_covs, verbose=0)  # Model's prediction\n",
    "            X_train.append(current_covs)\n",
    "\n",
    "            # Check stopping criterion\n",
    "            # criterion = estimated_sources.max(axis=1) > 0.5  # Threshold for stopping (arbitrary value\n",
    "            # if criterion:\n",
    "            #     break\n",
    "            estimated_sources_temp = estimated_sources.copy()\n",
    "            for i_sample in range(n_samples):\n",
    "                estimated_sources_temp[i_sample, estimated_dipole_idc[i_sample]] = 0\n",
    "\n",
    "            new_dipole_idc = np.argmax(estimated_sources_temp, axis=1)  # Convert to dipole indices\n",
    "            \n",
    "            for i_idx, new_idx in enumerate(new_dipole_idc):\n",
    "                estimated_dipole_idc[i_idx].append(new_idx)\n",
    "\n",
    "            true_data_matched = np.zeros((n_samples, n_dipoles))\n",
    "            avg_dists = []\n",
    "            for i_sample in range(n_samples):\n",
    "                true_data_matched[i_sample, true_dipoles[i_sample]] = 1\n",
    "                # estimated_positions = pos[np.array(estimated_dipole_idc[i_sample])]\n",
    "                # true_positions = pos[true_dipoles[i_sample]]\n",
    "                # pairwise_dist = cdist(true_positions, estimated_positions)\n",
    "                # # select the true positions closest to the estimated ones\n",
    "                # true_indices, estimated_indices = linear_sum_assignment(pairwise_dist)\n",
    "                # avg_dists.append(pairwise_dist[true_indices, estimated_indices].min(axis=-1).mean())\n",
    "            # print(\"average distances: \", round(np.mean(avg_dists), 2))\n",
    "            # epoch_distances[epoch] = np.mean(avg_dists)\n",
    "            Y_train.append(true_data_matched)\n",
    "            \n",
    "            # Outproject the dipoles from the respective data\n",
    "            current_data = wrap_outproject_from_data(current_data, leadfield, estimated_dipole_idc)\n",
    "\n",
    "    # Adjust parameters\n",
    "    # Training on the past iterations\n",
    "    for _ in range(n_train_cycles):\n",
    "        loss = model.train_on_batch(np.concatenate(X_train, axis=0), np.concatenate(Y_train, axis=0))\n",
    "        print(f\"\\t\\t\\tLoss: {np.mean(loss)}\")\n",
    "            \n",
    "\n",
    "# Save the model\n",
    "# model.save('rap_music_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "MLE: 19.27 mm\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from copy import deepcopy\n",
    "sim_params_temp = deepcopy(sim_params)\n",
    "sim_params_temp[\"batch_size\"] = 1\n",
    "sim_params_temp[\"n_sources\"] = 3\n",
    "sim_params_temp[\"inter_source_correlation\"] = 0.9\n",
    "\n",
    "sim_params_temp[\"correlation_mode\"] = None\n",
    "# sim_params_temp[\"correlation_mode\"] = \"cholesky\"\n",
    "sim_params_temp[\"noise_color_coeff\"] = 0.5\n",
    "\n",
    "sim_params_temp[\"snr_range\"] = (1, 1)\n",
    "sim_params_temp[\"amplitude_range\"] = (1, 1)\n",
    "\n",
    "idx = 0\n",
    "\n",
    "gen = generator(fwd, **sim_params_temp)\n",
    "X, true_indices, Y = generate_initial_data(gen)\n",
    "current_data = deepcopy(X)\n",
    "# Compute Covariances\n",
    "covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "estimated_idc = [np.array([]) for _ in range(len(current_data))]\n",
    "\n",
    "for i_iter in range(sim_params_temp[\"n_sources\"]):\n",
    "    estimated_sources = model2.predict(covs)\n",
    "    estimated_sources = np.stack([yy / yy.max() for yy in estimated_sources], axis=0)\n",
    "    estimated_sources_temp = estimated_sources.copy()\n",
    "    for i_sample in range(len(current_data)):\n",
    "        if i_iter > 0:\n",
    "            estimated_sources_temp[i_sample, estimated_idc[i_sample]] = 0\n",
    "        estimated_idc[i_sample] = np.append( estimated_idc[i_sample], np.argmax(estimated_sources_temp[i_sample]) ).astype(int)\n",
    "\n",
    "    \n",
    "\n",
    "    stc_ = mne.SourceEstimate(estimated_sources[idx], vertices, tmin=0, tstep=1/1000, \n",
    "                            subject=\"fsaverage\", verbose=0)\n",
    "    \n",
    "    mne.EvokedArray(current_data[idx], info).plot_topomap()\n",
    "    \n",
    "    brain = stc_.plot(brain_kwargs=dict(title=f\"Est. Source {i_iter+1}\"), **pp)\n",
    "    brain.add_text(0.1, 0.9, f\"Est. Source {i_iter+1}\", 'title',\n",
    "               font_size=14)\n",
    "\n",
    "    # selected_idx = np.argmax(stc_.data[:, 0])\n",
    "    # if pos[selected_idx, 0] < 0:\n",
    "    #     brain.add_foci(selected_idx, hemi=\"lh\", coords_as_verts=True, color=\"blue\", alpha=1)\n",
    "    # else:\n",
    "    #     brain.add_foci(selected_idx, hemi=\"rh\", coords_as_verts=True, color=\"blue\", alpha=1)\n",
    "\n",
    "\n",
    "    current_data = wrap_outproject_from_data(X.copy(), leadfield, estimated_idc, alpha=0)\n",
    "    # estimated_idc_trimmed = [np.array([es[-1],]) for es in estimated_idc]\n",
    "    # current_data = wrap_outproject_from_data(current_data, leadfield, estimated_idc_trimmed)\n",
    "\n",
    "    covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "    covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "\n",
    "estimated_positions = pos[estimated_idc[idx]]\n",
    "true_positions = pos[true_indices[idx]]\n",
    "pairwise_dist = cdist(true_positions, estimated_positions)\n",
    "# select the true positions closest to the estimated ones\n",
    "true_sub_idc, estimated_sub_idc = linear_sum_assignment(pairwise_dist)\n",
    "mle = pairwise_dist[true_sub_idc, estimated_sub_idc].mean()\n",
    "print(f\"MLE: {mle:.2f} mm\")\n",
    "\n",
    "L = leadfield[:, estimated_idc[idx]]\n",
    "gradients = np.zeros((n_dipoles, len(estimated_idc[idx])))\n",
    "for ii, estimated_idx in enumerate(estimated_idc[idx]):\n",
    "    gradients[estimated_idx, ii] = 1\n",
    "Y_est = gradients @ L.T @ np.linalg.pinv(L @ L.T)\n",
    "stc_.data = Y_est\n",
    "brain = stc_.plot(brain_kwargs=dict(title=\"Final Source Estimate\"), **pp)\n",
    "brain.add_text(0.1, 0.9, \"Final Source Estimate\", 'title',\n",
    "               font_size=14)\n",
    "\n",
    "stc_.data = Y[idx]\n",
    "brain = stc_.plot(brain_kwargs=dict(title=\"Ground Truth\"), **pp)\n",
    "brain.add_text(0.1, 0.9, \"Ground Truth\", 'title',\n",
    "               font_size=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternating Projections, mle = 27.52 mm\n"
     ]
    }
   ],
   "source": [
    "from invert import Solver\n",
    "n_sources = sim_params_temp[\"n_sources\"]\n",
    "evoked = mne.EvokedArray(X[idx], info)\n",
    "solver = Solver(\"ap\")\n",
    "solver.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=True, n=n_sources, \n",
    "                             k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=10)\n",
    "\n",
    "stc_ = solver.apply_inverse_operator(evoked)\n",
    "# stc_.data /= abs(stc_.data).max()\n",
    "# brain = stc_.plot(**pp)\n",
    "# brain.add_text(0.1, 0.9, solver.name, 'title',\n",
    "#                font_size=14)\n",
    "\n",
    "# evoked_ = mne.EvokedArray(fwd[\"sol\"][\"data\"] @ stc_.data, info).set_eeg_reference(\"average\", projection=True)\n",
    "# evoked_.plot_joint()\n",
    "\n",
    "# print(solver.name, \" r = \", pearsonr(abs(stc.data).mean(axis=-1), abs(stc_.data).mean(axis=-1))[0])\n",
    "\n",
    "mle = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "print(f\"{solver.name}, mle = {mle:.2f} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1\n",
      "Sample 2\n",
      "Sample 3\n",
      "Sample 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m estimated_idc \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray([]) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(current_data))]\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sim_params_temp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_sources\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m---> 74\u001b[0m     estimated_sources \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcovs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     estimated_sources \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([yy \u001b[38;5;241m/\u001b[39m yy\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;28;01mfor\u001b[39;00m yy \u001b[38;5;129;01min\u001b[39;00m estimated_sources], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     76\u001b[0m     estimated_sources_temp \u001b[38;5;241m=\u001b[39m estimated_sources\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:442\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m, x, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    440\u001b[0m ):\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     epoch_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:625\u001b[0m, in \u001b[0;36mTFEpochIterator.__init__\u001b[1;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy \u001b[38;5;241m=\u001b[39m distribute_strategy\n\u001b[1;32m--> 625\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedDataset):\n\u001b[0;32m    627\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(\n\u001b[0;32m    628\u001b[0m         dataset\n\u001b[0;32m    629\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:634\u001b[0m, in \u001b[0;36mTFEpochIterator._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:236\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    234\u001b[0m     indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mmap(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle)\n\u001b[1;32m--> 236\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n\u001b[0;32m    239\u001b[0m options\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39mauto_shard_policy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    240\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAutoShardPolicy\u001b[38;5;241m.\u001b[39mDATA\n\u001b[0;32m    241\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:197\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs\u001b[1;34m(indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    191\u001b[0m inputs \u001b[38;5;241m=\u001b[39m array_slicing\u001b[38;5;241m.\u001b[39mconvert_to_sliceable(\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs, target_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m )\n\u001b[0;32m    194\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mlists_to_tuples(inputs)\n\u001b[0;32m    196\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip(\n\u001b[1;32m--> 197\u001b[0m     (indices_dataset, \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepeat())\n\u001b[0;32m    198\u001b[0m )\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_batch\u001b[39m(i, data):\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_one\u001b[39m(x):\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:741\u001b[0m, in \u001b[0;36mDatasetV2.from_tensors\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# from_tensors_op -> dataset_ops).\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensors_op\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensors_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensors_op.py:23\u001b[0m, in \u001b[0;36m_from_tensors\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensors\u001b[39m(tensors, name):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensors_op.py:35\u001b[0m, in \u001b[0;36m_TensorDataset.__init__\u001b[1;34m(self, element, name)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure, element)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m---> 35\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_tensor_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_structure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(variant_tensor)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:7686\u001b[0m, in \u001b[0;36mtensor_dataset\u001b[1;34m(components, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   7684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   7685\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 7686\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7687\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTensorDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7688\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   7690\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from copy import deepcopy\n",
    "from invert import Solver\n",
    "\n",
    "sim_params_temp = deepcopy(sim_params)\n",
    "sim_params_temp[\"batch_size\"] = 1\n",
    "sim_params_temp[\"n_sources\"] = 2\n",
    "sim_params_temp[\"inter_source_correlation\"] = 0.9\n",
    "sim_params_temp[\"correlation_mode\"] = None\n",
    "sim_params_temp[\"snr_range\"] = (1, 1)\n",
    "sim_params_temp[\"amplitude_range\"] = (1, 1)\n",
    "sim_params_temp[\"n_timepoints\"] = 10\n",
    "# sim_params_temp[\"correlation_mode\"] = \"cholesky\"\n",
    "# sim_params_temp[\"noise_color_coeff\"] = (0.1, 0.5)\n",
    "sim_params_temp[\"correlation_mode\"] = None\n",
    "sim_params_temp[\"noise_color_coeff\"] = 0.0\n",
    "\n",
    "n_repetitions = 1000\n",
    "errors = []\n",
    "n_sources = sim_params_temp[\"n_sources\"]\n",
    "solver = Solver(\"ap\")\n",
    "solver_ssm = Solver(\"ssm\")\n",
    "idx = 0\n",
    "for i_samp in range(n_repetitions):\n",
    "    print(f\"Sample {i_samp+1}\")\n",
    "    gen = generator(fwd, **sim_params_temp)\n",
    "    X, true_indices, Y = generate_initial_data(gen)\n",
    "    \n",
    "    current_data = deepcopy(X)\n",
    "    # Compute Covariances\n",
    "    covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "    covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "    estimated_idc = [np.array([]) for _ in range(len(current_data))]\n",
    "\n",
    "    for i_iter in range(sim_params_temp[\"n_sources\"]):\n",
    "        estimated_sources = model.predict(covs, verbose=0)\n",
    "        estimated_sources = np.stack([yy / yy.max() for yy in estimated_sources], axis=0)\n",
    "        estimated_sources_temp = estimated_sources.copy()\n",
    "        for i_sample in range(len(current_data)):\n",
    "            if i_iter > 0:\n",
    "                estimated_sources_temp[i_sample, estimated_idc[i_sample]] = 0\n",
    "            estimated_idc[i_sample] = np.append( estimated_idc[i_sample], np.argmax(estimated_sources_temp[i_sample]) ).astype(int)\n",
    "        source = np.zeros_like(estimated_sources[idx])\n",
    "        source[estimated_idc[idx]] = 1\n",
    "        stc_ = mne.SourceEstimate(source, vertices, tmin=0, tstep=1/1000, \n",
    "                                subject=\"fsaverage\", verbose=0)\n",
    "        # stc_.plot(**pp)\n",
    "        \n",
    "        current_data = wrap_outproject_from_data(X, leadfield, estimated_idc, alpha=1.)\n",
    "        # estimated_idc_trimmed = [np.array([es[-1],]) for es in estimated_idc]\n",
    "        # current_data = wrap_outproject_from_data(current_data, leadfield, estimated_idc_trimmed)\n",
    "\n",
    "        covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "        covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "\n",
    "    # estimated_positions = pos[estimated_idc[idx]]\n",
    "    # true_positions = pos[true_indices[idx]]\n",
    "    # pairwise_dist = cdist(true_positions, estimated_positions)\n",
    "    # # select the true positions closest to the estimated ones\n",
    "    # true_sub_idc, estimated_sub_idc = linear_sum_assignment(pairwise_dist)\n",
    "    mle_cov = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "\n",
    "    error = dict(MLE=mle_cov, method=\"CovCNN\", i_sim=i_samp)\n",
    "    error.update(sim_params_temp)\n",
    "    errors.append(error)\n",
    "\n",
    "    current_data = deepcopy(X)\n",
    "    # Compute Covariances\n",
    "    covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "    covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "    estimated_idc = [np.array([]) for _ in range(len(current_data))]\n",
    "\n",
    "    for i_iter in range(sim_params_temp[\"n_sources\"]):\n",
    "        estimated_sources = model2.predict(covs, verbose=0)\n",
    "        estimated_sources = np.stack([yy / yy.max() for yy in estimated_sources], axis=0)\n",
    "        estimated_sources_temp = estimated_sources.copy()\n",
    "        for i_sample in range(len(current_data)):\n",
    "            if i_iter > 0:\n",
    "                estimated_sources_temp[i_sample, estimated_idc[i_sample]] = 0\n",
    "            estimated_idc[i_sample] = np.append( estimated_idc[i_sample], np.argmax(estimated_sources_temp[i_sample]) ).astype(int)\n",
    "        source = np.zeros_like(estimated_sources[idx])\n",
    "        source[estimated_idc[idx]] = 1\n",
    "        stc_ = mne.SourceEstimate(source, vertices, tmin=0, tstep=1/1000, \n",
    "                                subject=\"fsaverage\", verbose=0)\n",
    "        # stc_.plot(**pp)\n",
    "        \n",
    "        current_data = wrap_outproject_from_data(X, leadfield, estimated_idc, alpha=1.)\n",
    "        # estimated_idc_trimmed = [np.array([es[-1],]) for es in estimated_idc]\n",
    "        # current_data = wrap_outproject_from_data(current_data, leadfield, estimated_idc_trimmed)\n",
    "\n",
    "        covs = np.stack([x@x.T for x in current_data], axis=0)\n",
    "        covs = np.stack([cov/abs(cov).max() for cov in covs], axis=0)\n",
    "\n",
    "    # estimated_positions = pos[estimated_idc[idx]]\n",
    "    # true_positions = pos[true_indices[idx]]\n",
    "    # pairwise_dist = cdist(true_positions, estimated_positions)\n",
    "    # # select the true positions closest to the estimated ones\n",
    "    # true_sub_idc, estimated_sub_idc = linear_sum_assignment(pairwise_dist)\n",
    "    mle_cov = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    \n",
    "\n",
    "    error = dict(MLE=mle_cov, method=\"CovCNN2\", i_sim=i_samp)\n",
    "    error.update(sim_params_temp)\n",
    "    errors.append(error)\n",
    "\n",
    "    evoked = mne.EvokedArray(X[idx], info).set_eeg_reference(\"average\", projection=True, verbose=0).apply_proj(verbose=0)\n",
    "\n",
    "    # AP\n",
    "    solver.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=False, n=n_sources, \n",
    "                             k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=6)\n",
    "    stc_ = solver.apply_inverse_operator(evoked)\n",
    "    mle_ap = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    error = dict(MLE=mle_ap, method=\"AP\", i_sim=i_samp)\n",
    "    error.update(sim_params_temp)\n",
    "    errors.append(error)\n",
    "\n",
    "    # AP refined\n",
    "    solver.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=True, n=n_sources, \n",
    "                             k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=6)\n",
    "    stc_ = solver.apply_inverse_operator(evoked)\n",
    "    mle_ap = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    error = dict(MLE=mle_ap, method=\"AP-refined\", i_sim=i_samp)\n",
    "    error.update(sim_params_temp)\n",
    "    errors.append(error)\n",
    "\n",
    "    # # SSM\n",
    "    # solver_ssm.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=False, n=n_sources, \n",
    "    #                          k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=5)\n",
    "    # stc_ = solver_ssm.apply_inverse_operator(evoked)\n",
    "    # mle_ssm = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    # error = dict(MLE=mle_ssm, method=\"SSM\", i_sim=i_samp)\n",
    "    # error.update(sim_params_temp)\n",
    "    # errors.append(error)\n",
    "\n",
    "    # # SSM refined\n",
    "    # solver_ssm.make_inverse_operator(fwd, evoked, n_orders=0, refine_solution=True, n=n_sources, \n",
    "    #                          k=n_sources, diffusion_parameter=0.1, stop_crit=0, max_iter=5)\n",
    "    # stc_ = solver_ssm.apply_inverse_operator(evoked)\n",
    "    # mle_ssm = eval_mean_localization_error(Y[idx], stc_.data, adjacency.toarray(), adjacency.toarray(), distance_matrix, mode=\"match\")\n",
    "    # error = dict(MLE=mle_ssm, method=\"SSM-refined\", i_sim=i_samp)\n",
    "    # error.update(sim_params_temp)\n",
    "    # errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>32.563453</td>\n",
       "      <td>17.609402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.270026</td>\n",
       "      <td>31.986593</td>\n",
       "      <td>45.186194</td>\n",
       "      <td>88.560176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP-refined</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>24.794161</td>\n",
       "      <td>21.164265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.071344</td>\n",
       "      <td>41.746477</td>\n",
       "      <td>88.560176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CovCNN</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>26.997023</td>\n",
       "      <td>19.124436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.175771</td>\n",
       "      <td>24.740820</td>\n",
       "      <td>39.798547</td>\n",
       "      <td>116.098300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CovCNN2</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>32.504648</td>\n",
       "      <td>21.814533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.988239</td>\n",
       "      <td>31.196931</td>\n",
       "      <td>48.220348</td>\n",
       "      <td>116.098300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean        std  min        25%        50%  \\\n",
       "method                                                                \n",
       "AP          1000.0  32.563453  17.609402  0.0  20.270026  31.986593   \n",
       "AP-refined  1000.0  24.794161  21.164265  0.0   0.000000  24.071344   \n",
       "CovCNN      1000.0  26.997023  19.124436  0.0  12.175771  24.740820   \n",
       "CovCNN2     1000.0  32.504648  21.814533  0.0  14.988239  31.196931   \n",
       "\n",
       "                  75%         max  \n",
       "method                             \n",
       "AP          45.186194   88.560176  \n",
       "AP-refined  41.746477   88.560176  \n",
       "CovCNN      39.798547  116.098300  \n",
       "CovCNN2     48.220348  116.098300  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(errors)\n",
    "for estimator in (np.mean, np.median):\n",
    "    title = f\"\"\"{estimator.__name__} n={sim_params_temp[\"n_sources\"]}, snr={sim_params_temp[\"snr_range\"][0]}, rho={sim_params_temp[\"inter_source_correlation\"]}, T={sim_params_temp[\"n_timepoints\"]}\"\"\"\n",
    "    plt.figure()\n",
    "    sns.barplot(data=df, x=\"method\", y=\"MLE\", estimator=estimator)\n",
    "    plt.title(title)\n",
    "    plt.ylim(0, 40)\n",
    "\n",
    "df.groupby(\"method\").describe()[\"MLE\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esienv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
