{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; \n",
    "sys.path.insert(0, '../../esinet')\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "from invert.cmaps import parula\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    2.7s remaining:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    3.0s remaining:    1.8s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi16')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "dist = cdist(pos, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  7.98it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 200.09it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.23386270e-09 7.36455872e-09 9.40828593e-08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    }
   ],
   "source": [
    "# settings = dict(number_of_sources=1, extents=40, duration_of_trial=0.01, target_snr=99999999999)\n",
    "settings = dict(number_of_sources=4, extents=(1, 40), duration_of_trial=1, target_snr=99999)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "y = evoked.data[:, 0]\n",
    "x = stc.data[:, 0]\n",
    "\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_thresholding(r, lam):\n",
    "    r = np.squeeze(np.array(r))\n",
    "    C = np.sign(r) * np.clip(abs(r) - lam, a_min=0, a_max=None)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_total = int(1e4)\n",
    "A = deepcopy(leadfield)\n",
    "n_chans, n_dipoles = A.shape\n",
    "beta = 1 / np.linalg.norm(A)\n",
    "lam = 0.000001\n",
    "x_t = np.zeros(n_dipoles)\n",
    "A_H = np.matrix(A).getH()\n",
    "for t in range(t_total):\n",
    "    v_t = y - A @ x_t\n",
    "    x_t = soft_thresholding(x_t + beta * A_H @ v_t, lam)\n",
    "abs(x_t).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [nan nan nan]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lukas\\Dokumente\\projects\\invert\\dev\\ista.ipynb Zelle 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukas/Dokumente/projects/invert/dev/ista.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m stc_ \u001b[39m=\u001b[39m stc\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukas/Dokumente/projects/invert/dev/ista.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m stc_\u001b[39m.\u001b[39mdata[:, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m x_t \u001b[39m/\u001b[39m \u001b[39mabs\u001b[39m(x_t)\u001b[39m.\u001b[39mmax()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lukas/Dokumente/projects/invert/dev/ista.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m stc_\u001b[39m.\u001b[39;49mplot(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpp)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\mne\\source_estimate.py:650\u001b[0m, in \u001b[0;36m_BaseSourceEstimate.plot\u001b[1;34m(self, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39m@copy_function_doc_to_method_doc\u001b[39m(plot_source_estimates)\n\u001b[0;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39mself\u001b[39m, subject\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, surface\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minflated\u001b[39m\u001b[39m'\u001b[39m, hemi\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlh\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    641\u001b[0m          colormap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, time_label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, smoothing_steps\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    648\u001b[0m          src\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, volume_options\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, view_layout\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    649\u001b[0m          add_data_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, brain_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 650\u001b[0m     brain \u001b[39m=\u001b[39m plot_source_estimates(\n\u001b[0;32m    651\u001b[0m         \u001b[39mself\u001b[39;49m, subject, surface\u001b[39m=\u001b[39;49msurface, hemi\u001b[39m=\u001b[39;49mhemi, colormap\u001b[39m=\u001b[39;49mcolormap,\n\u001b[0;32m    652\u001b[0m         time_label\u001b[39m=\u001b[39;49mtime_label, smoothing_steps\u001b[39m=\u001b[39;49msmoothing_steps,\n\u001b[0;32m    653\u001b[0m         transparent\u001b[39m=\u001b[39;49mtransparent, alpha\u001b[39m=\u001b[39;49malpha, time_viewer\u001b[39m=\u001b[39;49mtime_viewer,\n\u001b[0;32m    654\u001b[0m         subjects_dir\u001b[39m=\u001b[39;49msubjects_dir, figure\u001b[39m=\u001b[39;49mfigure, views\u001b[39m=\u001b[39;49mviews,\n\u001b[0;32m    655\u001b[0m         colorbar\u001b[39m=\u001b[39;49mcolorbar, clim\u001b[39m=\u001b[39;49mclim, cortex\u001b[39m=\u001b[39;49mcortex, size\u001b[39m=\u001b[39;49msize,\n\u001b[0;32m    656\u001b[0m         background\u001b[39m=\u001b[39;49mbackground, foreground\u001b[39m=\u001b[39;49mforeground,\n\u001b[0;32m    657\u001b[0m         initial_time\u001b[39m=\u001b[39;49minitial_time, time_unit\u001b[39m=\u001b[39;49mtime_unit, backend\u001b[39m=\u001b[39;49mbackend,\n\u001b[0;32m    658\u001b[0m         spacing\u001b[39m=\u001b[39;49mspacing, title\u001b[39m=\u001b[39;49mtitle, show_traces\u001b[39m=\u001b[39;49mshow_traces,\n\u001b[0;32m    659\u001b[0m         src\u001b[39m=\u001b[39;49msrc, volume_options\u001b[39m=\u001b[39;49mvolume_options, view_layout\u001b[39m=\u001b[39;49mview_layout,\n\u001b[0;32m    660\u001b[0m         add_data_kwargs\u001b[39m=\u001b[39;49madd_data_kwargs, brain_kwargs\u001b[39m=\u001b[39;49mbrain_kwargs,\n\u001b[0;32m    661\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[0;32m    662\u001b[0m     \u001b[39mreturn\u001b[39;00m brain\n",
      "File \u001b[1;32m<decorator-gen-174>:12\u001b[0m, in \u001b[0;36mplot_source_estimates\u001b[1;34m(stc, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\mne\\viz\\_3d.py:1924\u001b[0m, in \u001b[0;36mplot_source_estimates\u001b[1;34m(stc, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n\u001b[0;32m   1922\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1923\u001b[0m     \u001b[39mwith\u001b[39;00m use_3d_backend(backend):\n\u001b[1;32m-> 1924\u001b[0m         \u001b[39mreturn\u001b[39;00m _plot_stc(\n\u001b[0;32m   1925\u001b[0m             stc, overlay_alpha\u001b[39m=\u001b[39;49malpha, brain_alpha\u001b[39m=\u001b[39;49malpha,\n\u001b[0;32m   1926\u001b[0m             vector_alpha\u001b[39m=\u001b[39;49malpha, cortex\u001b[39m=\u001b[39;49mcortex, foreground\u001b[39m=\u001b[39;49mforeground,\n\u001b[0;32m   1927\u001b[0m             size\u001b[39m=\u001b[39;49msize, scale_factor\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, show_traces\u001b[39m=\u001b[39;49mshow_traces,\n\u001b[0;32m   1928\u001b[0m             src\u001b[39m=\u001b[39;49msrc, volume_options\u001b[39m=\u001b[39;49mvolume_options,\n\u001b[0;32m   1929\u001b[0m             view_layout\u001b[39m=\u001b[39;49mview_layout, add_data_kwargs\u001b[39m=\u001b[39;49madd_data_kwargs,\n\u001b[0;32m   1930\u001b[0m             brain_kwargs\u001b[39m=\u001b[39;49mbrain_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\mne\\viz\\_3d.py:2038\u001b[0m, in \u001b[0;36m_plot_stc\u001b[1;34m(stc, subject, surface, hemi, colormap, time_label, smoothing_steps, subjects_dir, views, clim, figure, initial_time, time_unit, background, time_viewer, colorbar, transparent, brain_alpha, overlay_alpha, vector_alpha, cortex, foreground, size, scale_factor, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs)\u001b[0m\n\u001b[0;32m   2036\u001b[0m     use_kwargs\u001b[39m.\u001b[39mupdate(hemi\u001b[39m=\u001b[39mhemi)\n\u001b[0;32m   2037\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):  \u001b[39m# traits warnings\u001b[39;00m\n\u001b[1;32m-> 2038\u001b[0m         brain\u001b[39m.\u001b[39;49madd_data(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49muse_kwargs)\n\u001b[0;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m volume:\n\u001b[0;32m   2041\u001b[0m     use_kwargs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32m<decorator-gen-189>:12\u001b[0m, in \u001b[0;36madd_data\u001b[1;34m(self, array, fmin, fmid, fmax, thresh, center, transparent, colormap, alpha, vertices, smoothing_steps, time, time_label, colorbar, hemi, remove_existing, time_label_size, initial_time, scale_factor, vector_alpha, clim, src, volume_options, colorbar_kwargs, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py:2050\u001b[0m, in \u001b[0;36mBrain.add_data\u001b[1;34m(self, array, fmin, fmid, fmax, thresh, center, transparent, colormap, alpha, vertices, smoothing_steps, time, time_label, colorbar, hemi, remove_existing, time_label_size, initial_time, scale_factor, vector_alpha, clim, src, volume_options, colorbar_kwargs, verbose)\u001b[0m\n\u001b[0;32m   2048\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39m'\u001b[39m\u001b[39mfmid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fmid\n\u001b[0;32m   2049\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39m'\u001b[39m\u001b[39mfmax\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fmax\n\u001b[1;32m-> 2050\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_lut()\n\u001b[0;32m   2052\u001b[0m \u001b[39m# 1) add the surfaces first\u001b[39;00m\n\u001b[0;32m   2053\u001b[0m actor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py:3223\u001b[0m, in \u001b[0;36mBrain.update_lut\u001b[1;34m(self, fmin, fmid, fmax, alpha)\u001b[0m\n\u001b[0;32m   3221\u001b[0m transparent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39m'\u001b[39m\u001b[39mtransparent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m   3222\u001b[0m lims \u001b[39m=\u001b[39m {key: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[key] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfmid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfmax\u001b[39m\u001b[39m'\u001b[39m)}\n\u001b[1;32m-> 3223\u001b[0m _update_monotonic(lims, fmin\u001b[39m=\u001b[39;49mfmin, fmid\u001b[39m=\u001b[39;49mfmid, fmax\u001b[39m=\u001b[39;49mfmax)\n\u001b[0;32m   3224\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(val \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m lims\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m   3226\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mupdate(lims)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py:3877\u001b[0m, in \u001b[0;36m_update_monotonic\u001b[1;34m(lims, fmin, fmid, fmax)\u001b[0m\n\u001b[0;32m   3875\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m    Bumping fmid = \u001b[39m\u001b[39m{\u001b[39;00mlims[\u001b[39m\"\u001b[39m\u001b[39mfmid\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mfmin\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   3876\u001b[0m         lims[\u001b[39m'\u001b[39m\u001b[39mfmid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fmin\n\u001b[1;32m-> 3877\u001b[0m \u001b[39massert\u001b[39;00m lims[\u001b[39m'\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m lims[\u001b[39m'\u001b[39m\u001b[39mfmid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m lims[\u001b[39m'\u001b[39m\u001b[39mfmax\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m   3878\u001b[0m \u001b[39mif\u001b[39;00m fmid \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3879\u001b[0m     lims[\u001b[39m'\u001b[39m\u001b[39mfmid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fmid\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stc_ = stc.copy()\n",
    "stc_.data[:, 0] = x_t / abs(x_t).max()\n",
    "stc_.plot(**pp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('invertenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda1e5657e486f74a7b39841fb8103db2af51a77394f44c39a7821a371af47bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
