{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Forward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi32')\n",
    "fwd = create_forward_model(info=info, sampling='ico4')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "n_chans, n_dipoles = leadfield.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 5124\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.97s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00, 62.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (5124, 1000) (5124, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 19.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [5.19182089e-10 1.74571140e-09 5.22952957e-08]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    }
   ],
   "source": [
    "# settings = dict(number_of_sources=1, extents=40, duration_of_trial=0.01, target_snr=99999999999)\n",
    "settings = dict(number_of_sources=3, extents=(1, 40), duration_of_trial=1, target_snr=2)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "M = evoked.data\n",
    "\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baf4a5768bd430b8eaba5ccb82fe6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from invert import make_inverse_operator, apply_inverse_operator\n",
    "from invert.evaluate import nmse, corr\n",
    "from tqdm.notebook import tqdm\n",
    "solver = \"lor\"\n",
    "alpha_heuristic = 1/settings[\"target_snr\"]**2\n",
    "inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, alpha=alpha_heuristic, verbose=0)\n",
    "stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "error_heuristic = np.median(corr(stc.data, stc_hat.data))\n",
    "\n",
    "alphas = np.linspace(1.5e3, 2.5e3, 20)\n",
    "errors = []\n",
    "for alpha in tqdm(alphas):\n",
    "    inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, alpha=alpha, verbose=0)\n",
    "    stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "    error = np.median(corr(stc.data, stc_hat.data))\n",
    "    errors.append(error)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(alphas, errors)\n",
    "plt.xlabel(\"alphas\")\n",
    "plt.ylabel(\"corr\")\n",
    "plt.ylim(0,1)\n",
    "plt.plot([alpha_heuristic, alpha_heuristic], plt.ylim(), 'r')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [6.52956037e-05 7.85430437e-05 1.65699895e-04]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x2480de520d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [4.54311450e-05 5.30130690e-05 7.36848788e-05]\n",
      "Using control points [4.54311450e-05 5.30130690e-05 7.36848788e-05]\n"
     ]
    }
   ],
   "source": [
    "solver = \"dSPM\"\n",
    "# alpha_heuristic = 1/settings[\"target_snr\"]**2\n",
    "alpha = 2000\n",
    "inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, alpha=alpha, verbose=0)\n",
    "stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "stc_hat.plot(**pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\virtualenvs\\invertenv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:863: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  warn(\"Method 'bounded' does not support relative tolerance in x; \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=0.0260\n",
      "Using control points [2.69993792e-09 3.79865658e-09 1.90327871e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1975446e2b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.33156213e-09 2.41506867e-09 3.25942281e-08]\n",
      "Using control points [2.45756571e-09 3.58205804e-09 7.57540420e-09]\n"
     ]
    }
   ],
   "source": [
    "from invert import make_inverse_operator, apply_inverse_operator\n",
    "from invert.adapters import contextualize_bd\n",
    "from invert.evaluate import nmse\n",
    "\n",
    "solver = \"lstm\"\n",
    "# inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, verbose=1)\n",
    "\n",
    "stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "error = np.median(nmse(stc.data, stc_hat.data))\n",
    "print(f\"error={error:.4f}\")\n",
    "stc_hat.plot(**pp, brain_kwargs=dict(title=solver))\n",
    "\n",
    "# stc_hat.data = contextualize_bd(stc_hat.data, leadfield, num_epochs=20)\n",
    "# error = np.median(nmse(stc.data, stc_hat.data))\n",
    "# print(f\"error={error:.4f}\")\n",
    "# stc_hat.plot(**pp, brain_kwargs=dict(title=solver + \" contextualized\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invert import all_solvers, make_inverse_operator, apply_inverse_operator\n",
    "from invert.adapters import contextualize_bd\n",
    "from invert.evaluate import nmse, corr\n",
    "stc.plot(**pp, brain_kwargs=dict(title=\"Ground Truth\"))\n",
    "errors = dict()\n",
    "for solver in all_solvers:\n",
    "    print(solver)\n",
    "    inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, alpha=1/4.5)\n",
    "    stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "    # stc_hat.plot(**pp, brain_kwargs=dict(title=solver))\n",
    "    errors[solver] = corr(stc.data, stc_hat.data)\n",
    "    \n",
    "solver = \"esinet\"\n",
    "stc_hat = net.predict(evoked)[0]\n",
    "# stc_hat.plot(**pp, brain_kwargs=dict(title=solver))\n",
    "errors[solver] = corr(stc.data, stc_hat.data)\n",
    "\n",
    "solver += \" contextualized\"\n",
    "stc_hat.data = contextualize_bd(stc_hat.data, leadfield)\n",
    "errors[solver] = corr(stc.data, stc_hat.data)\n",
    "# stc_hat.plot(**pp, brain_kwargs=dict(title=solver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = \"LORETA\"\n",
    "inverse_operator = make_inverse_operator(fwd, solver=solver, evoked=evoked, alpha=1/4.5)\n",
    "stc_hat = apply_inverse_operator(evoked, inverse_operator, fwd)\n",
    "stc_hat.plot(**pp, brain_kwargs=dict(title=solver))\n",
    "\n",
    "stc_hat.data = contextualize_bd(stc_hat.data, leadfield, steps_per_ep=25, verbose=1)\n",
    "errors[solver] = corr(stc.data, stc_hat.data)\n",
    "stc_hat.plot(**pp, brain_kwargs=dict(title=solver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib qt\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "# ax.set_yscale(\"log\")\n",
    "sns.boxplot(data=pd.DataFrame(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (invertenv)",
   "language": "python",
   "name": "invertenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a54b85cbc80ea8362b8e45e33618627fd9167210ff2c52e6dbeaf85afe35b874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
