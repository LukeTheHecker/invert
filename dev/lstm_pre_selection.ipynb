{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import mne\n",
    "from esinet import Simulation\n",
    "from esinet.forward import get_info, create_forward_model\n",
    "from esinet.util import unpack_fwd\n",
    "pp = dict(surface='white', hemi='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(sim):\n",
    "    X = np.squeeze(np.stack([eeg.average().data for eeg in sim.eeg_data]))\n",
    "    y = np.squeeze(np.stack([src.data for src in sim.source_data]))\n",
    "    for i, (x_sample, y_sample) in enumerate(zip(X, y)):\n",
    "        # X[i] = np.stack([(x - np.mean(x)) / np.std(x) for x in x_sample.T], axis=0).T\n",
    "        # y[i] = np.stack([ y / np.max(abs(y)) for y in y_sample.T], axis=0).T\n",
    "\n",
    "        X[i] = np.stack([x - np.mean(x) for x in x_sample.T], axis=0).T\n",
    "        X[i] /= X[i].std()\n",
    "        y[i] /= np.max(abs(y[i]))\n",
    "\n",
    "    X = np.swapaxes(X, 1,2)\n",
    "    y = np.swapaxes(y, 1,2)\n",
    "    \n",
    "    return X, y\n",
    "def make_mask(y, thresh=0.001):\n",
    "    y_mask = np.zeros((y.shape[0], n_dipoles))\n",
    "    for i, y_samp in enumerate(y):\n",
    "        yy = abs(y_samp).mean(axis=0)\n",
    "        \n",
    "\n",
    "        y_mask[i] = (yy > yy.max()*thresh).astype(int)\n",
    "    return y_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(kind='biosemi128')\n",
    "fwd = create_forward_model(info=info, sampling='ico3')\n",
    "\n",
    "leadfield, pos = unpack_fwd(fwd)[1:3]\n",
    "n_chans, n_dipoles = leadfield.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:58<00:00, 84.72it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 5493.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 10) (1284, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:58<00:00, 170.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.08123995 0.12730579 0.66833728]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n"
     ]
    }
   ],
   "source": [
    "settings = dict(number_of_sources=(1, 15), extents=(1, 40), duration_of_trial=0.01, target_snr=1e99)\n",
    "\n",
    "sim = Simulation(fwd, info, settings).simulate(10000)\n",
    "stc = sim.source_data[0]\n",
    "evoked = sim.eeg_data[0].average()\n",
    "\n",
    "stc.data /= abs(stc.data).max()\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)\n",
    "evoked.plot_joint()\n",
    "\n",
    "X, y = prep_data(sim)\n",
    "y_mask = make_mask(y, thresh=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Prelocalizer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, None, 128)]       0         \n",
      "                                                                 \n",
      " FC1 (TimeDistributed)       (None, None, 300)         38700     \n",
      "                                                                 \n",
      " LSTM1 (Bidirectional)       (None, 128)               186880    \n",
      "                                                                 \n",
      " Mask (Dense)                (None, 1284)              165636    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 391,216\n",
      "Trainable params: 391,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "266/266 [==============================] - 7s 15ms/step - loss: 0.2357 - val_loss: 0.1974\n",
      "Epoch 2/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1993 - val_loss: 0.1944\n",
      "Epoch 3/30\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.1944 - val_loss: 0.1892\n",
      "Epoch 4/30\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.1885 - val_loss: 0.1852\n",
      "Epoch 5/30\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.1824 - val_loss: 0.1795\n",
      "Epoch 6/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1772 - val_loss: 0.1775\n",
      "Epoch 7/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1727 - val_loss: 0.1744\n",
      "Epoch 8/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1689 - val_loss: 0.1716\n",
      "Epoch 9/30\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.1650 - val_loss: 0.1699\n",
      "Epoch 10/30\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.1617 - val_loss: 0.1689\n",
      "Epoch 11/30\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.1589 - val_loss: 0.1680\n",
      "Epoch 12/30\n",
      "266/266 [==============================] - 3s 13ms/step - loss: 0.1564 - val_loss: 0.1664\n",
      "Epoch 13/30\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.1541 - val_loss: 0.1666\n",
      "Epoch 14/30\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.1519 - val_loss: 0.1668\n",
      "Epoch 15/30\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.1496 - val_loss: 0.1661\n",
      "Epoch 16/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1476 - val_loss: 0.1653\n",
      "Epoch 17/30\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.1458 - val_loss: 0.1662\n",
      "Epoch 18/30\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.1440 - val_loss: 0.1660\n",
      "Epoch 19/30\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.1425 - val_loss: 0.1663\n",
      "Epoch 20/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1410 - val_loss: 0.1660\n",
      "Epoch 21/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1393 - val_loss: 0.1659\n",
      "Epoch 22/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1380 - val_loss: 0.1671\n",
      "Epoch 23/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1363 - val_loss: 0.1673\n",
      "Epoch 24/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1349 - val_loss: 0.1665\n",
      "Epoch 25/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1338 - val_loss: 0.1668\n",
      "Epoch 26/30\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1325 - val_loss: 0.1672\n",
      "Epoch 27/30\n",
      "266/266 [==============================] - 3s 9ms/step - loss: 0.1314 - val_loss: 0.1685\n",
      "Epoch 28/30\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.1308 - val_loss: 0.1683\n",
      "Epoch 29/30\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.1293 - val_loss: 0.1688\n",
      "Epoch 30/30\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.1285 - val_loss: 0.1691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3808cbdc0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Bidirectional, LSTM, multiply, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "n_channels, n_dipoles = leadfield.shape\n",
    "input_shape = (None, None, n_channels)\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "n_dense_units = 300\n",
    "n_lstm_units = 64\n",
    "activation_function = \"tanh\"\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "dropout = 0.2\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None, n_channels), name='Input')\n",
    "\n",
    "fc1 = TimeDistributed(Dense(n_dense_units, \n",
    "            activation=activation_function), \n",
    "            name='FC1')(inputs)\n",
    "\n",
    "# Masking\n",
    "lstm1 = Bidirectional(LSTM(n_lstm_units, return_sequences=False, \n",
    "            input_shape=(None, n_dense_units), dropout=dropout), \n",
    "            name='LSTM1')(fc1)\n",
    "out = Dense(n_dipoles, \n",
    "            activation=\"softmax\", \n",
    "            name='Mask')(lstm1)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=out, name='Prelocalizer')\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "model.fit(X, y_mask, epochs=epochs, batch_size=batch_size, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.40it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 10) (1284, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 138.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.         0.         0.40258414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Using control points [0.00016571 0.00031698 0.02303454]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.00459589 0.00733536 0.03026608]\n",
      "Using control points [0.         0.         0.36870243]\n"
     ]
    }
   ],
   "source": [
    "settings = dict(number_of_sources=3, extents=(1, 25), duration_of_trial=0.01, target_snr=1e99)\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings).simulate(2)\n",
    "stc = sim_test.source_data[0]\n",
    "evoked = sim_test.eeg_data[0].average()\n",
    "\n",
    "stc.data /= abs(stc.data).max()\n",
    "brain = stc.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title',\n",
    "               font_size=14)\n",
    "evoked.plot_joint()\n",
    "\n",
    "X_test, y_test = prep_data(sim_test)\n",
    "y_mask_test = make_mask(y_test, thresh=0.001)\n",
    "\n",
    "y_hat = model.predict(X_test)[0]\n",
    "stc_ = stc.copy()\n",
    "stc_.data *= 0\n",
    "stc_.data[:, 0] = y_hat\n",
    "\n",
    "brain = stc_.plot(**pp)\n",
    "brain.add_text(0.1, 0.9, 'Predicted Mask', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('invertenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "109cbb5ed194d0e1c7aea844cf0a4a10faadf2a56a1c0eb03142356ad9dcb9c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
